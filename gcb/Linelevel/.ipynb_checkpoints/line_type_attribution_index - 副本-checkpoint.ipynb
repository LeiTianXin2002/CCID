{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ad6ca09",
   "metadata": {},
   "source": [
    "此 .ipynb为按照行级，获得预测正确和错误的不同行级元素的贡献值分布。根据统计分析结果(line_type_attribution_index获得的结果)，挑出实例的笔记"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e84e3fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "\n",
    "\n",
    "from captum.attr import visualization as viz\n",
    "from captum.attr import LayerConductance, LayerIntegratedGradients\n",
    "from captum.attr import configure_interpretable_embedding_layer, remove_interpretable_embedding_layer\n",
    "\n",
    "# 解决服务器挂掉的问题\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ff062613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device( \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bf31e07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 1024\n",
    "MAX_EPOCHS = 10\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 1e-5\n",
    "NUM_CLASSES = 2\n",
    "WEIGTH_DECAY = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b071fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cd873c30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Statements True:\n",
      " [\"[('returnstatement', 'return ( insertions . size () > 0 || ! unresolvedInsertions . isEmpty () || deletions . size () > 0 );', tensor(0.0590, dtype=torch.float64)), ('MethodDeclaration', 'public boolean areInsertionsOrDeletionsQueued () {', tensor(0.1059, dtype=torch.float64))]\", \"[('returnstatement', 'return Lists . transform ( type . getFieldList (), GET _ TYPE );', tensor(0.0478, dtype=torch.float64)), ('MethodDeclaration', 'public static List < RelDataType > getFieldTypeList ( final RelDataType type ) {', tensor(0.0580, dtype=torch.float64))]\", \"[('ifstatement', 'if ( txtPattern == null ) {', tensor(0.0214, dtype=torch.float64)), ('variableDeclaration', 'txtPattern = new ZapTextField ();', tensor(0.0512, dtype=torch.float64)), ('returnstatement', 'return txtPattern ;', tensor(0.0719, dtype=torch.float64)), ('MethodDeclaration', 'public ZapTextField getTxtPattern () {', tensor(0.0075, dtype=torch.float64))]\"]\n",
      "Filtered Statements True len:\n",
      " 4\n",
      "Filter True Index:\n",
      " [1, 3, 7]\n",
      "Filter True Index len:\n",
      " 4\n"
     ]
    }
   ],
   "source": [
    "filtered_statements_true = []\n",
    "filter_true_index = []\n",
    "\n",
    "with open(\"linetype_attribution_index_true.txt\", \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        if i % 2 == 0:\n",
    "            filtered_statements_true.append(line.strip())\n",
    "        else:\n",
    "            filter_true_index.append(line.strip())\n",
    "        \n",
    "# 查看前三个\n",
    "print(\"Filtered Statements True:\\n\", filtered_statements_true[:3])\n",
    "print(\"Filtered Statements True len:\\n\", len(filtered_statements_true))\n",
    "\n",
    "filter_true_index = [int(x) for x in filter_true_index]\n",
    "print(\"Filter True Index:\\n\", filter_true_index[:3])\n",
    "print(\"Filter True Index len:\\n\", len(filter_true_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2aaebfe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Statements False:\n",
      " [\"[('returnstatement', 'return recordParser . data ();', tensor(0.1162, dtype=torch.float64)), ('MethodDeclaration', 'public Struct ceDataAttribute () {', tensor(0.2231, dtype=torch.float64))]\", \"[('returnstatement', 'return queue . file ();', tensor(0.0569, dtype=torch.float64)), ('MethodDeclaration', 'public File getSinkFile () {', tensor(0.1377, dtype=torch.float64))]\", \"[('variableDeclaration', 'return new Lob ( this );', tensor(0.1033, dtype=torch.float64)), ('returnstatement', 'return new Lob ( this );', tensor(0.1033, dtype=torch.float64)), ('MethodDeclaration', 'public Lob build () {', tensor(0.1032, dtype=torch.float64))]\"]\n",
      "Filtered Statements False len:\n",
      " 3\n",
      "Filter False Index:\n",
      " [5, 6, 14]\n",
      "Filter False Index len:\n",
      " 3\n"
     ]
    }
   ],
   "source": [
    "filtered_statements_false = []\n",
    "filter_false_index = []\n",
    "\n",
    "with open(\"linetype_attribution_index_false.txt\", \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        if i % 2 == 0:\n",
    "            filtered_statements_false.append(line.strip())\n",
    "        else:\n",
    "            filter_false_index.append(line.strip())\n",
    "            \n",
    "# 查看前三个\n",
    "print(\"Filtered Statements False:\\n\", filtered_statements_false[:3])\n",
    "print(\"Filtered Statements False len:\\n\", len(filtered_statements_false))\n",
    "\n",
    "filter_false_index = [int(x) for x in filter_false_index]\n",
    "print(\"Filter False Index:\\n\", filter_false_index[:3])\n",
    "print(\"Filter False Index len:\\n\", len(filter_false_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ad5f803f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "# 假设你的列表如下\n",
    "char_list = ['1', '2', '3', '4', '5']\n",
    "\n",
    "# 使用列表推导式将所有元素转换为数字\n",
    "num_list = [int(x) for x in char_list]\n",
    "\n",
    "print(num_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87461f39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3b8e3dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_test_data():\n",
    "    test_param = pd.read_json(\"D:/BERT_learing/code_comment_inconsistency_detection/data/param/test.json\")\n",
    "    test_return = pd.read_json(\"D:/BERT_learing/code_comment_inconsistency_detection/data/return/test.json\")\n",
    "    test_summary = pd.read_json(\"D:/BERT_learing/code_comment_inconsistency_detection/data/summary/test.json\")\n",
    "    test_df = pd.concat([test_summary,test_param, test_return], axis=0)\n",
    "    test_df = test_df[:20]\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "    return test_df\n",
    "test_df = retrieve_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7da1c99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_other_index(df,index):\n",
    "    filtered_df = df.loc[index]\n",
    "    filtered_df = filtered_df.reset_index(drop=True)\n",
    "    filtered_df[\"raw_data_index_column\"] = index\n",
    "    return filtered_df\n",
    "\n",
    "test_df_true = remove_other_index(test_df,filter_true_index)\n",
    "test_df_false = remove_other_index(test_df,filter_false_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3983c5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "11e4d12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lines_count(df):\n",
    "    line_counts = []\n",
    "    for i in range(len(df)):\n",
    "        string = df.loc[i]['new_code_raw']\n",
    "        line_count = len(string.split('\\n'))\n",
    "        line_counts.append(line_count)\n",
    "    df['line_counts'] = line_counts\n",
    "    return df\n",
    "test_df_true = get_lines_count(test_df_true)\n",
    "test_df_false = get_lines_count(test_df_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef5ae8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e42afc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_true = test_df_true\n",
    "df_clean_false = test_df_false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cf598e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = torch.load('save_GCBmodel.pt',map_location=torch.device('cuda:0'))\n",
    "model = torch.load('D:/BERT_learing/CCDP/for_captum/save_model/save_GCBmodel.pt',map_location=torch.device('cpu'))\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d76cca9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1+cpu\n",
      "None\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())  #输出为True，则安装无误\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "db0b8ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "aba07f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"D:/BERT_learing/code_comment_inconsistency_detection/graphcodebert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ea322f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaEmbeddings(\n",
       "  (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "  (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "  (token_type_embeddings): Embedding(1, 768)\n",
       "  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.roberta.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "db6de6fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaLayer(\n",
       "  (attention): RobertaAttention(\n",
       "    (self): RobertaSelfAttention(\n",
       "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (output): RobertaSelfOutput(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (intermediate): RobertaIntermediate(\n",
       "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    (intermediate_act_fn): GELUActivation()\n",
       "  )\n",
       "  (output): RobertaOutput(\n",
       "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.roberta.encoder.layer[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e79e32eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_embeddings = model.get_input_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ca9012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f64e8e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c241dc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict和squad_pos_forward_func可以合成一个\n",
    "def predict(inputs, position_ids=None, attention_mask=None):\n",
    "    output = model(inputs,\n",
    "                   position_ids=position_ids,\n",
    "                  attention_mask=attention_mask )\n",
    "    \n",
    "    prediction = output.logits\n",
    "    prediction_1 = nn.functional.softmax(prediction, dim=1)\n",
    "    prediction = prediction_1.max(1).values\n",
    "    out = torch.argmax(prediction_1, dim=-1)\n",
    "    # prediction：每个输入样本的最大预测概率。\n",
    "    # out：预测的类别标签。\n",
    "    # prediction_1：所有类别的预测概率。    \n",
    "    return prediction,out,prediction_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c4de032c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squad_pos_forward_func(inputs,position_ids=None, attention_mask=None, position=0):\n",
    "    pred ,_,_= predict(inputs,\n",
    "                     position_ids=position_ids,\n",
    "                   attention_mask=attention_mask)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7c1bd6f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 0)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_token_id = tokenizer.pad_token_id # 0\n",
    "sep_token_id = tokenizer.sep_token_id # 101\n",
    "cls_token_id = tokenizer.cls_token_id # 102\n",
    "ref_token_id,sep_token_id,cls_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "63d48d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意长度\n",
    "def truncate(ids,len_tru = 512):\n",
    "    return ids[:len_tru] if len(ids) > len_tru else ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8206c991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这是单个数据的处理方式，应该要想数据集应该怎么处理\n",
    "def construct_input_ref_pair(comment,AST_type,  ref_token_id, sep_token_id, cls_token_id):\n",
    "    comment = tokenizer.encode(comment, add_special_tokens=False,truncation=True,max_length=512)\n",
    "    AST_type = tokenizer.encode(AST_type, add_special_tokens=False,truncation=True,max_length=512)\n",
    "    # construct input token ids\n",
    "    input_ids = [cls_token_id] + comment + [sep_token_id] + AST_type + [sep_token_id]\n",
    "\n",
    "    # construct reference token ids \n",
    "    ref_input_ids = [cls_token_id] + [ref_token_id] * len(comment) + [sep_token_id] + \\\n",
    "        [ref_token_id] * len(AST_type) + [sep_token_id]\n",
    "    input_ids = truncate(input_ids)\n",
    "    ref_input_ids = truncate(ref_input_ids)\n",
    "    return torch.tensor([input_ids], device=device), torch.tensor([ref_input_ids], device=device), len(comment)\n",
    "\n",
    "def construct_input_ref_token_type_pair(input_ids, sep_ind=0):\n",
    "    seq_len = input_ids.size(1)\n",
    "    token_type_ids = torch.tensor([[0 if i <= sep_ind else 1 for i in range(seq_len)]], device=device)\n",
    "    ref_token_type_ids = torch.zeros_like(token_type_ids, device=device)# * -1\n",
    "    return token_type_ids, ref_token_type_ids\n",
    "\n",
    "def construct_input_ref_pos_id_pair(input_ids):\n",
    "    seq_length = input_ids.size(1)\n",
    "    position_ids = torch.arange(seq_length, dtype=torch.long, device=device)\n",
    "    # we could potentially also use random permutation with `torch.randperm(seq_length, device=device)`\n",
    "    ref_position_ids = torch.zeros(seq_length, dtype=torch.long, device=device)\n",
    "\n",
    "    position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "    ref_position_ids = ref_position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "    return position_ids, ref_position_ids\n",
    "\n",
    "def construct_attention_mask(input_ids):\n",
    "    return torch.ones_like(input_ids)\n",
    "\n",
    "def construct_whole_bert_embeddings(input_ids, ref_input_ids, \\\n",
    "                                    token_type_ids=None, ref_token_type_ids=None, \\\n",
    "                                    position_ids=None, ref_position_ids=None):\n",
    "    input_embeddings = model.roberta.embeddings(input_ids, token_type_ids=token_type_ids, position_ids=position_ids)\n",
    "    ref_input_embeddings = model.roberta.embeddings(ref_input_ids, token_type_ids=ref_token_type_ids, position_ids=ref_position_ids)\n",
    "    \n",
    "    return input_embeddings, ref_input_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0582b7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_data_list(AST_list,comment_list):\n",
    "    input_ids_all = []\n",
    "    ref_input_ids_all = []\n",
    "    position_ids_all = []\n",
    "    attention_mask_all = []\n",
    "    token_type_ids_all = []\n",
    "    all_tokens_all = []\n",
    "    for i in range(len(AST_list)):\n",
    "        input_ids, ref_input_ids, comment_len = construct_input_ref_pair(comment_list[i],AST_list[i], ref_token_id,\\\n",
    "                                                                         sep_token_id, cls_token_id)\n",
    "        token_type_ids, ref_token_type_ids = construct_input_ref_token_type_pair(input_ids, comment_len)\n",
    "        position_ids, ref_position_ids = construct_input_ref_pos_id_pair(input_ids)\n",
    "        attention_mask = construct_attention_mask(input_ids)\n",
    "        \n",
    "        indices = input_ids[0].detach().tolist()\n",
    "        \n",
    "        all_tokens = []                                       ###\n",
    "        for _, token in enumerate(indices):\n",
    "            all_tokens.append(tokenizer.decode([token]))\n",
    "        \n",
    "        input_ids_all.append(input_ids)\n",
    "        ref_input_ids_all.append(ref_input_ids)\n",
    "        position_ids_all.append(position_ids)\n",
    "        attention_mask_all.append(attention_mask)\n",
    "        token_type_ids_all.append(token_type_ids)\n",
    "        all_tokens_all.append(all_tokens)\n",
    "\n",
    "    return input_ids_all,ref_input_ids_all,position_ids_all,attention_mask_all,token_type_ids_all,all_tokens_all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a4cabf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f1094ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前k个贡献最高的word 和 token_type 和 position\n",
    "# return value为归因贡献值  indices为词对应的索引  top_tokens为 词或位置或token_type\n",
    "def get_topk_attributed_tokens(attrs,all_token_t, k=5):\n",
    "    values_max, indices_max = torch.topk(attrs, k)\n",
    "    top_tokens_max = [all_token_t[idx] for idx in indices_max]\n",
    "    values_min, indices_min = torch.topk(attrs, k, largest=False)\n",
    "    top_tokens_min = [all_token_t[idx] for idx in indices_min] \n",
    "    \n",
    "    return top_tokens_max, values_max, indices_max,top_tokens_min,values_min,indices_min\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f1c77cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def split_punctuation(s):\n",
    "    # 使用正则表达式匹配连续的标点符号或者字母和标点符号之间的位置\n",
    "    splits = re.finditer(r'(?<=\\w)(?=[{}])|(?<=[{}])(?=\\w)'.format(string.punctuation, string.punctuation), s)\n",
    "    \n",
    "    # 获取所有分割位置\n",
    "    split_positions = [match.start() for match in splits]\n",
    "    \n",
    "    # 在分割位置插入空格\n",
    "    for pos in reversed(split_positions):\n",
    "        s = s[:pos] + ' ' + s[pos:]\n",
    "        \n",
    "    s = s.replace(\"< s >\", \"<s>\")\n",
    "    s = s.replace(\"</ s >\", \"</s>\")\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6453886d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从 all_tokens 还原为 原单词 ，并且计算归因值\n",
    "def get_restore_words(code,comment,input_ids,all_tokens,attribution_num):\n",
    "    all_tokens_decode = tokenizer.decode(input_ids)\n",
    "    len_all_tokens_decode = len(all_tokens_decode) + 4\n",
    "    # 使用decode获得的序列，去掉分词之后的空格    例 ' a' -> 'a'\n",
    "    all_tokens_clean = []\n",
    "    for token in all_tokens:\n",
    "        s_without_leading_space = token.lstrip()\n",
    "        all_tokens_clean.append(s_without_leading_space)\n",
    "#     print('all_tokens_clean:\\n',all_tokens_clean)\n",
    "#     print('all_tokens_clean:\\n',len(all_tokens_clean))\n",
    "    \n",
    "\n",
    "    # 获得 code_comment_baseline\n",
    "    code = tokenizer.encode(code, add_special_tokens=False,truncation=True,max_length=512)\n",
    "    comment = tokenizer.encode(comment, add_special_tokens=False,truncation=True,max_length=512)\n",
    "    code_decode = tokenizer.decode(code)\n",
    "    comment_decode = tokenizer.decode(comment)\n",
    "    \n",
    "    code_comment_baseline = tokenizer.decode(tokenizer.cls_token_id) + ' '+ comment_decode \\\n",
    "                            + ' '+ tokenizer.decode(tokenizer.sep_token_id) + ' ' + code_decode \\\n",
    "                            + ' ' + tokenizer.decode(tokenizer.sep_token_id)\n",
    "    \n",
    "    code_comment_baseline = code_comment_baseline[:len_all_tokens_decode]\n",
    "    code_comment_baseline = split_punctuation(code_comment_baseline)\n",
    "    code_comment_baseline = code_comment_baseline.split()\n",
    "\n",
    "#     print('code_comment_baseline:\\n',code_comment_baseline)\n",
    "#     print('code_comment_baseline_len:\\n',len(code_comment_baseline))\n",
    "\n",
    "    \n",
    "    # 获得 相邻有几个token合并在一块的列表times  为了以后再计算attribute时求和\n",
    "    times = []\n",
    "    token_index = 0\n",
    "    for code_comment in code_comment_baseline:\n",
    "        temp = ''\n",
    "        time = 0\n",
    "        while temp != code_comment:\n",
    "            temp = temp + all_tokens_clean[token_index]\n",
    "            token_index = token_index + 1\n",
    "            time = time + 1\n",
    "        times.append(time)\n",
    "#     print('times:\\n',times)\n",
    "    \n",
    "    attribute_sum = []\n",
    "    start = 0\n",
    "    for time in times:\n",
    "        end = start + time\n",
    "        attribute = sum(attribution_num[start:end]) / time\n",
    "        attribute_sum.append(attribute)\n",
    "        start = end\n",
    "#     print('attribute_sum:\\n',attribute_sum)\n",
    "    return code_comment_baseline ,attribute_sum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ea788594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_line_code_and_attribute(code,code_all_tokens,attributions_num):\n",
    "    # 特殊符号前  加空格\n",
    "    code = split_punctuation(code)\n",
    "    \n",
    "    # 把  行前空格去掉  便于单词与行之间匹配\n",
    "    code = [line.lstrip() for line in code.splitlines()]\n",
    "    code = '\\n'.join(code)  \n",
    "    code_lineList = code.split('\\n')\n",
    "    code_lineList = [' '.join(x.split()) for x in code_lineList]\n",
    "    # 有空行，把空行去掉\n",
    "    code_lineList = [item for item in code_lineList if item != '']\n",
    "    \n",
    "    attribute = []\n",
    "    i = 0  \n",
    "    for code_line in code_lineList:\n",
    "        count = 0\n",
    "        if i < len(code_all_tokens):\n",
    "            temp = code_all_tokens[i]\n",
    "            attr = attributions_num[i]\n",
    "            i = i + 1\n",
    "        while((i < len(code_all_tokens)) and(temp != code_line)):\n",
    "            attr = attr + attributions_num[i]\n",
    "            temp = temp + ' ' + code_all_tokens[i]\n",
    "            i = i + 1\n",
    "            count = count + 1\n",
    "        attribute.append(attr/count)\n",
    "\n",
    "    return code_lineList,attribute   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1432edfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_before_and_including(lst, element):\n",
    "    if element in lst:\n",
    "        index = lst.index(element)\n",
    "        lst_c = lst[index+1:]\n",
    "        if element in lst_c:\n",
    "            lst_c.remove(element)\n",
    "        return lst_c\n",
    "    else:\n",
    "        return lst\n",
    "    \n",
    "def remove_after_including(lst, element):\n",
    "    if element in lst:\n",
    "        index = lst.index(element)\n",
    "        return lst[:index + 1]\n",
    "    else:\n",
    "        return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8635954e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_all_attribute(code,all_tokens,attributions_num):\n",
    "    # 删除 all_token 列表中的<s>注释</s>  </s>\n",
    "    code_all_tokens = remove_before_and_including(all_tokens,'</s>')\n",
    "    comment_all_tokens = remove_after_including(all_tokens,'</s>')  \n",
    "    index = all_tokens.index('</s>')\n",
    "    attribute_comment = attributions_num[:index+1]\n",
    "#     print(attribute_comment)\n",
    "    \n",
    "    attribute_code = attributions_num[index+1:-1]\n",
    "#     print(attribute_code,len(attribute_code))\n",
    "    code_lineList_token,attribute_num_code = get_line_code_and_attribute(code,code_all_tokens,attribute_code)\n",
    "##     print(attribute_num_code)\n",
    "    attribute_num_code = torch.stack(attribute_num_code)\n",
    "    \n",
    "    new_all_tokens = comment_all_tokens + code_lineList_token\n",
    "    attributions_num_all = torch.cat((attribute_comment, attribute_num_code))\n",
    "\n",
    "#     attributions_num_all = attribute_comment + attribute_num_code\n",
    "#     print(len(attribute_comment),len(attribute_num_code))\n",
    "#     print(new_all_tokens)\n",
    "    return new_all_tokens,attributions_num_all,code_lineList_token,attribute_num_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "544b9b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 只要最大的\n",
    "def get_topk_attributed_tokens(attrs,all_token_t, k=10):\n",
    "    values_max, indices_max = torch.topk(attrs, k)\n",
    "    top_tokens_max = [all_token_t[idx] for idx in indices_max]\n",
    "    \n",
    "    return top_tokens_max, values_max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450e5303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "25d196c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import LayerIntegratedGradients\n",
    "from captum.attr import visualization as viz\n",
    "\n",
    "lig = LayerIntegratedGradients(squad_pos_forward_func,input_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "36fd7f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_sentence_2(code,comment,input_ids,ref_input_ids, token_type_ids,\\\n",
    "                         position_ids, attention_mask,  ground_lable,all_tokens,vis_data_records):\n",
    "    \n",
    "    pre ,out,_ = predict(input_ids,  position_ids=position_ids,attention_mask=attention_mask)\n",
    "    \n",
    "    if out == 1:\n",
    "        sen_type = 'Inconsistency'\n",
    "    else:\n",
    "        sen_type = 'Consistency'\n",
    "    pre = pre.item()\n",
    "    pre = \"{:.3f}\".format(pre)\n",
    "    pre = float(pre) \n",
    "    \n",
    "    attributions_ig, delta_ig = lig.attribute(input_ids, baselines=ref_input_ids,\\\n",
    "                           additional_forward_args=(position_ids,attention_mask,0),return_convergence_delta=True,internal_batch_size=8)\n",
    "    attributions = attributions_ig.sum(dim=2).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "\n",
    "    try:\n",
    "        all_tokens ,attributions = get_restore_words(code,comment,input_ids[0],all_tokens,attributions)     # 合并为一个单词\n",
    "        attributions = torch.tensor(attributions)\n",
    "\n",
    "        # code_lineList_token 和 attribute_num_code 用于后续统计分析\n",
    "        new_all_tokens,attributions_num_all,code_lineList_token,attribute_num_code = final_all_attribute(code,all_tokens,attributions)\n",
    "        \n",
    "        add_attributions_to_visualizer(attributions_num_all, new_all_tokens, pre, ground_lable, sen_type, delta_ig, vis_data_records)\n",
    "        \n",
    "#         top_tokens_max, values_max,top_tokens_min,\\\n",
    "#         values_min = get_topk_attributed_tokens(attributions_num_all,new_all_tokens)\n",
    "\n",
    "        return new_all_tokens\n",
    "    except Exception as e:\n",
    "        print(\"解析错误\")\n",
    "        return _\n",
    "\n",
    "def add_attributions_to_visualizer(attributions, all_tokens, pre, ground_lable, sen_type, delta, vis_data_records):\n",
    "    # storing couple samples in an array for visualization purposes\n",
    "    vis_data_records.append(viz.VisualizationDataRecord(\n",
    "                            attributions,\n",
    "                            pre,\n",
    "                            sen_type,\n",
    "                            ground_lable,\n",
    "                            sen_type,\n",
    "                            attributions.sum(),\n",
    "                            all_tokens,\n",
    "                            delta))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b26fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ef3ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d82ffcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_line_attribution(df):\n",
    "    code_list = df['new_code_raw']\n",
    "    comment_list = df['old_comment_raw']\n",
    "    ground_lable = df['label']\n",
    "    \n",
    "    input_ids_all,ref_input_ids_all,position_ids_all,attention_mask_all,\\\n",
    "    token_type_ids_all,all_tokens_all= input_data_list(code_list,comment_list)\n",
    "    \n",
    "    viz_list = []   \n",
    "    batch_size = 10\n",
    "    for i in range(0, len(code_list), batch_size): \n",
    "        temp_code_list = code_list[i:i + batch_size]    \n",
    "        temp_comment_list = comment_list[i:i + batch_size]\n",
    "        temp_input_ids_all = input_ids_all[i:i + batch_size]\n",
    "        temp_ref_input_ids_all = ref_input_ids_all[i:i + batch_size]\n",
    "        temp_token_type_ids_all = token_type_ids_all[i:i + batch_size]\n",
    "        temp_position_ids_all = position_ids_all[i:i + batch_size]\n",
    "        temp_attention_mask_all = attention_mask_all[i:i + batch_size]\n",
    "        temp_ground_lable = ground_lable[i:i + batch_size]\n",
    "        temp_all_tokens_all = all_tokens_all[i:i + batch_size]\n",
    "        \n",
    "        vis_data_records_ig = []\n",
    "        for l in range(len(temp_code_list)):\n",
    "            new_all_tokens  = interpret_sentence_2(temp_code_list[l],          temp_comment_list[l],\\\n",
    "                                                   temp_input_ids_all[l],      temp_ref_input_ids_all[l],\\\n",
    "                                                   temp_token_type_ids_all[l], temp_position_ids_all[l],\\\n",
    "                                                   temp_attention_mask_all[l], temp_ground_lable[l],\\\n",
    "                                                   temp_all_tokens_all[l],     vis_data_records_ig)\n",
    "        viz_list.append(vis_data_records_ig)\n",
    "            \n",
    "    return viz_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19b1183",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da08c9a0",
   "metadata": {},
   "source": [
    "true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8c211d88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "viz_list_true = analyse_line_attribution(df_clean_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "eaec1819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 应该等于  len(df_clean_true) / batch_size(10) 向上取整\n",
    "len(df_clean_true),len(viz_list_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "449ad5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<captum.attr._utils.visualization.VisualizationDataRecord at 0x239681c5540>,\n",
       "  <captum.attr._utils.visualization.VisualizationDataRecord at 0x2395c83ec20>,\n",
       "  <captum.attr._utils.visualization.VisualizationDataRecord at 0x2395c83f0a0>,\n",
       "  <captum.attr._utils.visualization.VisualizationDataRecord at 0x239681c43a0>]]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viz_list_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "65aa0216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualize attributions based on Integrated Gradients\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>Consistency (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>Consistency</b></text></td><td><text style=\"padding-right:2em\"><b>inf</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #s                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Check                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> whether                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> any                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> insertion                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> or                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> deletion                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> actions                    </font></mark><mark style=\"background-color: hsl(0, 75%, 85%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> are                    </font></mark><mark style=\"background-color: hsl(0, 75%, 82%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> currently                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> queued                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #/s                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> public boolean areInsertionsOrDeletionsQueued () {                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> return ( insertions . size () > 0 || ! unresolvedInsertions . isEmpty () || deletions . size () > 0 );                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> }                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>Consistency (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>Consistency</b></text></td><td><text style=\"padding-right:2em\"><b>inf</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #s                    </font></mark><mark style=\"background-color: hsl(120, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Returns                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> list                    </font></mark><mark style=\"background-color: hsl(0, 75%, 80%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 85%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> types                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> fields                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> given                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> struct                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> type                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #/s                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> public static List < RelDataType > getFieldTypeList ( final RelDataType type ) {                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> return Lists . transform ( type . getFieldList (), GET _ TYPE );                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> }                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>Consistency (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>Consistency</b></text></td><td><text style=\"padding-right:2em\"><b>inf</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #s                    </font></mark><mark style=\"background-color: hsl(120, 75%, 58%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> This                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> method                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> initializes                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> txtPattern                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #/s                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> public ZapTextField getTxtPattern () {                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> if ( txtPattern == null ) {                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> txtPattern = new ZapTextField ();                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> }                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> return txtPattern ;                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> }                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>Consistency (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>Consistency</b></text></td><td><text style=\"padding-right:2em\"><b>inf</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #s                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> HBase                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> region                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> cut                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> size                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(0, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> GB                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #/s                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> public float getKylinHBaseRegionCut () {                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> return Float . valueOf ( getOptional (\" kylin . hbase . region . cut \", \" 5 . 0 \"));                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> }                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(0, len(viz_list_true)): \n",
    "    print('Visualize attributions based on Integrated Gradients')\n",
    "    _ = viz.visualize_text(viz_list_true[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fdb1c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0223f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f883fae0",
   "metadata": {},
   "source": [
    "false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b493fb12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2e2a8ea8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "viz_list_false = analyse_line_attribution(df_clean_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2c079aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 应该等于  len(df_clean_false) / batch_size(10) 向上取整\n",
    "len(df_clean_false),len(viz_list_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "60809103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualize attributions based on Integrated Gradients\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>Inconsistency (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>Inconsistency</b></text></td><td><text style=\"padding-right:2em\"><b>inf</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #s                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Construct                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> value                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> data                    </font></mark><mark style=\"background-color: hsl(120, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> attribute                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> CloudEvents                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #/s                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> public Struct ceDataAttribute () {                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> return recordParser . data ();                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> }                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>Consistency (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>Consistency</b></text></td><td><text style=\"padding-right:2em\"><b>-inf</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #s                    </font></mark><mark style=\"background-color: hsl(120, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Returns                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #/s                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> public File getSinkFile () {                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> return queue . file ();                    </font></mark><mark style=\"background-color: hsl(0, 75%, 60%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> }                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>Consistency (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>Consistency</b></text></td><td><text style=\"padding-right:2em\"><b>-inf</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #s                    </font></mark><mark style=\"background-color: hsl(0, 75%, 73%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Build                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Ravioli                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> client                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #/s                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> public Lob build () {                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> return new Lob ( this );                    </font></mark><mark style=\"background-color: hsl(0, 75%, 60%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> }                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(0, len(viz_list_false)): \n",
    "    print('Visualize attributions based on Integrated Gradients')\n",
    "    _ = viz.visualize_text(viz_list_false[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea7cd31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0b05c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leitx",
   "language": "python",
   "name": "leitx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
