{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ad6ca09",
   "metadata": {},
   "source": [
    "此 .ipynb为按照行级进行分析可解释性的过程 , 最终显示行级的代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e84e3fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "\n",
    "\n",
    "from captum.attr import visualization as viz\n",
    "from captum.attr import LayerConductance, LayerIntegratedGradients\n",
    "from captum.attr import configure_interpretable_embedding_layer, remove_interpretable_embedding_layer\n",
    "\n",
    "# 解决服务器挂掉的问题\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff062613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device( \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf31e07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 1024\n",
    "MAX_EPOCHS = 10\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 1e-5\n",
    "NUM_CLASSES = 2\n",
    "WEIGTH_DECAY = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b8e3dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_test_data():\n",
    "    test_param = pd.read_json(\"D:/BERT_learing/code_comment_inconsistency_detection/data/param/test.json\")\n",
    "    test_return = pd.read_json(\"D:/BERT_learing/code_comment_inconsistency_detection/data/return/test.json\")\n",
    "    test_summary = pd.read_json(\"D:/BERT_learing/code_comment_inconsistency_detection/data/summary/test.json\")\n",
    "    test_df = pd.concat([test_summary,test_param, test_return], axis=0)\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "    test_df = test_df[:5]\n",
    "    return test_df\n",
    "test_df = retrieve_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11e4d12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>comment_type</th>\n",
       "      <th>old_comment_raw</th>\n",
       "      <th>old_comment_subtokens</th>\n",
       "      <th>new_comment_raw</th>\n",
       "      <th>new_comment_subtokens</th>\n",
       "      <th>span_minimal_diff_comment_subtokens</th>\n",
       "      <th>old_code_raw</th>\n",
       "      <th>old_code_subtokens</th>\n",
       "      <th>new_code_raw</th>\n",
       "      <th>new_code_subtokens</th>\n",
       "      <th>span_diff_code_subtokens</th>\n",
       "      <th>token_diff_code_subtokens</th>\n",
       "      <th>line_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apache_calcite-896-FirstSentence-0</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Creates elastic node as single member of a clu...</td>\n",
       "      <td>[creates, elastic, node, as, single, member, o...</td>\n",
       "      <td>Creates an instance with existing settings</td>\n",
       "      <td>[creates, an, instance, with, existing, settings]</td>\n",
       "      <td>[&lt;REPLACE_OLD&gt;, elastic, node, as, single, mem...</td>\n",
       "      <td>public static EmbeddedElasticsearchNode crea...</td>\n",
       "      <td>[public, static, embedded, elasticsearch, node...</td>\n",
       "      <td>private static EmbeddedElasticsearchNode cre...</td>\n",
       "      <td>[private, static, embedded, elasticsearch, nod...</td>\n",
       "      <td>[&lt;REPLACE_OLD&gt;, public, &lt;REPLACE_NEW&gt;, private...</td>\n",
       "      <td>[&lt;REPLACE_OLD&gt;, public, &lt;REPLACE_NEW&gt;, private...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hibernate_hibernate_orm-1601-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Check whether any insertion or deletion action...</td>\n",
       "      <td>[check, whether, any, insertion, or, deletion,...</td>\n",
       "      <td>Check whether any insertion or deletion action...</td>\n",
       "      <td>[check, whether, any, insertion, or, deletion,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>\\tpublic boolean areInsertionsOrDeletionsQueue...</td>\n",
       "      <td>[public, boolean, are, insertions, or, deletio...</td>\n",
       "      <td>\\tpublic boolean areInsertionsOrDeletionsQueue...</td>\n",
       "      <td>[public, boolean, are, insertions, or, deletio...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, boolean, are, insertions, or,...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, boolean, &lt;KEEP&gt;, are,...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apache_giraph-33-Associations-FirstSentence</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Marshal the aggregator values of to a JSONArra...</td>\n",
       "      <td>[marshal, the, aggregator, values, of, to, a, ...</td>\n",
       "      <td>Marshal the aggregator values of the worker to...</td>\n",
       "      <td>[marshal, the, aggregator, values, of, the, wo...</td>\n",
       "      <td>[&lt;INSERT_OLD_KEEP_BEFORE&gt;, of, &lt;INSERT_NEW_KEE...</td>\n",
       "      <td>private JSONArray marshalAggregatorValues(lo...</td>\n",
       "      <td>[private, jsonarray, marshal, aggregator, valu...</td>\n",
       "      <td>private byte[] marshalAggregatorValues(long ...</td>\n",
       "      <td>[private, byte, [, ], marshal, aggregator, val...</td>\n",
       "      <td>[&lt;KEEP&gt;, private, &lt;KEEP_END&gt;, &lt;REPLACE_OLD&gt;, j...</td>\n",
       "      <td>[&lt;KEEP&gt;, private, &lt;REPLACE_OLD&gt;, jsonarray, &lt;R...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apache_calcite-677-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Returns a list of the types of the fields in a...</td>\n",
       "      <td>[returns, a, list, of, the, types, of, the, fi...</td>\n",
       "      <td>Returns a list of the types of the fields in a...</td>\n",
       "      <td>[returns, a, list, of, the, types, of, the, fi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>public static List&lt;RelDataType&gt; getFieldType...</td>\n",
       "      <td>[public, static, list, &lt;, rel, data, type, &gt;, ...</td>\n",
       "      <td>public static List&lt;RelDataType&gt; getFieldType...</td>\n",
       "      <td>[public, static, list, &lt;, rel, data, type, &gt;, ...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, list, &lt;, rel, data, t...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;KEEP&gt;, list,...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apache_calcite-315-Associations-FirstSentence</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Create an instance based on current maven prof...</td>\n",
       "      <td>[create, an, instance, based, on, current, mav...</td>\n",
       "      <td>Creates an instance based on current maven pro...</td>\n",
       "      <td>[creates, an, instance, based, on, current, ma...</td>\n",
       "      <td>[&lt;REPLACE_OLD&gt;, create, &lt;REPLACE_NEW&gt;, creates...</td>\n",
       "      <td>static MongoDatabaseRule create() {\\n    fin...</td>\n",
       "      <td>[static, mongo, database, rule, create, (, ), ...</td>\n",
       "      <td>static MongoDatabasePolicy create() {\\n    f...</td>\n",
       "      <td>[static, mongo, database, policy, create, (, )...</td>\n",
       "      <td>[&lt;KEEP&gt;, static, mongo, database, &lt;KEEP_END&gt;, ...</td>\n",
       "      <td>[&lt;KEEP&gt;, static, &lt;KEEP&gt;, mongo, &lt;KEEP&gt;, databa...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              id  label comment_type  \\\n",
       "0             apache_calcite-896-FirstSentence-0      1      Summary   \n",
       "1   hibernate_hibernate_orm-1601-FirstSentence-0      0      Summary   \n",
       "2    apache_giraph-33-Associations-FirstSentence      1      Summary   \n",
       "3             apache_calcite-677-FirstSentence-0      0      Summary   \n",
       "4  apache_calcite-315-Associations-FirstSentence      1      Summary   \n",
       "\n",
       "                                     old_comment_raw  \\\n",
       "0  Creates elastic node as single member of a clu...   \n",
       "1  Check whether any insertion or deletion action...   \n",
       "2  Marshal the aggregator values of to a JSONArra...   \n",
       "3  Returns a list of the types of the fields in a...   \n",
       "4  Create an instance based on current maven prof...   \n",
       "\n",
       "                               old_comment_subtokens  \\\n",
       "0  [creates, elastic, node, as, single, member, o...   \n",
       "1  [check, whether, any, insertion, or, deletion,...   \n",
       "2  [marshal, the, aggregator, values, of, to, a, ...   \n",
       "3  [returns, a, list, of, the, types, of, the, fi...   \n",
       "4  [create, an, instance, based, on, current, mav...   \n",
       "\n",
       "                                     new_comment_raw  \\\n",
       "0         Creates an instance with existing settings   \n",
       "1  Check whether any insertion or deletion action...   \n",
       "2  Marshal the aggregator values of the worker to...   \n",
       "3  Returns a list of the types of the fields in a...   \n",
       "4  Creates an instance based on current maven pro...   \n",
       "\n",
       "                               new_comment_subtokens  \\\n",
       "0  [creates, an, instance, with, existing, settings]   \n",
       "1  [check, whether, any, insertion, or, deletion,...   \n",
       "2  [marshal, the, aggregator, values, of, the, wo...   \n",
       "3  [returns, a, list, of, the, types, of, the, fi...   \n",
       "4  [creates, an, instance, based, on, current, ma...   \n",
       "\n",
       "                 span_minimal_diff_comment_subtokens  \\\n",
       "0  [<REPLACE_OLD>, elastic, node, as, single, mem...   \n",
       "1                                                 []   \n",
       "2  [<INSERT_OLD_KEEP_BEFORE>, of, <INSERT_NEW_KEE...   \n",
       "3                                                 []   \n",
       "4  [<REPLACE_OLD>, create, <REPLACE_NEW>, creates...   \n",
       "\n",
       "                                        old_code_raw  \\\n",
       "0    public static EmbeddedElasticsearchNode crea...   \n",
       "1  \\tpublic boolean areInsertionsOrDeletionsQueue...   \n",
       "2    private JSONArray marshalAggregatorValues(lo...   \n",
       "3    public static List<RelDataType> getFieldType...   \n",
       "4    static MongoDatabaseRule create() {\\n    fin...   \n",
       "\n",
       "                                  old_code_subtokens  \\\n",
       "0  [public, static, embedded, elasticsearch, node...   \n",
       "1  [public, boolean, are, insertions, or, deletio...   \n",
       "2  [private, jsonarray, marshal, aggregator, valu...   \n",
       "3  [public, static, list, <, rel, data, type, >, ...   \n",
       "4  [static, mongo, database, rule, create, (, ), ...   \n",
       "\n",
       "                                        new_code_raw  \\\n",
       "0    private static EmbeddedElasticsearchNode cre...   \n",
       "1  \\tpublic boolean areInsertionsOrDeletionsQueue...   \n",
       "2    private byte[] marshalAggregatorValues(long ...   \n",
       "3    public static List<RelDataType> getFieldType...   \n",
       "4    static MongoDatabasePolicy create() {\\n    f...   \n",
       "\n",
       "                                  new_code_subtokens  \\\n",
       "0  [private, static, embedded, elasticsearch, nod...   \n",
       "1  [public, boolean, are, insertions, or, deletio...   \n",
       "2  [private, byte, [, ], marshal, aggregator, val...   \n",
       "3  [public, static, list, <, rel, data, type, >, ...   \n",
       "4  [static, mongo, database, policy, create, (, )...   \n",
       "\n",
       "                            span_diff_code_subtokens  \\\n",
       "0  [<REPLACE_OLD>, public, <REPLACE_NEW>, private...   \n",
       "1  [<KEEP>, public, boolean, are, insertions, or,...   \n",
       "2  [<KEEP>, private, <KEEP_END>, <REPLACE_OLD>, j...   \n",
       "3  [<KEEP>, public, static, list, <, rel, data, t...   \n",
       "4  [<KEEP>, static, mongo, database, <KEEP_END>, ...   \n",
       "\n",
       "                           token_diff_code_subtokens  line_counts  \n",
       "0  [<REPLACE_OLD>, public, <REPLACE_NEW>, private...            6  \n",
       "1  [<KEEP>, public, <KEEP>, boolean, <KEEP>, are,...            4  \n",
       "2  [<KEEP>, private, <REPLACE_OLD>, jsonarray, <R...           28  \n",
       "3  [<KEEP>, public, <KEEP>, static, <KEEP>, list,...            4  \n",
       "4  [<KEEP>, static, <KEEP>, mongo, <KEEP>, databa...           16  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_lines_count(df):\n",
    "    line_counts = []\n",
    "    for i in range(len(df)):\n",
    "        string = df.loc[i]['new_code_raw']\n",
    "        line_count = len(string.split('\\n'))\n",
    "        line_counts.append(line_count)\n",
    "    df['line_counts'] = line_counts\n",
    "    return df\n",
    "test_df = get_lines_count(test_df)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef5ae8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e42afc18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>comment_type</th>\n",
       "      <th>old_comment_raw</th>\n",
       "      <th>old_comment_subtokens</th>\n",
       "      <th>new_comment_raw</th>\n",
       "      <th>new_comment_subtokens</th>\n",
       "      <th>span_minimal_diff_comment_subtokens</th>\n",
       "      <th>old_code_raw</th>\n",
       "      <th>old_code_subtokens</th>\n",
       "      <th>new_code_raw</th>\n",
       "      <th>new_code_subtokens</th>\n",
       "      <th>span_diff_code_subtokens</th>\n",
       "      <th>token_diff_code_subtokens</th>\n",
       "      <th>line_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apache_calcite-896-FirstSentence-0</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Creates elastic node as single member of a clu...</td>\n",
       "      <td>[creates, elastic, node, as, single, member, o...</td>\n",
       "      <td>Creates an instance with existing settings</td>\n",
       "      <td>[creates, an, instance, with, existing, settings]</td>\n",
       "      <td>[&lt;REPLACE_OLD&gt;, elastic, node, as, single, mem...</td>\n",
       "      <td>public static EmbeddedElasticsearchNode crea...</td>\n",
       "      <td>[public, static, embedded, elasticsearch, node...</td>\n",
       "      <td>private static EmbeddedElasticsearchNode cre...</td>\n",
       "      <td>[private, static, embedded, elasticsearch, nod...</td>\n",
       "      <td>[&lt;REPLACE_OLD&gt;, public, &lt;REPLACE_NEW&gt;, private...</td>\n",
       "      <td>[&lt;REPLACE_OLD&gt;, public, &lt;REPLACE_NEW&gt;, private...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hibernate_hibernate_orm-1601-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Check whether any insertion or deletion action...</td>\n",
       "      <td>[check, whether, any, insertion, or, deletion,...</td>\n",
       "      <td>Check whether any insertion or deletion action...</td>\n",
       "      <td>[check, whether, any, insertion, or, deletion,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>\\tpublic boolean areInsertionsOrDeletionsQueue...</td>\n",
       "      <td>[public, boolean, are, insertions, or, deletio...</td>\n",
       "      <td>\\tpublic boolean areInsertionsOrDeletionsQueue...</td>\n",
       "      <td>[public, boolean, are, insertions, or, deletio...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, boolean, are, insertions, or,...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, boolean, &lt;KEEP&gt;, are,...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apache_giraph-33-Associations-FirstSentence</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Marshal the aggregator values of to a JSONArra...</td>\n",
       "      <td>[marshal, the, aggregator, values, of, to, a, ...</td>\n",
       "      <td>Marshal the aggregator values of the worker to...</td>\n",
       "      <td>[marshal, the, aggregator, values, of, the, wo...</td>\n",
       "      <td>[&lt;INSERT_OLD_KEEP_BEFORE&gt;, of, &lt;INSERT_NEW_KEE...</td>\n",
       "      <td>private JSONArray marshalAggregatorValues(lo...</td>\n",
       "      <td>[private, jsonarray, marshal, aggregator, valu...</td>\n",
       "      <td>private byte[] marshalAggregatorValues(long ...</td>\n",
       "      <td>[private, byte, [, ], marshal, aggregator, val...</td>\n",
       "      <td>[&lt;KEEP&gt;, private, &lt;KEEP_END&gt;, &lt;REPLACE_OLD&gt;, j...</td>\n",
       "      <td>[&lt;KEEP&gt;, private, &lt;REPLACE_OLD&gt;, jsonarray, &lt;R...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apache_calcite-677-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Returns a list of the types of the fields in a...</td>\n",
       "      <td>[returns, a, list, of, the, types, of, the, fi...</td>\n",
       "      <td>Returns a list of the types of the fields in a...</td>\n",
       "      <td>[returns, a, list, of, the, types, of, the, fi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>public static List&lt;RelDataType&gt; getFieldType...</td>\n",
       "      <td>[public, static, list, &lt;, rel, data, type, &gt;, ...</td>\n",
       "      <td>public static List&lt;RelDataType&gt; getFieldType...</td>\n",
       "      <td>[public, static, list, &lt;, rel, data, type, &gt;, ...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, list, &lt;, rel, data, t...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;KEEP&gt;, list,...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apache_calcite-315-Associations-FirstSentence</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Create an instance based on current maven prof...</td>\n",
       "      <td>[create, an, instance, based, on, current, mav...</td>\n",
       "      <td>Creates an instance based on current maven pro...</td>\n",
       "      <td>[creates, an, instance, based, on, current, ma...</td>\n",
       "      <td>[&lt;REPLACE_OLD&gt;, create, &lt;REPLACE_NEW&gt;, creates...</td>\n",
       "      <td>static MongoDatabaseRule create() {\\n    fin...</td>\n",
       "      <td>[static, mongo, database, rule, create, (, ), ...</td>\n",
       "      <td>static MongoDatabasePolicy create() {\\n    f...</td>\n",
       "      <td>[static, mongo, database, policy, create, (, )...</td>\n",
       "      <td>[&lt;KEEP&gt;, static, mongo, database, &lt;KEEP_END&gt;, ...</td>\n",
       "      <td>[&lt;KEEP&gt;, static, &lt;KEEP&gt;, mongo, &lt;KEEP&gt;, databa...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              id  label comment_type  \\\n",
       "0             apache_calcite-896-FirstSentence-0      1      Summary   \n",
       "1   hibernate_hibernate_orm-1601-FirstSentence-0      0      Summary   \n",
       "2    apache_giraph-33-Associations-FirstSentence      1      Summary   \n",
       "3             apache_calcite-677-FirstSentence-0      0      Summary   \n",
       "4  apache_calcite-315-Associations-FirstSentence      1      Summary   \n",
       "\n",
       "                                     old_comment_raw  \\\n",
       "0  Creates elastic node as single member of a clu...   \n",
       "1  Check whether any insertion or deletion action...   \n",
       "2  Marshal the aggregator values of to a JSONArra...   \n",
       "3  Returns a list of the types of the fields in a...   \n",
       "4  Create an instance based on current maven prof...   \n",
       "\n",
       "                               old_comment_subtokens  \\\n",
       "0  [creates, elastic, node, as, single, member, o...   \n",
       "1  [check, whether, any, insertion, or, deletion,...   \n",
       "2  [marshal, the, aggregator, values, of, to, a, ...   \n",
       "3  [returns, a, list, of, the, types, of, the, fi...   \n",
       "4  [create, an, instance, based, on, current, mav...   \n",
       "\n",
       "                                     new_comment_raw  \\\n",
       "0         Creates an instance with existing settings   \n",
       "1  Check whether any insertion or deletion action...   \n",
       "2  Marshal the aggregator values of the worker to...   \n",
       "3  Returns a list of the types of the fields in a...   \n",
       "4  Creates an instance based on current maven pro...   \n",
       "\n",
       "                               new_comment_subtokens  \\\n",
       "0  [creates, an, instance, with, existing, settings]   \n",
       "1  [check, whether, any, insertion, or, deletion,...   \n",
       "2  [marshal, the, aggregator, values, of, the, wo...   \n",
       "3  [returns, a, list, of, the, types, of, the, fi...   \n",
       "4  [creates, an, instance, based, on, current, ma...   \n",
       "\n",
       "                 span_minimal_diff_comment_subtokens  \\\n",
       "0  [<REPLACE_OLD>, elastic, node, as, single, mem...   \n",
       "1                                                 []   \n",
       "2  [<INSERT_OLD_KEEP_BEFORE>, of, <INSERT_NEW_KEE...   \n",
       "3                                                 []   \n",
       "4  [<REPLACE_OLD>, create, <REPLACE_NEW>, creates...   \n",
       "\n",
       "                                        old_code_raw  \\\n",
       "0    public static EmbeddedElasticsearchNode crea...   \n",
       "1  \\tpublic boolean areInsertionsOrDeletionsQueue...   \n",
       "2    private JSONArray marshalAggregatorValues(lo...   \n",
       "3    public static List<RelDataType> getFieldType...   \n",
       "4    static MongoDatabaseRule create() {\\n    fin...   \n",
       "\n",
       "                                  old_code_subtokens  \\\n",
       "0  [public, static, embedded, elasticsearch, node...   \n",
       "1  [public, boolean, are, insertions, or, deletio...   \n",
       "2  [private, jsonarray, marshal, aggregator, valu...   \n",
       "3  [public, static, list, <, rel, data, type, >, ...   \n",
       "4  [static, mongo, database, rule, create, (, ), ...   \n",
       "\n",
       "                                        new_code_raw  \\\n",
       "0    private static EmbeddedElasticsearchNode cre...   \n",
       "1  \\tpublic boolean areInsertionsOrDeletionsQueue...   \n",
       "2    private byte[] marshalAggregatorValues(long ...   \n",
       "3    public static List<RelDataType> getFieldType...   \n",
       "4    static MongoDatabasePolicy create() {\\n    f...   \n",
       "\n",
       "                                  new_code_subtokens  \\\n",
       "0  [private, static, embedded, elasticsearch, nod...   \n",
       "1  [public, boolean, are, insertions, or, deletio...   \n",
       "2  [private, byte, [, ], marshal, aggregator, val...   \n",
       "3  [public, static, list, <, rel, data, type, >, ...   \n",
       "4  [static, mongo, database, policy, create, (, )...   \n",
       "\n",
       "                            span_diff_code_subtokens  \\\n",
       "0  [<REPLACE_OLD>, public, <REPLACE_NEW>, private...   \n",
       "1  [<KEEP>, public, boolean, are, insertions, or,...   \n",
       "2  [<KEEP>, private, <KEEP_END>, <REPLACE_OLD>, j...   \n",
       "3  [<KEEP>, public, static, list, <, rel, data, t...   \n",
       "4  [<KEEP>, static, mongo, database, <KEEP_END>, ...   \n",
       "\n",
       "                           token_diff_code_subtokens  line_counts  \n",
       "0  [<REPLACE_OLD>, public, <REPLACE_NEW>, private...            6  \n",
       "1  [<KEEP>, public, <KEEP>, boolean, <KEEP>, are,...            4  \n",
       "2  [<KEEP>, private, <REPLACE_OLD>, jsonarray, <R...           28  \n",
       "3  [<KEEP>, public, <KEEP>, static, <KEEP>, list,...            4  \n",
       "4  [<KEEP>, static, <KEEP>, mongo, <KEEP>, databa...           16  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = test_df\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c90c464d",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_list = df_clean['new_code_raw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db25cdb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  private static EmbeddedElasticsearchNode create(Settings settings) {\\n    // ensure PainlessPlugin is installed or otherwise scripted fields would not work\\n    Node node = new LocalNode(settings, Arrays.asList(Netty4Plugin.class, PainlessPlugin.class));\\n    return new EmbeddedElasticsearchNode(node);\\n  }\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcd1d3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8fa6eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  private static EmbeddedElasticsearchNode create(Settings settings) {\\n    // ensure PainlessPlugin is installed or otherwise scripted fields would not work\\n    Node node = new LocalNode(settings, Arrays.asList(Netty4Plugin.class, PainlessPlugin.class));\\n    return new EmbeddedElasticsearchNode(node);\\n  }\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.loc[0]['new_code_raw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2095c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf598e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = torch.load('save_GCBmodel.pt',map_location=torch.device('cuda:0'))\n",
    "model = torch.load('D:/BERT_learing/CCDP/for_captum/save_model/save_GCBmodel.pt',map_location=torch.device('cpu'))\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d76cca9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1+cpu\n",
      "None\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())  #输出为True，则安装无误\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db0b8ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aba07f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"D:/BERT_learing/code_comment_inconsistency_detection/graphcodebert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea322f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaEmbeddings(\n",
       "  (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "  (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "  (token_type_embeddings): Embedding(1, 768)\n",
       "  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.roberta.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db6de6fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaLayer(\n",
       "  (attention): RobertaAttention(\n",
       "    (self): RobertaSelfAttention(\n",
       "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (output): RobertaSelfOutput(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (intermediate): RobertaIntermediate(\n",
       "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    (intermediate_act_fn): GELUActivation()\n",
       "  )\n",
       "  (output): RobertaOutput(\n",
       "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.roberta.encoder.layer[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e79e32eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_embeddings = model.get_input_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ca9012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f64e8e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c241dc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict和squad_pos_forward_func可以合成一个\n",
    "def predict(inputs, position_ids=None, attention_mask=None):\n",
    "    output = model(inputs,\n",
    "                   position_ids=position_ids,\n",
    "                  attention_mask=attention_mask )\n",
    "    \n",
    "    prediction = output.logits\n",
    "    prediction_1 = nn.functional.softmax(prediction, dim=1)\n",
    "    prediction = prediction_1.max(1).values\n",
    "    out = torch.argmax(prediction_1, dim=-1)\n",
    "    # prediction：每个输入样本的最大预测概率。\n",
    "    # out：预测的类别标签。\n",
    "    # prediction_1：所有类别的预测概率。    \n",
    "    return prediction,out,prediction_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4de032c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squad_pos_forward_func(inputs,position_ids=None, attention_mask=None, position=0):\n",
    "    pred ,_,_= predict(inputs,\n",
    "                     position_ids=position_ids,\n",
    "                   attention_mask=attention_mask)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c1bd6f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_token_id = tokenizer.pad_token_id # 0\n",
    "sep_token_id = tokenizer.sep_token_id # 101\n",
    "cls_token_id = tokenizer.cls_token_id # 102\n",
    "ref_token_id,sep_token_id,cls_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63d48d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意长度\n",
    "def truncate(ids,len_tru = 512):\n",
    "    return ids[:len_tru] if len(ids) > len_tru else ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8206c991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这是单个数据的处理方式，应该要想数据集应该怎么处理\n",
    "def construct_input_ref_pair(comment,AST_type,  ref_token_id, sep_token_id, cls_token_id):\n",
    "    comment = tokenizer.encode(comment, add_special_tokens=False,truncation=True,max_length=512)\n",
    "    AST_type = tokenizer.encode(AST_type, add_special_tokens=False,truncation=True,max_length=512)\n",
    "    # construct input token ids\n",
    "    input_ids = [cls_token_id] + comment + [sep_token_id] + AST_type + [sep_token_id]\n",
    "\n",
    "    # construct reference token ids \n",
    "    ref_input_ids = [cls_token_id] + [ref_token_id] * len(comment) + [sep_token_id] + \\\n",
    "        [ref_token_id] * len(AST_type) + [sep_token_id]\n",
    "    input_ids = truncate(input_ids)\n",
    "    ref_input_ids = truncate(ref_input_ids)\n",
    "    return torch.tensor([input_ids], device=device), torch.tensor([ref_input_ids], device=device), len(comment)\n",
    "\n",
    "def construct_input_ref_token_type_pair(input_ids, sep_ind=0):\n",
    "    seq_len = input_ids.size(1)\n",
    "    token_type_ids = torch.tensor([[0 if i <= sep_ind else 1 for i in range(seq_len)]], device=device)\n",
    "    ref_token_type_ids = torch.zeros_like(token_type_ids, device=device)# * -1\n",
    "    return token_type_ids, ref_token_type_ids\n",
    "\n",
    "def construct_input_ref_pos_id_pair(input_ids):\n",
    "    seq_length = input_ids.size(1)\n",
    "    position_ids = torch.arange(seq_length, dtype=torch.long, device=device)\n",
    "    # we could potentially also use random permutation with `torch.randperm(seq_length, device=device)`\n",
    "    ref_position_ids = torch.zeros(seq_length, dtype=torch.long, device=device)\n",
    "\n",
    "    position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "    ref_position_ids = ref_position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "    return position_ids, ref_position_ids\n",
    "\n",
    "def construct_attention_mask(input_ids):\n",
    "    return torch.ones_like(input_ids)\n",
    "\n",
    "def construct_whole_bert_embeddings(input_ids, ref_input_ids, \\\n",
    "                                    token_type_ids=None, ref_token_type_ids=None, \\\n",
    "                                    position_ids=None, ref_position_ids=None):\n",
    "    input_embeddings = model.roberta.embeddings(input_ids, token_type_ids=token_type_ids, position_ids=position_ids)\n",
    "    ref_input_embeddings = model.roberta.embeddings(ref_input_ids, token_type_ids=ref_token_type_ids, position_ids=ref_position_ids)\n",
    "    \n",
    "    return input_embeddings, ref_input_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0582b7a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1c77cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def split_punctuation(s):\n",
    "    # 使用正则表达式匹配连续的标点符号或者字母和标点符号之间的位置\n",
    "    splits = re.finditer(r'(?<=\\w)(?=[{}])|(?<=[{}])(?=\\w)'.format(string.punctuation, string.punctuation), s)\n",
    "    \n",
    "    # 获取所有分割位置\n",
    "    split_positions = [match.start() for match in splits]\n",
    "    \n",
    "    # 在分割位置插入空格\n",
    "    for pos in reversed(split_positions):\n",
    "        s = s[:pos] + ' ' + s[pos:]\n",
    "        \n",
    "    s = s.replace(\"< s >\", \"<s>\")\n",
    "    s = s.replace(\"</ s >\", \"</s>\")\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6453886d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从 all_tokens 还原为 原单词 ，并且计算归因值\n",
    "def get_restore_words(code,comment,input_ids,all_tokens,attribution_num):\n",
    "    all_tokens_decode = tokenizer.decode(input_ids)\n",
    "    len_all_tokens_decode = len(all_tokens_decode) + 4\n",
    "    # 使用decode获得的序列，去掉分词之后的空格    例 ' a' -> 'a'\n",
    "    all_tokens_clean = []\n",
    "    for token in all_tokens:\n",
    "        s_without_leading_space = token.lstrip()\n",
    "        all_tokens_clean.append(s_without_leading_space)\n",
    "#     print('all_tokens_clean:\\n',all_tokens_clean)\n",
    "#     print('all_tokens_clean:\\n',len(all_tokens_clean))\n",
    "    \n",
    "\n",
    "    # 获得 code_comment_baseline\n",
    "    code = tokenizer.encode(code, add_special_tokens=False,truncation=True,max_length=512)\n",
    "    comment = tokenizer.encode(comment, add_special_tokens=False,truncation=True,max_length=512)\n",
    "    code_decode = tokenizer.decode(code)\n",
    "    comment_decode = tokenizer.decode(comment)\n",
    "    \n",
    "    code_comment_baseline = tokenizer.decode(tokenizer.cls_token_id) + ' '+ comment_decode \\\n",
    "                            + ' '+ tokenizer.decode(tokenizer.sep_token_id) + ' ' + code_decode \\\n",
    "                            + ' ' + tokenizer.decode(tokenizer.sep_token_id)\n",
    "    \n",
    "    code_comment_baseline = code_comment_baseline[:len_all_tokens_decode]\n",
    "    code_comment_baseline = split_punctuation(code_comment_baseline)\n",
    "    code_comment_baseline = code_comment_baseline.split()\n",
    "\n",
    "#     print('code_comment_baseline:\\n',code_comment_baseline)\n",
    "#     print('code_comment_baseline_len:\\n',len(code_comment_baseline))\n",
    "\n",
    "    \n",
    "    # 获得 相邻有几个token合并在一块的列表times  为了以后再计算attribute时求和\n",
    "    times = []\n",
    "    token_index = 0\n",
    "    for code_comment in code_comment_baseline:\n",
    "        temp = ''\n",
    "        time = 0\n",
    "        while temp != code_comment:\n",
    "            temp = temp + all_tokens_clean[token_index]\n",
    "            token_index = token_index + 1\n",
    "            time = time + 1\n",
    "        times.append(time)\n",
    "#     print('times:\\n',times)\n",
    "    \n",
    "    attribute_sum = []\n",
    "    start = 0\n",
    "    for time in times:\n",
    "        end = start + time\n",
    "        attribute = sum(attribution_num[start:end]) / time\n",
    "        attribute_sum.append(attribute)\n",
    "        start = end\n",
    "#     print('attribute_sum:\\n',attribute_sum)\n",
    "    return code_comment_baseline ,attribute_sum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea788594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_line_code_and_attribute(code,code_all_tokens,attributions_num):\n",
    "    # 特殊符号前  加空格\n",
    "    code = split_punctuation(code)\n",
    "    \n",
    "    # 把  行前空格去掉  便于单词与行之间匹配\n",
    "    code = [line.lstrip() for line in code.splitlines()]\n",
    "    code = '\\n'.join(code)  \n",
    "    code_lineList = code.split('\\n')\n",
    "    code_lineList = [' '.join(x.split()) for x in code_lineList]\n",
    "    # 有空行，把空行去掉\n",
    "    code_lineList = [item for item in code_lineList if item != '']\n",
    "    \n",
    "    attribute = []\n",
    "    i = 0  \n",
    "    for code_line in code_lineList:\n",
    "        count = 0\n",
    "        if i < len(code_all_tokens):\n",
    "            temp = code_all_tokens[i]\n",
    "            attr = attributions_num[i]\n",
    "            i = i + 1\n",
    "        while((i < len(code_all_tokens)) and(temp != code_line)):\n",
    "            attr = attr + attributions_num[i]\n",
    "            temp = temp + ' ' + code_all_tokens[i]\n",
    "            i = i + 1\n",
    "            count = count + 1\n",
    "        attribute.append(attr/count)\n",
    "\n",
    "    return code_lineList,attribute   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1432edfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_before_and_including(lst, element):\n",
    "    if element in lst:\n",
    "        index = lst.index(element)\n",
    "        lst_c = lst[index+1:]\n",
    "        if element in lst_c:\n",
    "            lst_c.remove(element)\n",
    "        return lst_c\n",
    "    else:\n",
    "        return lst\n",
    "    \n",
    "def remove_after_including(lst, element):\n",
    "    if element in lst:\n",
    "        index = lst.index(element)\n",
    "        return lst[:index + 1]\n",
    "    else:\n",
    "        return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8635954e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_all_attribute(code,all_tokens,attributions_num):\n",
    "    # 删除 all_token 列表中的<s>注释</s>  </s>\n",
    "    code_all_tokens = remove_before_and_including(all_tokens,'</s>')\n",
    "    comment_all_tokens = remove_after_including(all_tokens,'</s>')  \n",
    "    index = all_tokens.index('</s>')\n",
    "    attribute_comment = attributions_num[:index+1]\n",
    "#     print(attribute_comment)\n",
    "    \n",
    "    attribute_code = attributions_num[index+1:-1]\n",
    "#     print(attribute_code,len(attribute_code))\n",
    "    code_lineList_token,attribute_num_code = get_line_code_and_attribute(code,code_all_tokens,attribute_code)\n",
    "##     print(attribute_num_code)\n",
    "    attribute_num_code = torch.stack(attribute_num_code)\n",
    "    \n",
    "    new_all_tokens = comment_all_tokens + code_lineList_token\n",
    "    attributions_num_all = torch.cat((attribute_comment, attribute_num_code))\n",
    "\n",
    "#     attributions_num_all = attribute_comment + attribute_num_code\n",
    "#     print(len(attribute_comment),len(attribute_num_code))\n",
    "#     print(new_all_tokens)\n",
    "    return new_all_tokens,attributions_num_all,code_lineList_token,attribute_num_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c57a30a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "450e5303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def perturb_func(inputs):\n",
    "    # 创建一个与输入相同形状的扰动张量，初始值为0\n",
    "    perturbation = torch.zeros_like(inputs)\n",
    "    \n",
    "    # 对于不等于0, 1, 2的元素，进行上下扰动\n",
    "    mask = (inputs != 0) & (inputs != 1) & (inputs != 2)\n",
    "    perturbation[mask] = torch.randint_like(inputs[mask], low=-1, high=2)\n",
    "    \n",
    "    # 生成扰动后的输入\n",
    "    perturbed_inputs = inputs + perturbation\n",
    "    return perturbed_inputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "25d196c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import LayerIntegratedGradients\n",
    "from captum.attr import visualization as viz\n",
    "from captum.metrics import infidelity\n",
    "from captum.metrics import sensitivity_max\n",
    "\n",
    "\n",
    "lig = LayerIntegratedGradients(squad_pos_forward_func,input_embeddings)\n",
    "\n",
    "vis_data_records_ig = []\n",
    "\n",
    "def interpret_sentence(code,comment,old_code,input_ids,ref_input_ids, token_type_ids,\\\n",
    "                       position_ids, attention_mask, all_tokens, ground_lable,vis_data_records):\n",
    "    pre ,out,_ = predict(input_ids, position_ids=position_ids,attention_mask=attention_mask)\n",
    "    if out == 1:\n",
    "        sen_type = 'pos'\n",
    "    else:\n",
    "        sen_type = 'nag'\n",
    "    pre = pre.item()\n",
    "    pre = \"{:.3f}\".format(pre)\n",
    "    pre = float(pre) \n",
    "    pre ,sen_type\n",
    "    \n",
    "    attributions_ig, delta_ig = lig.attribute(input_ids, baselines=ref_input_ids,\\\n",
    "                           additional_forward_args=(position_ids,attention_mask,0),return_convergence_delta=True,internal_batch_size=8)\n",
    "    \n",
    "    attributions = attributions_ig.sum(dim=2).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "    \n",
    "###########################################################################################################################################\n",
    "    # 准确性\n",
    "    # 计算 Infidelity\n",
    "    infidelity_score = infidelity(squad_pos_forward_func, perturb_func, input_ids, attributions)\n",
    "    print(f\"Infidelity: {infidelity_score.item()}\")\n",
    "    \n",
    "    # 稳定性\n",
    "    # 计算 Max-Sensitivity\n",
    "    max_sensitivity_score = sensitivity_max(squad_pos_forward_func, input_ids, attributions)\n",
    "    print(f\"Max-Sensitivity: {max_sensitivity_score.item()}\")\n",
    "###########################################################################################################################################\n",
    "\n",
    "    all_tokens ,attributions = get_restore_words(code,comment,input_ids[0],all_tokens,attributions)     # 合并为一个单词\n",
    "    attributions = torch.tensor(attributions)\n",
    "    print(all_tokens)\n",
    "    new_all_tokens,attributions_num_all,code_lineList_token,attribute_num_code= final_all_attribute(code,all_tokens,attributions)\n",
    "    \n",
    "\n",
    "    return code,old_code,code_lineList_token,attribute_num_code\n",
    "\n",
    "def add_attributions_to_visualizer(attributions, all_tokens, pre, ground_lable, sen_type, delta, vis_data_records):\n",
    "\n",
    "    # storing couple samples in an array for visualization purposes\n",
    "    vis_data_records.append(viz.VisualizationDataRecord(\n",
    "                            attributions,\n",
    "                            pre,\n",
    "                            pre,\n",
    "                            ground_lable,\n",
    "                            sen_type,\n",
    "                            attributions.sum(),\n",
    "                            all_tokens,\n",
    "                            delta))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "3b270703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_sentence_2(code,comment,old_code,input_ids,ref_input_ids, token_type_ids,\\\n",
    "                         position_ids, attention_mask, all_tokens, ground_lable,vis_data_records):\n",
    "    pre ,out,_ = predict(input_ids,  position_ids=position_ids,attention_mask=attention_mask)\n",
    "    if out == 1:\n",
    "        sen_type = 'pos'\n",
    "    else:\n",
    "        sen_type = 'nag'\n",
    "    pre = pre.item()\n",
    "    pre = \"{:.3f}\".format(pre)\n",
    "    pre = float(pre) \n",
    "    pre ,sen_type\n",
    "    \n",
    "    attributions_ig, delta_ig = lig.attribute(input_ids, baselines=ref_input_ids,\\\n",
    "                           additional_forward_args=(position_ids,attention_mask,0),return_convergence_delta=True,internal_batch_size=8)\n",
    "    attributions = attributions_ig.sum(dim=2).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "\n",
    "###########################################################################################################################################\n",
    "    # 准确性\n",
    "    # 计算 Infidelity\n",
    "    attributions_copy = attributions.unsqueeze(0)\n",
    "\n",
    "    # Calculate infidelity and sensitivity_max\n",
    "    \n",
    "#     infid = infidelity(squad_pos_forward_func, perturb_func,input_ids, attributions_copy)\n",
    "#     print(f\"Infidelity: {infid.item()}\")\n",
    "    print(input_ids)\n",
    "    # 稳定性\n",
    "    # 计算 Max-Sensitivity\n",
    "    sens_max = sensitivity_max(lig.attribute(input_ids, baselines=ref_input_ids,\\\n",
    "                                            additional_forward_args=(position_ids,attention_mask,0),\\\n",
    "                                            return_convergence_delta=True,internal_batch_size=8), \\\n",
    "                               input_ids,perturb_func=perturb_func)\n",
    "    print(f\"Max-Sensitivity: {sens_max.item()}\")\n",
    "###########################################################################################################################################\n",
    "   \n",
    "    try:\n",
    "        all_tokens ,attributions = get_restore_words(code,comment,input_ids[0],all_tokens,attributions)     # 合并为一个单词\n",
    "        attributions = torch.tensor(attributions)\n",
    "\n",
    "        new_all_tokens,attributions_num_all,code_lineList_token,attribute_num_code = final_all_attribute(code,all_tokens,attributions)\n",
    "\n",
    "        return code,old_code,code_lineList_token,attribute_num_code\n",
    "    except Exception as e:\n",
    "        print(\"解析错误\")\n",
    "        return _,_,_,_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a44b49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "8e0e4a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tpublic boolean areInsertionsOrDeletionsQueued() {\n",
      "\t\treturn ( insertions.size() > 0 || ! unresolvedInsertions.isEmpty() || deletions.size() > 0 );\n",
      "\t}\n",
      "\n",
      "Check whether any insertion or deletion actions are currently queued.\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "AST_list = df_clean['new_code_raw']\n",
    "\n",
    "AST_list_old = df_clean['old_code_raw']\n",
    "\n",
    "comment_list = df_clean['old_comment_raw']\n",
    "\n",
    "ground_lable = df_clean['label']\n",
    "\n",
    "print(AST_list[1])\n",
    "print(comment_list[1])\n",
    "print(ground_lable[1])\n",
    "\n",
    "def input_data_list(AST_list,comment_list):\n",
    "    input_ids_all = []\n",
    "    ref_input_ids_all = []\n",
    "    position_ids_all = []\n",
    "    attention_mask_all = []\n",
    "    token_type_ids_all = []\n",
    "    all_tokens_all = []\n",
    "    for i in range(len(AST_list)):\n",
    "        input_ids, ref_input_ids, comment_len = construct_input_ref_pair(comment_list[i],AST_list[i], ref_token_id,\\\n",
    "                                                                         sep_token_id, cls_token_id)\n",
    "        token_type_ids, ref_token_type_ids = construct_input_ref_token_type_pair(input_ids, comment_len)\n",
    "        position_ids, ref_position_ids = construct_input_ref_pos_id_pair(input_ids)\n",
    "        attention_mask = construct_attention_mask(input_ids)\n",
    "        \n",
    "        indices = input_ids[0].detach().tolist()\n",
    "        \n",
    "        all_tokens = []                                       ###\n",
    "        for _, token in enumerate(indices):\n",
    "            all_tokens.append(tokenizer.decode([token]))\n",
    "        \n",
    "        input_ids_all.append(input_ids)\n",
    "        ref_input_ids_all.append(ref_input_ids)\n",
    "        position_ids_all.append(position_ids)\n",
    "        attention_mask_all.append(attention_mask)\n",
    "        token_type_ids_all.append(token_type_ids)\n",
    "        all_tokens_all.append(all_tokens)\n",
    "\n",
    "    return input_ids_all,ref_input_ids_all,position_ids_all,attention_mask_all,token_type_ids_all,all_tokens_all \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "41b6ac2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_all,ref_input_ids_all,position_ids_all,\\\n",
    "attention_mask_all,token_type_ids_all,all_tokens_all= input_data_list(AST_list,comment_list)\n",
    "# print(input_ids_all[1])\n",
    "# print(ref_input_ids_all[1])\n",
    "# print(input_ids_all[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65b6821",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0, 42349,   293, 33827, 37908,    25,   881,   919,     9,    10,\n",
      "         18016,     4,     2,  1437,   940, 25156,  6133, 42495,  9682, 11599,\n",
      "         21061, 48271,  1045,  1640, 47718,  9629,    43, 25522, 50118,  1437,\n",
      "          1437,  1437, 21277,  1306, 23689,  1672, 49577,    16,  5923,    50,\n",
      "          3680, 29560,  5447,    74,    45,   173, 50118,  1437,  1437,  1437,\n",
      "         44058, 37908,  5457,    92,  4004, 48271,  1640, 48419,     6,  1586,\n",
      "         24192,     4,   281, 36583,  1640, 15721,  2553,   306, 49577,     4,\n",
      "          4684,     6, 23689,  1672, 49577,     4,  4684, 48749, 50118,  1437,\n",
      "          1437,  1437,   671,    92,  6133, 42495,  9682, 11599, 21061, 48271,\n",
      "          1640, 46840,  4397, 50118,  1437, 35524, 50118,     2]])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(AST_list)):    \n",
    "    code,old_code,_,_ \\\n",
    "    = interpret_sentence_2(AST_list[i],comment_list[i],AST_list_old[i],input_ids_all[i],ref_input_ids_all[i],\\\n",
    "                           token_type_ids_all[i], position_ids_all[i], attention_mask_all[i], all_tokens_all[i],\\\n",
    "                           ground_lable[i],vis_data_records_ig)\n",
    "    print('对比以下代码查看代码更改位置') \n",
    "    print(f'新代码：{code}')\n",
    "    print(f'旧代码代码：{old_code}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33b3c37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7d4398",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Visualize attributions based on Integrated Gradients')\n",
    "_ = viz.visualize_text(vis_data_records_ig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9a9711",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leitx",
   "language": "python",
   "name": "leitx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
