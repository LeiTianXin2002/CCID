{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ad6ca09",
   "metadata": {},
   "source": [
    "此 .ipynb为按照行级，获得预测正确和错误的不同行级元素的贡献值分布。根据统计分析结果。\n",
    "<br>打印出 <br>\n",
    "[('returnstatement', 'return ( insertions . size () > 0 || ! unresolvedInsertions . isEmpty () || deletions . size () > 0 );', tensor(0.0590, dtype=torch.float64)), ('MethodDeclaration', 'public boolean areInsertionsOrDeletionsQueued () {', tensor(0.1059, dtype=torch.float64))]<br>[('行级语句类型','对应的行级语句','贡献值')]<br>\n",
    "1<br>\n",
    "索引<br>\n",
    "根据上述的txt，挑出实例，不用挑太多"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc81ca72",
   "metadata": {},
   "source": [
    "将每个实例中的类别贡献值与统计分析中的绝对值均值进行大小比较，大于绝对值均值的保留"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e84e3fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "\n",
    "\n",
    "from captum.attr import visualization as viz\n",
    "from captum.attr import LayerConductance, LayerIntegratedGradients\n",
    "from captum.attr import configure_interpretable_embedding_layer, remove_interpretable_embedding_layer\n",
    "\n",
    "# 解决服务器挂掉的问题\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ff062613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device( \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bf31e07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 1024\n",
    "MAX_EPOCHS = 10\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 1e-5\n",
    "NUM_CLASSES = 2\n",
    "WEIGTH_DECAY = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3b8e3dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_test_data():\n",
    "    test_param = pd.read_json(\"D:/BERT_learing/code_comment_inconsistency_detection/data/param/test.json\")\n",
    "    test_return = pd.read_json(\"D:/BERT_learing/code_comment_inconsistency_detection/data/return/test.json\")\n",
    "    test_summary = pd.read_json(\"D:/BERT_learing/code_comment_inconsistency_detection/data/summary/test.json\")\n",
    "    test_df = pd.concat([test_summary,test_param, test_return], axis=0)\n",
    "    test_df = test_df[:20]\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "    return test_df\n",
    "test_df = retrieve_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "11e4d12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>comment_type</th>\n",
       "      <th>old_comment_raw</th>\n",
       "      <th>old_comment_subtokens</th>\n",
       "      <th>new_comment_raw</th>\n",
       "      <th>new_comment_subtokens</th>\n",
       "      <th>span_minimal_diff_comment_subtokens</th>\n",
       "      <th>old_code_raw</th>\n",
       "      <th>old_code_subtokens</th>\n",
       "      <th>new_code_raw</th>\n",
       "      <th>new_code_subtokens</th>\n",
       "      <th>span_diff_code_subtokens</th>\n",
       "      <th>token_diff_code_subtokens</th>\n",
       "      <th>line_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apache_calcite-896-FirstSentence-0</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Creates elastic node as single member of a clu...</td>\n",
       "      <td>[creates, elastic, node, as, single, member, o...</td>\n",
       "      <td>Creates an instance with existing settings</td>\n",
       "      <td>[creates, an, instance, with, existing, settings]</td>\n",
       "      <td>[&lt;REPLACE_OLD&gt;, elastic, node, as, single, mem...</td>\n",
       "      <td>public static EmbeddedElasticsearchNode crea...</td>\n",
       "      <td>[public, static, embedded, elasticsearch, node...</td>\n",
       "      <td>private static EmbeddedElasticsearchNode cre...</td>\n",
       "      <td>[private, static, embedded, elasticsearch, nod...</td>\n",
       "      <td>[&lt;REPLACE_OLD&gt;, public, &lt;REPLACE_NEW&gt;, private...</td>\n",
       "      <td>[&lt;REPLACE_OLD&gt;, public, &lt;REPLACE_NEW&gt;, private...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hibernate_hibernate_orm-1601-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Check whether any insertion or deletion action...</td>\n",
       "      <td>[check, whether, any, insertion, or, deletion,...</td>\n",
       "      <td>Check whether any insertion or deletion action...</td>\n",
       "      <td>[check, whether, any, insertion, or, deletion,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>\\tpublic boolean areInsertionsOrDeletionsQueue...</td>\n",
       "      <td>[public, boolean, are, insertions, or, deletio...</td>\n",
       "      <td>\\tpublic boolean areInsertionsOrDeletionsQueue...</td>\n",
       "      <td>[public, boolean, are, insertions, or, deletio...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, boolean, are, insertions, or,...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, boolean, &lt;KEEP&gt;, are,...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apache_giraph-33-Associations-FirstSentence</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Marshal the aggregator values of to a JSONArra...</td>\n",
       "      <td>[marshal, the, aggregator, values, of, to, a, ...</td>\n",
       "      <td>Marshal the aggregator values of the worker to...</td>\n",
       "      <td>[marshal, the, aggregator, values, of, the, wo...</td>\n",
       "      <td>[&lt;INSERT_OLD_KEEP_BEFORE&gt;, of, &lt;INSERT_NEW_KEE...</td>\n",
       "      <td>private JSONArray marshalAggregatorValues(lo...</td>\n",
       "      <td>[private, jsonarray, marshal, aggregator, valu...</td>\n",
       "      <td>private byte[] marshalAggregatorValues(long ...</td>\n",
       "      <td>[private, byte, [, ], marshal, aggregator, val...</td>\n",
       "      <td>[&lt;KEEP&gt;, private, &lt;KEEP_END&gt;, &lt;REPLACE_OLD&gt;, j...</td>\n",
       "      <td>[&lt;KEEP&gt;, private, &lt;REPLACE_OLD&gt;, jsonarray, &lt;R...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apache_calcite-677-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Returns a list of the types of the fields in a...</td>\n",
       "      <td>[returns, a, list, of, the, types, of, the, fi...</td>\n",
       "      <td>Returns a list of the types of the fields in a...</td>\n",
       "      <td>[returns, a, list, of, the, types, of, the, fi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>public static List&lt;RelDataType&gt; getFieldType...</td>\n",
       "      <td>[public, static, list, &lt;, rel, data, type, &gt;, ...</td>\n",
       "      <td>public static List&lt;RelDataType&gt; getFieldType...</td>\n",
       "      <td>[public, static, list, &lt;, rel, data, type, &gt;, ...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, list, &lt;, rel, data, t...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;KEEP&gt;, list,...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apache_calcite-315-Associations-FirstSentence</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Create an instance based on current maven prof...</td>\n",
       "      <td>[create, an, instance, based, on, current, mav...</td>\n",
       "      <td>Creates an instance based on current maven pro...</td>\n",
       "      <td>[creates, an, instance, based, on, current, ma...</td>\n",
       "      <td>[&lt;REPLACE_OLD&gt;, create, &lt;REPLACE_NEW&gt;, creates...</td>\n",
       "      <td>static MongoDatabaseRule create() {\\n    fin...</td>\n",
       "      <td>[static, mongo, database, rule, create, (, ), ...</td>\n",
       "      <td>static MongoDatabasePolicy create() {\\n    f...</td>\n",
       "      <td>[static, mongo, database, policy, create, (, )...</td>\n",
       "      <td>[&lt;KEEP&gt;, static, mongo, database, &lt;KEEP_END&gt;, ...</td>\n",
       "      <td>[&lt;KEEP&gt;, static, &lt;KEEP&gt;, mongo, &lt;KEEP&gt;, databa...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              id  label comment_type  \\\n",
       "0             apache_calcite-896-FirstSentence-0      1      Summary   \n",
       "1   hibernate_hibernate_orm-1601-FirstSentence-0      0      Summary   \n",
       "2    apache_giraph-33-Associations-FirstSentence      1      Summary   \n",
       "3             apache_calcite-677-FirstSentence-0      0      Summary   \n",
       "4  apache_calcite-315-Associations-FirstSentence      1      Summary   \n",
       "\n",
       "                                     old_comment_raw  \\\n",
       "0  Creates elastic node as single member of a clu...   \n",
       "1  Check whether any insertion or deletion action...   \n",
       "2  Marshal the aggregator values of to a JSONArra...   \n",
       "3  Returns a list of the types of the fields in a...   \n",
       "4  Create an instance based on current maven prof...   \n",
       "\n",
       "                               old_comment_subtokens  \\\n",
       "0  [creates, elastic, node, as, single, member, o...   \n",
       "1  [check, whether, any, insertion, or, deletion,...   \n",
       "2  [marshal, the, aggregator, values, of, to, a, ...   \n",
       "3  [returns, a, list, of, the, types, of, the, fi...   \n",
       "4  [create, an, instance, based, on, current, mav...   \n",
       "\n",
       "                                     new_comment_raw  \\\n",
       "0         Creates an instance with existing settings   \n",
       "1  Check whether any insertion or deletion action...   \n",
       "2  Marshal the aggregator values of the worker to...   \n",
       "3  Returns a list of the types of the fields in a...   \n",
       "4  Creates an instance based on current maven pro...   \n",
       "\n",
       "                               new_comment_subtokens  \\\n",
       "0  [creates, an, instance, with, existing, settings]   \n",
       "1  [check, whether, any, insertion, or, deletion,...   \n",
       "2  [marshal, the, aggregator, values, of, the, wo...   \n",
       "3  [returns, a, list, of, the, types, of, the, fi...   \n",
       "4  [creates, an, instance, based, on, current, ma...   \n",
       "\n",
       "                 span_minimal_diff_comment_subtokens  \\\n",
       "0  [<REPLACE_OLD>, elastic, node, as, single, mem...   \n",
       "1                                                 []   \n",
       "2  [<INSERT_OLD_KEEP_BEFORE>, of, <INSERT_NEW_KEE...   \n",
       "3                                                 []   \n",
       "4  [<REPLACE_OLD>, create, <REPLACE_NEW>, creates...   \n",
       "\n",
       "                                        old_code_raw  \\\n",
       "0    public static EmbeddedElasticsearchNode crea...   \n",
       "1  \\tpublic boolean areInsertionsOrDeletionsQueue...   \n",
       "2    private JSONArray marshalAggregatorValues(lo...   \n",
       "3    public static List<RelDataType> getFieldType...   \n",
       "4    static MongoDatabaseRule create() {\\n    fin...   \n",
       "\n",
       "                                  old_code_subtokens  \\\n",
       "0  [public, static, embedded, elasticsearch, node...   \n",
       "1  [public, boolean, are, insertions, or, deletio...   \n",
       "2  [private, jsonarray, marshal, aggregator, valu...   \n",
       "3  [public, static, list, <, rel, data, type, >, ...   \n",
       "4  [static, mongo, database, rule, create, (, ), ...   \n",
       "\n",
       "                                        new_code_raw  \\\n",
       "0    private static EmbeddedElasticsearchNode cre...   \n",
       "1  \\tpublic boolean areInsertionsOrDeletionsQueue...   \n",
       "2    private byte[] marshalAggregatorValues(long ...   \n",
       "3    public static List<RelDataType> getFieldType...   \n",
       "4    static MongoDatabasePolicy create() {\\n    f...   \n",
       "\n",
       "                                  new_code_subtokens  \\\n",
       "0  [private, static, embedded, elasticsearch, nod...   \n",
       "1  [public, boolean, are, insertions, or, deletio...   \n",
       "2  [private, byte, [, ], marshal, aggregator, val...   \n",
       "3  [public, static, list, <, rel, data, type, >, ...   \n",
       "4  [static, mongo, database, policy, create, (, )...   \n",
       "\n",
       "                            span_diff_code_subtokens  \\\n",
       "0  [<REPLACE_OLD>, public, <REPLACE_NEW>, private...   \n",
       "1  [<KEEP>, public, boolean, are, insertions, or,...   \n",
       "2  [<KEEP>, private, <KEEP_END>, <REPLACE_OLD>, j...   \n",
       "3  [<KEEP>, public, static, list, <, rel, data, t...   \n",
       "4  [<KEEP>, static, mongo, database, <KEEP_END>, ...   \n",
       "\n",
       "                           token_diff_code_subtokens  line_counts  \n",
       "0  [<REPLACE_OLD>, public, <REPLACE_NEW>, private...            6  \n",
       "1  [<KEEP>, public, <KEEP>, boolean, <KEEP>, are,...            4  \n",
       "2  [<KEEP>, private, <REPLACE_OLD>, jsonarray, <R...           28  \n",
       "3  [<KEEP>, public, <KEEP>, static, <KEEP>, list,...            4  \n",
       "4  [<KEEP>, static, <KEEP>, mongo, <KEEP>, databa...           16  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_lines_count(df):\n",
    "    line_counts = []\n",
    "    for i in range(len(df)):\n",
    "        string = df.loc[i]['new_code_raw']\n",
    "        line_count = len(string.split('\\n'))\n",
    "        line_counts.append(line_count)\n",
    "    df['line_counts'] = line_counts\n",
    "    return df\n",
    "test_df = get_lines_count(test_df)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef5ae8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e42afc18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>comment_type</th>\n",
       "      <th>old_comment_raw</th>\n",
       "      <th>old_comment_subtokens</th>\n",
       "      <th>new_comment_raw</th>\n",
       "      <th>new_comment_subtokens</th>\n",
       "      <th>span_minimal_diff_comment_subtokens</th>\n",
       "      <th>old_code_raw</th>\n",
       "      <th>old_code_subtokens</th>\n",
       "      <th>new_code_raw</th>\n",
       "      <th>new_code_subtokens</th>\n",
       "      <th>span_diff_code_subtokens</th>\n",
       "      <th>token_diff_code_subtokens</th>\n",
       "      <th>line_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apache_calcite-896-FirstSentence-0</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Creates elastic node as single member of a clu...</td>\n",
       "      <td>[creates, elastic, node, as, single, member, o...</td>\n",
       "      <td>Creates an instance with existing settings</td>\n",
       "      <td>[creates, an, instance, with, existing, settings]</td>\n",
       "      <td>[&lt;REPLACE_OLD&gt;, elastic, node, as, single, mem...</td>\n",
       "      <td>public static EmbeddedElasticsearchNode crea...</td>\n",
       "      <td>[public, static, embedded, elasticsearch, node...</td>\n",
       "      <td>private static EmbeddedElasticsearchNode cre...</td>\n",
       "      <td>[private, static, embedded, elasticsearch, nod...</td>\n",
       "      <td>[&lt;REPLACE_OLD&gt;, public, &lt;REPLACE_NEW&gt;, private...</td>\n",
       "      <td>[&lt;REPLACE_OLD&gt;, public, &lt;REPLACE_NEW&gt;, private...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hibernate_hibernate_orm-1601-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Check whether any insertion or deletion action...</td>\n",
       "      <td>[check, whether, any, insertion, or, deletion,...</td>\n",
       "      <td>Check whether any insertion or deletion action...</td>\n",
       "      <td>[check, whether, any, insertion, or, deletion,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>\\tpublic boolean areInsertionsOrDeletionsQueue...</td>\n",
       "      <td>[public, boolean, are, insertions, or, deletio...</td>\n",
       "      <td>\\tpublic boolean areInsertionsOrDeletionsQueue...</td>\n",
       "      <td>[public, boolean, are, insertions, or, deletio...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, boolean, are, insertions, or,...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, boolean, &lt;KEEP&gt;, are,...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apache_giraph-33-Associations-FirstSentence</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Marshal the aggregator values of to a JSONArra...</td>\n",
       "      <td>[marshal, the, aggregator, values, of, to, a, ...</td>\n",
       "      <td>Marshal the aggregator values of the worker to...</td>\n",
       "      <td>[marshal, the, aggregator, values, of, the, wo...</td>\n",
       "      <td>[&lt;INSERT_OLD_KEEP_BEFORE&gt;, of, &lt;INSERT_NEW_KEE...</td>\n",
       "      <td>private JSONArray marshalAggregatorValues(lo...</td>\n",
       "      <td>[private, jsonarray, marshal, aggregator, valu...</td>\n",
       "      <td>private byte[] marshalAggregatorValues(long ...</td>\n",
       "      <td>[private, byte, [, ], marshal, aggregator, val...</td>\n",
       "      <td>[&lt;KEEP&gt;, private, &lt;KEEP_END&gt;, &lt;REPLACE_OLD&gt;, j...</td>\n",
       "      <td>[&lt;KEEP&gt;, private, &lt;REPLACE_OLD&gt;, jsonarray, &lt;R...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apache_calcite-677-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Returns a list of the types of the fields in a...</td>\n",
       "      <td>[returns, a, list, of, the, types, of, the, fi...</td>\n",
       "      <td>Returns a list of the types of the fields in a...</td>\n",
       "      <td>[returns, a, list, of, the, types, of, the, fi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>public static List&lt;RelDataType&gt; getFieldType...</td>\n",
       "      <td>[public, static, list, &lt;, rel, data, type, &gt;, ...</td>\n",
       "      <td>public static List&lt;RelDataType&gt; getFieldType...</td>\n",
       "      <td>[public, static, list, &lt;, rel, data, type, &gt;, ...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, list, &lt;, rel, data, t...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;KEEP&gt;, list,...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apache_calcite-315-Associations-FirstSentence</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Create an instance based on current maven prof...</td>\n",
       "      <td>[create, an, instance, based, on, current, mav...</td>\n",
       "      <td>Creates an instance based on current maven pro...</td>\n",
       "      <td>[creates, an, instance, based, on, current, ma...</td>\n",
       "      <td>[&lt;REPLACE_OLD&gt;, create, &lt;REPLACE_NEW&gt;, creates...</td>\n",
       "      <td>static MongoDatabaseRule create() {\\n    fin...</td>\n",
       "      <td>[static, mongo, database, rule, create, (, ), ...</td>\n",
       "      <td>static MongoDatabasePolicy create() {\\n    f...</td>\n",
       "      <td>[static, mongo, database, policy, create, (, )...</td>\n",
       "      <td>[&lt;KEEP&gt;, static, mongo, database, &lt;KEEP_END&gt;, ...</td>\n",
       "      <td>[&lt;KEEP&gt;, static, &lt;KEEP&gt;, mongo, &lt;KEEP&gt;, databa...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              id  label comment_type  \\\n",
       "0             apache_calcite-896-FirstSentence-0      1      Summary   \n",
       "1   hibernate_hibernate_orm-1601-FirstSentence-0      0      Summary   \n",
       "2    apache_giraph-33-Associations-FirstSentence      1      Summary   \n",
       "3             apache_calcite-677-FirstSentence-0      0      Summary   \n",
       "4  apache_calcite-315-Associations-FirstSentence      1      Summary   \n",
       "\n",
       "                                     old_comment_raw  \\\n",
       "0  Creates elastic node as single member of a clu...   \n",
       "1  Check whether any insertion or deletion action...   \n",
       "2  Marshal the aggregator values of to a JSONArra...   \n",
       "3  Returns a list of the types of the fields in a...   \n",
       "4  Create an instance based on current maven prof...   \n",
       "\n",
       "                               old_comment_subtokens  \\\n",
       "0  [creates, elastic, node, as, single, member, o...   \n",
       "1  [check, whether, any, insertion, or, deletion,...   \n",
       "2  [marshal, the, aggregator, values, of, to, a, ...   \n",
       "3  [returns, a, list, of, the, types, of, the, fi...   \n",
       "4  [create, an, instance, based, on, current, mav...   \n",
       "\n",
       "                                     new_comment_raw  \\\n",
       "0         Creates an instance with existing settings   \n",
       "1  Check whether any insertion or deletion action...   \n",
       "2  Marshal the aggregator values of the worker to...   \n",
       "3  Returns a list of the types of the fields in a...   \n",
       "4  Creates an instance based on current maven pro...   \n",
       "\n",
       "                               new_comment_subtokens  \\\n",
       "0  [creates, an, instance, with, existing, settings]   \n",
       "1  [check, whether, any, insertion, or, deletion,...   \n",
       "2  [marshal, the, aggregator, values, of, the, wo...   \n",
       "3  [returns, a, list, of, the, types, of, the, fi...   \n",
       "4  [creates, an, instance, based, on, current, ma...   \n",
       "\n",
       "                 span_minimal_diff_comment_subtokens  \\\n",
       "0  [<REPLACE_OLD>, elastic, node, as, single, mem...   \n",
       "1                                                 []   \n",
       "2  [<INSERT_OLD_KEEP_BEFORE>, of, <INSERT_NEW_KEE...   \n",
       "3                                                 []   \n",
       "4  [<REPLACE_OLD>, create, <REPLACE_NEW>, creates...   \n",
       "\n",
       "                                        old_code_raw  \\\n",
       "0    public static EmbeddedElasticsearchNode crea...   \n",
       "1  \\tpublic boolean areInsertionsOrDeletionsQueue...   \n",
       "2    private JSONArray marshalAggregatorValues(lo...   \n",
       "3    public static List<RelDataType> getFieldType...   \n",
       "4    static MongoDatabaseRule create() {\\n    fin...   \n",
       "\n",
       "                                  old_code_subtokens  \\\n",
       "0  [public, static, embedded, elasticsearch, node...   \n",
       "1  [public, boolean, are, insertions, or, deletio...   \n",
       "2  [private, jsonarray, marshal, aggregator, valu...   \n",
       "3  [public, static, list, <, rel, data, type, >, ...   \n",
       "4  [static, mongo, database, rule, create, (, ), ...   \n",
       "\n",
       "                                        new_code_raw  \\\n",
       "0    private static EmbeddedElasticsearchNode cre...   \n",
       "1  \\tpublic boolean areInsertionsOrDeletionsQueue...   \n",
       "2    private byte[] marshalAggregatorValues(long ...   \n",
       "3    public static List<RelDataType> getFieldType...   \n",
       "4    static MongoDatabasePolicy create() {\\n    f...   \n",
       "\n",
       "                                  new_code_subtokens  \\\n",
       "0  [private, static, embedded, elasticsearch, nod...   \n",
       "1  [public, boolean, are, insertions, or, deletio...   \n",
       "2  [private, byte, [, ], marshal, aggregator, val...   \n",
       "3  [public, static, list, <, rel, data, type, >, ...   \n",
       "4  [static, mongo, database, policy, create, (, )...   \n",
       "\n",
       "                            span_diff_code_subtokens  \\\n",
       "0  [<REPLACE_OLD>, public, <REPLACE_NEW>, private...   \n",
       "1  [<KEEP>, public, boolean, are, insertions, or,...   \n",
       "2  [<KEEP>, private, <KEEP_END>, <REPLACE_OLD>, j...   \n",
       "3  [<KEEP>, public, static, list, <, rel, data, t...   \n",
       "4  [<KEEP>, static, mongo, database, <KEEP_END>, ...   \n",
       "\n",
       "                           token_diff_code_subtokens  line_counts  \n",
       "0  [<REPLACE_OLD>, public, <REPLACE_NEW>, private...            6  \n",
       "1  [<KEEP>, public, <KEEP>, boolean, <KEEP>, are,...            4  \n",
       "2  [<KEEP>, private, <REPLACE_OLD>, jsonarray, <R...           28  \n",
       "3  [<KEEP>, public, <KEEP>, static, <KEEP>, list,...            4  \n",
       "4  [<KEEP>, static, <KEEP>, mongo, <KEEP>, databa...           16  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = test_df\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c90c464d",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_list = df_clean['new_code_raw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "db25cdb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  private static EmbeddedElasticsearchNode create(Settings settings) {\\n    // ensure PainlessPlugin is installed or otherwise scripted fields would not work\\n    Node node = new LocalNode(settings, Arrays.asList(Netty4Plugin.class, PainlessPlugin.class));\\n    return new EmbeddedElasticsearchNode(node);\\n  }\\n'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcd1d3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a8fa6eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  private static EmbeddedElasticsearchNode create(Settings settings) {\\n    // ensure PainlessPlugin is installed or otherwise scripted fields would not work\\n    Node node = new LocalNode(settings, Arrays.asList(Netty4Plugin.class, PainlessPlugin.class));\\n    return new EmbeddedElasticsearchNode(node);\\n  }\\n'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.loc[0]['new_code_raw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a2095c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cf598e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = torch.load('save_GCBmodel.pt',map_location=torch.device('cuda:0'))\n",
    "model = torch.load('D:/BERT_learing/CCDP/for_captum/save_model/save_GCBmodel.pt',map_location=torch.device('cpu'))\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d76cca9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1+cpu\n",
      "None\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())  #输出为True，则安装无误\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "db0b8ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "aba07f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"D:/BERT_learing/code_comment_inconsistency_detection/graphcodebert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ea322f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaEmbeddings(\n",
       "  (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "  (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "  (token_type_embeddings): Embedding(1, 768)\n",
       "  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.roberta.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "db6de6fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaLayer(\n",
       "  (attention): RobertaAttention(\n",
       "    (self): RobertaSelfAttention(\n",
       "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (output): RobertaSelfOutput(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (intermediate): RobertaIntermediate(\n",
       "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    (intermediate_act_fn): GELUActivation()\n",
       "  )\n",
       "  (output): RobertaOutput(\n",
       "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.roberta.encoder.layer[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e79e32eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_embeddings = model.get_input_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ca9012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f64e8e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c241dc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict和squad_pos_forward_func可以合成一个\n",
    "def predict(inputs, position_ids=None, attention_mask=None):\n",
    "    output = model(inputs,\n",
    "                   position_ids=position_ids,\n",
    "                  attention_mask=attention_mask )\n",
    "    \n",
    "    prediction = output.logits\n",
    "    prediction_1 = nn.functional.softmax(prediction, dim=1)\n",
    "    prediction = prediction_1.max(1).values\n",
    "    out = torch.argmax(prediction_1, dim=-1)\n",
    "    # prediction：每个输入样本的最大预测概率。\n",
    "    # out：预测的类别标签。\n",
    "    # prediction_1：所有类别的预测概率。    \n",
    "    return prediction,out,prediction_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c4de032c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squad_pos_forward_func(inputs,position_ids=None, attention_mask=None, position=0):\n",
    "    pred ,_,_= predict(inputs,\n",
    "                     position_ids=position_ids,\n",
    "                   attention_mask=attention_mask)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7c1bd6f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 0)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_token_id = tokenizer.pad_token_id # 0\n",
    "sep_token_id = tokenizer.sep_token_id # 101\n",
    "cls_token_id = tokenizer.cls_token_id # 102\n",
    "ref_token_id,sep_token_id,cls_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "63d48d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意长度\n",
    "def truncate(ids,len_tru = 512):\n",
    "    return ids[:len_tru] if len(ids) > len_tru else ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8206c991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这是单个数据的处理方式，应该要想数据集应该怎么处理\n",
    "def construct_input_ref_pair(comment,AST_type,  ref_token_id, sep_token_id, cls_token_id):\n",
    "    comment = tokenizer.encode(comment, add_special_tokens=False,truncation=True,max_length=512)\n",
    "    AST_type = tokenizer.encode(AST_type, add_special_tokens=False,truncation=True,max_length=512)\n",
    "    # construct input token ids\n",
    "    input_ids = [cls_token_id] + comment + [sep_token_id] + AST_type + [sep_token_id]\n",
    "\n",
    "    # construct reference token ids \n",
    "    ref_input_ids = [cls_token_id] + [ref_token_id] * len(comment) + [sep_token_id] + \\\n",
    "        [ref_token_id] * len(AST_type) + [sep_token_id]\n",
    "    input_ids = truncate(input_ids)\n",
    "    ref_input_ids = truncate(ref_input_ids)\n",
    "    return torch.tensor([input_ids], device=device), torch.tensor([ref_input_ids], device=device), len(comment)\n",
    "\n",
    "def construct_input_ref_token_type_pair(input_ids, sep_ind=0):\n",
    "    seq_len = input_ids.size(1)\n",
    "    token_type_ids = torch.tensor([[0 if i <= sep_ind else 1 for i in range(seq_len)]], device=device)\n",
    "    ref_token_type_ids = torch.zeros_like(token_type_ids, device=device)# * -1\n",
    "    return token_type_ids, ref_token_type_ids\n",
    "\n",
    "def construct_input_ref_pos_id_pair(input_ids):\n",
    "    seq_length = input_ids.size(1)\n",
    "    position_ids = torch.arange(seq_length, dtype=torch.long, device=device)\n",
    "    # we could potentially also use random permutation with `torch.randperm(seq_length, device=device)`\n",
    "    ref_position_ids = torch.zeros(seq_length, dtype=torch.long, device=device)\n",
    "\n",
    "    position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "    ref_position_ids = ref_position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "    return position_ids, ref_position_ids\n",
    "\n",
    "def construct_attention_mask(input_ids):\n",
    "    return torch.ones_like(input_ids)\n",
    "\n",
    "def construct_whole_bert_embeddings(input_ids, ref_input_ids, \\\n",
    "                                    token_type_ids=None, ref_token_type_ids=None, \\\n",
    "                                    position_ids=None, ref_position_ids=None):\n",
    "    input_embeddings = model.roberta.embeddings(input_ids, token_type_ids=token_type_ids, position_ids=position_ids)\n",
    "    ref_input_embeddings = model.roberta.embeddings(ref_input_ids, token_type_ids=ref_token_type_ids, position_ids=ref_position_ids)\n",
    "    \n",
    "    return input_embeddings, ref_input_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0582b7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_data_list(AST_list,comment_list):\n",
    "    input_ids_all = []\n",
    "    ref_input_ids_all = []\n",
    "    position_ids_all = []\n",
    "    attention_mask_all = []\n",
    "    token_type_ids_all = []\n",
    "    all_tokens_all = []\n",
    "    for i in range(len(AST_list)):\n",
    "        input_ids, ref_input_ids, comment_len = construct_input_ref_pair(comment_list[i],AST_list[i], ref_token_id,\\\n",
    "                                                                         sep_token_id, cls_token_id)\n",
    "        token_type_ids, ref_token_type_ids = construct_input_ref_token_type_pair(input_ids, comment_len)\n",
    "        position_ids, ref_position_ids = construct_input_ref_pos_id_pair(input_ids)\n",
    "        attention_mask = construct_attention_mask(input_ids)\n",
    "        \n",
    "        indices = input_ids[0].detach().tolist()\n",
    "        \n",
    "        all_tokens = []                                       ###\n",
    "        for _, token in enumerate(indices):\n",
    "            all_tokens.append(tokenizer.decode([token]))\n",
    "        \n",
    "        input_ids_all.append(input_ids)\n",
    "        ref_input_ids_all.append(ref_input_ids)\n",
    "        position_ids_all.append(position_ids)\n",
    "        attention_mask_all.append(attention_mask)\n",
    "        token_type_ids_all.append(token_type_ids)\n",
    "        all_tokens_all.append(all_tokens)\n",
    "\n",
    "    return input_ids_all,ref_input_ids_all,position_ids_all,attention_mask_all,token_type_ids_all,all_tokens_all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a4cabf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f1094ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前k个贡献最高的word 和 token_type 和 position\n",
    "# return value为归因贡献值  indices为词对应的索引  top_tokens为 词或位置或token_type\n",
    "def get_topk_attributed_tokens(attrs,all_token_t, k=5):\n",
    "    values_max, indices_max = torch.topk(attrs, k)\n",
    "    top_tokens_max = [all_token_t[idx] for idx in indices_max]\n",
    "    values_min, indices_min = torch.topk(attrs, k, largest=False)\n",
    "    top_tokens_min = [all_token_t[idx] for idx in indices_min] \n",
    "    \n",
    "    return top_tokens_max, values_max, indices_max,top_tokens_min,values_min,indices_min\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f1c77cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def split_punctuation(s):\n",
    "    # 使用正则表达式匹配连续的标点符号或者字母和标点符号之间的位置\n",
    "    splits = re.finditer(r'(?<=\\w)(?=[{}])|(?<=[{}])(?=\\w)'.format(string.punctuation, string.punctuation), s)\n",
    "    \n",
    "    # 获取所有分割位置\n",
    "    split_positions = [match.start() for match in splits]\n",
    "    \n",
    "    # 在分割位置插入空格\n",
    "    for pos in reversed(split_positions):\n",
    "        s = s[:pos] + ' ' + s[pos:]\n",
    "        \n",
    "    s = s.replace(\"< s >\", \"<s>\")\n",
    "    s = s.replace(\"</ s >\", \"</s>\")\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6453886d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从 all_tokens 还原为 原单词 ，并且计算归因值\n",
    "def get_restore_words(code,comment,input_ids,all_tokens,attribution_num):\n",
    "    all_tokens_decode = tokenizer.decode(input_ids)\n",
    "    len_all_tokens_decode = len(all_tokens_decode) + 4\n",
    "    # 使用decode获得的序列，去掉分词之后的空格    例 ' a' -> 'a'\n",
    "    all_tokens_clean = []\n",
    "    for token in all_tokens:\n",
    "        s_without_leading_space = token.lstrip()\n",
    "        all_tokens_clean.append(s_without_leading_space)\n",
    "#     print('all_tokens_clean:\\n',all_tokens_clean)\n",
    "#     print('all_tokens_clean:\\n',len(all_tokens_clean))\n",
    "    \n",
    "\n",
    "    # 获得 code_comment_baseline\n",
    "    code = tokenizer.encode(code, add_special_tokens=False,truncation=True,max_length=512)\n",
    "    comment = tokenizer.encode(comment, add_special_tokens=False,truncation=True,max_length=512)\n",
    "    code_decode = tokenizer.decode(code)\n",
    "    comment_decode = tokenizer.decode(comment)\n",
    "    \n",
    "    code_comment_baseline = tokenizer.decode(tokenizer.cls_token_id) + ' '+ comment_decode \\\n",
    "                            + ' '+ tokenizer.decode(tokenizer.sep_token_id) + ' ' + code_decode \\\n",
    "                            + ' ' + tokenizer.decode(tokenizer.sep_token_id)\n",
    "    \n",
    "    code_comment_baseline = code_comment_baseline[:len_all_tokens_decode]\n",
    "    code_comment_baseline = split_punctuation(code_comment_baseline)\n",
    "    code_comment_baseline = code_comment_baseline.split()\n",
    "\n",
    "#     print('code_comment_baseline:\\n',code_comment_baseline)\n",
    "#     print('code_comment_baseline_len:\\n',len(code_comment_baseline))\n",
    "\n",
    "    \n",
    "    # 获得 相邻有几个token合并在一块的列表times  为了以后再计算attribute时求和\n",
    "    times = []\n",
    "    token_index = 0\n",
    "    for code_comment in code_comment_baseline:\n",
    "        temp = ''\n",
    "        time = 0\n",
    "        while temp != code_comment:\n",
    "            temp = temp + all_tokens_clean[token_index]\n",
    "            token_index = token_index + 1\n",
    "            time = time + 1\n",
    "        times.append(time)\n",
    "#     print('times:\\n',times)\n",
    "    \n",
    "    attribute_sum = []\n",
    "    start = 0\n",
    "    for time in times:\n",
    "        end = start + time\n",
    "        attribute = sum(attribution_num[start:end]) / time\n",
    "        attribute_sum.append(attribute)\n",
    "        start = end\n",
    "#     print('attribute_sum:\\n',attribute_sum)\n",
    "    return code_comment_baseline ,attribute_sum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ea788594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_line_code_and_attribute(code,code_all_tokens,attributions_num):\n",
    "    # 特殊符号前  加空格\n",
    "    code = split_punctuation(code)\n",
    "    \n",
    "    # 把  行前空格去掉  便于单词与行之间匹配\n",
    "    code = [line.lstrip() for line in code.splitlines()]\n",
    "    code = '\\n'.join(code)  \n",
    "    code_lineList = code.split('\\n')\n",
    "    code_lineList = [' '.join(x.split()) for x in code_lineList]\n",
    "    # 有空行，把空行去掉\n",
    "    code_lineList = [item for item in code_lineList if item != '']\n",
    "    \n",
    "    attribute = []\n",
    "    i = 0  \n",
    "    for code_line in code_lineList:\n",
    "        count = 0\n",
    "        if i < len(code_all_tokens):\n",
    "            temp = code_all_tokens[i]\n",
    "            attr = attributions_num[i]\n",
    "            i = i + 1\n",
    "        while((i < len(code_all_tokens)) and(temp != code_line)):\n",
    "            attr = attr + attributions_num[i]\n",
    "            temp = temp + ' ' + code_all_tokens[i]\n",
    "            i = i + 1\n",
    "            count = count + 1\n",
    "        attribute.append(attr/count)\n",
    "\n",
    "    return code_lineList,attribute   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1432edfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_before_and_including(lst, element):\n",
    "    if element in lst:\n",
    "        index = lst.index(element)\n",
    "        lst_c = lst[index+1:]\n",
    "        if element in lst_c:\n",
    "            lst_c.remove(element)\n",
    "        return lst_c\n",
    "    else:\n",
    "        return lst\n",
    "    \n",
    "def remove_after_including(lst, element):\n",
    "    if element in lst:\n",
    "        index = lst.index(element)\n",
    "        return lst[:index + 1]\n",
    "    else:\n",
    "        return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8635954e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_all_attribute(code,all_tokens,attributions_num):\n",
    "    # 删除 all_token 列表中的<s>注释</s>  </s>\n",
    "    code_all_tokens = remove_before_and_including(all_tokens,'</s>')\n",
    "    comment_all_tokens = remove_after_including(all_tokens,'</s>')  \n",
    "    index = all_tokens.index('</s>')\n",
    "    attribute_comment = attributions_num[:index+1]\n",
    "#     print(attribute_comment)\n",
    "    \n",
    "    attribute_code = attributions_num[index+1:-1]\n",
    "#     print(attribute_code,len(attribute_code))\n",
    "    code_lineList_token,attribute_num_code = get_line_code_and_attribute(code,code_all_tokens,attribute_code)\n",
    "##     print(attribute_num_code)\n",
    "    attribute_num_code = torch.stack(attribute_num_code)\n",
    "    \n",
    "    new_all_tokens = comment_all_tokens + code_lineList_token\n",
    "    attributions_num_all = torch.cat((attribute_comment, attribute_num_code))\n",
    "\n",
    "#     attributions_num_all = attribute_comment + attribute_num_code\n",
    "#     print(len(attribute_comment),len(attribute_num_code))\n",
    "#     print(new_all_tokens)\n",
    "    return new_all_tokens,attributions_num_all,code_lineList_token,attribute_num_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450e5303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "25d196c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import LayerIntegratedGradients\n",
    "from captum.attr import visualization as viz\n",
    "\n",
    "lig = LayerIntegratedGradients(squad_pos_forward_func,input_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3b270703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_sentence_2(code,comment,old_code,input_ids,ref_input_ids, token_type_ids,\\\n",
    "                         position_ids, attention_mask, all_tokens):\n",
    "    pre ,out,_ = predict(input_ids,  position_ids=position_ids,attention_mask=attention_mask)\n",
    "  \n",
    "    attributions_ig, delta_ig = lig.attribute(input_ids, baselines=ref_input_ids,\\\n",
    "                           additional_forward_args=(position_ids,attention_mask,0),return_convergence_delta=True,internal_batch_size=8)\n",
    "    \n",
    "    attributions = attributions_ig.sum(dim=2).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "#     print(delta_ig)\n",
    "#     print(attributions)\n",
    "    try:\n",
    "        all_tokens ,attributions = get_restore_words(code,comment,input_ids[0],all_tokens,attributions)     # 合并为一个单词\n",
    "        attributions = torch.tensor(attributions)\n",
    "#         print(all_tokens)\n",
    "\n",
    "\n",
    "        # code_lineList_token 和 attribute_num_code 用于后续统计分析\n",
    "        new_all_tokens,attributions_num_all,code_lineList_token,attribute_num_code = final_all_attribute(code,all_tokens,attributions)\n",
    "\n",
    "        return out,code_lineList_token,attribute_num_code\n",
    "    except Exception as e:\n",
    "#         pass\n",
    "        print(\"解析错误\")\n",
    "        return -1,_,_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b26fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bafb88a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346ef47e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19adae4e",
   "metadata": {},
   "source": [
    "判断行级贡献值分布情况，将一些特殊语句变为一个具有代表性的词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "227bba4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单个示例获取各种statement 的函数\n",
    "def get_ifstatement(code_line,attribution_num):\n",
    "    pattern = re.compile(r'\\bif\\b')    \n",
    "    code_contains_if = [(i, s) for i, s in enumerate(code_line) if pattern.search(s)]   \n",
    "    attr_contains_if = [attribution_num[code_contains_if[i][0]] for i in range(len(code_contains_if))]\n",
    "    merged_list = [('ifstatement', s, attr) for (_, s), attr in zip(code_contains_if, attr_contains_if)]\n",
    "    return merged_list\n",
    "def get_forstatement(code_line,attribution_num):\n",
    "    pattern = re.compile(r'\\bfor\\b')    \n",
    "    code_contains_for = [(i, s) for i, s in enumerate(code_line) if pattern.search(s)]   \n",
    "    attr_contains_for = [attribution_num[code_contains_for[i][0]] for i in range(len(code_contains_for))]\n",
    "    merged_list = [('forstatement', s, attr) for (_, s), attr in zip(code_contains_for, attr_contains_for)]\n",
    "    return merged_list\n",
    "def get_whilestatement(code_line,attribution_num):\n",
    "    pattern = re.compile(r'\\bwhile\\b')    \n",
    "    code_contains_while = [(i, s) for i, s in enumerate(code_line) if pattern.search(s)]   \n",
    "    attr_contains_while = [attribution_num[code_contains_while[i][0]] for i in range(len(code_contains_while))]\n",
    "    merged_list = [('whilestatement', s, attr) for (_, s), attr in zip(code_contains_while, attr_contains_while)]\n",
    "    return merged_list\n",
    "def get_variableDeclaration(code_line,attribution_num):\n",
    "    pattern = re.compile(r'\\bnew\\b')    \n",
    "    code_contains_new = [(i, s) for i, s in enumerate(code_line) if pattern.search(s)]       \n",
    "    attr_contains_new = [attribution_num[code_contains_new[i][0]] for i in range(len(code_contains_new))]\n",
    "    merged_list = [('variableDeclaration', s, attr) for (_, s), attr in zip(code_contains_new, attr_contains_new)]\n",
    "    return merged_list\n",
    "def get_expression(code_line,attribution_num):\n",
    "    pattern = re.compile(r'\\b=\\b')    \n",
    "    code_contains_exp = [(i, s) for i, s in enumerate(code_line) if pattern.search(s)] \n",
    "    attr_contains_exp = [attribution_num[code_contains_exp[i][0]] for i in range(len(code_contains_exp))]\n",
    "    merged_list = [('expression', s, attr) for (_, s), attr in zip(code_contains_exp, attr_contains_exp)]\n",
    "    return merged_list\n",
    "def get_try_catch(code_line,attribution_num):\n",
    "    pattern = re.compile(r'\\btry\\b')    \n",
    "    code_contains_try_catch = [(i, s) for i, s in enumerate(code_line) if pattern.search(s)] \n",
    "    attr_contains_try_catch = [attribution_num[code_contains_try_catch[i][0]] for i in range(len(code_contains_try_catch))]\n",
    "    merged_list = [('trystatement', s, attr) for (_, s), attr in zip(code_contains_try_catch, attr_contains_try_catch)]\n",
    "    return merged_list\n",
    "def get_return(code_line,attribution_num):\n",
    "    pattern = re.compile(r'\\breturn\\b')    \n",
    "    code_contains_return = [(i, s) for i, s in enumerate(code_line) if pattern.search(s)]\n",
    "    attr_contains_return = [attribution_num[code_contains_return[i][0]] for i in range(len(code_contains_return))]\n",
    "    merged_list = [('returnstatement', s, attr) for (_, s), attr in zip(code_contains_return, attr_contains_return)]\n",
    "    return merged_list\n",
    "def get_MethodDeclaration(code_line,attribution_num):\n",
    "    code_contains_Method = [code_line[0]]\n",
    "    attr_contains_Method = [attribution_num[0]]\n",
    "    merged_list = list(zip(['MethodDeclaration'],code_line, attribution_num))\n",
    "    return merged_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "17c3536d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 集成到数据集中 , 对返回值进行数据分析 , 六个列表试着画小提琴图\n",
    "from itertools import chain\n",
    "\n",
    "def get_all_statement(code_line_list,attribution_num_list):\n",
    "    type_code_attr = []\n",
    "    for (code_line,attribution_num) in zip(code_line_list,attribution_num_list):\n",
    "#         print(code_line,attribution_num)\n",
    "        merged_list_if = get_ifstatement(code_line,attribution_num)\n",
    "        merged_list_for = get_forstatement(code_line,attribution_num)\n",
    "        merged_list_while = get_whilestatement(code_line,attribution_num)\n",
    "        merged_list_new = get_variableDeclaration(code_line,attribution_num)\n",
    "        merged_listexp = get_expression(code_line,attribution_num)\n",
    "        merged_list_try_catch = get_try_catch(code_line,attribution_num)\n",
    "        merged_list_return = get_return(code_line,attribution_num)\n",
    "        merged_list_Method = get_MethodDeclaration(code_line,attribution_num)\n",
    "        \n",
    "        conditions = [\n",
    "            merged_list_if,\n",
    "            merged_list_for,\n",
    "            merged_list_while,\n",
    "            merged_list_new,\n",
    "            merged_listexp,\n",
    "            merged_list_try_catch,\n",
    "            merged_list_return ,\n",
    "            merged_list_Method\n",
    "        ]\n",
    "        # 合并上述非空的列表\n",
    "        merged_conditions = list(chain(*[lst for lst in conditions if lst]))\n",
    "        type_code_attr.append(merged_conditions)\n",
    "        \n",
    "    return type_code_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d82ffcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_line_attribution(df):\n",
    "    code_list = df['new_code_raw']\n",
    "    comment_list = df['old_comment_raw']\n",
    "    code_list_old = df['old_code_raw']\n",
    "    ground_lable = df['label']\n",
    "    \n",
    "    input_ids_all,ref_input_ids_all,position_ids_all,attention_mask_all,\\\n",
    "    token_type_ids_all,all_tokens_all= input_data_list(code_list,comment_list)\n",
    "    \n",
    "    code_lineList_token_true = []\n",
    "    attribute_num_code_true = []\n",
    "    index_true = []\n",
    "    code_lineList_token_false = []\n",
    "    attribute_num_code_false = []\n",
    "    index_false = []\n",
    "\n",
    "    for i in range(len(code_list)): \n",
    "        out,code_lineList_token,attribute_num_code \\\n",
    "        = interpret_sentence_2(code_list[i],comment_list[i],\\\n",
    "                               code_list_old[i],input_ids_all[i],\\\n",
    "                               ref_input_ids_all[i], token_type_ids_all[i],\\\n",
    "                               position_ids_all[i],attention_mask_all[i], all_tokens_all[i])\n",
    "        if out != -1:\n",
    "            if out == ground_lable[i]:\n",
    "                index_true.append(i)\n",
    "                code_lineList_token_true.append(code_lineList_token)\n",
    "                attribute_num_code_true.append(attribute_num_code)\n",
    "            else :\n",
    "                index_false.append(i)\n",
    "                code_lineList_token_false.append(code_lineList_token)\n",
    "                attribute_num_code_false.append(attribute_num_code)\n",
    "    return index_true,index_false,code_lineList_token_true,attribute_num_code_true,code_lineList_token_false,attribute_num_code_false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19b1183",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8c211d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "解析错误\n",
      "解析错误\n",
      "解析错误\n",
      "解析错误\n"
     ]
    }
   ],
   "source": [
    "index_true,index_false,code_lineList_token_true,attribute_num_code_true,code_lineList_token_false,attribute_num_code_false\\\n",
    "= analyse_line_attribution(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "eaec1819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 9, 9)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(index_true),len(code_lineList_token_true),len(attribute_num_code_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da33c1a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38da89a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cffbf4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average_list 为 均值的元组 (类型名，均值)\n",
    "def get_filter_pair(list_pair,average_list,index_all):\n",
    "\n",
    "    type_dict = dict(average_list)\n",
    "    \n",
    "    # 过滤符合条件的子列表，并记录被删除的索引\n",
    "    filtered_nested_statements = []\n",
    "    removed_indices = []\n",
    "    \n",
    "    for index, sublist in enumerate(list_pair):\n",
    "        if all(stmt_type in type_dict and value > type_dict[stmt_type] for stmt_type, _, value in sublist if stmt_type in type_dict):\n",
    "            filtered_nested_statements.append(sublist)\n",
    "        else:\n",
    "            removed_indices.append(index)\n",
    "    index_all_t = [index_all[i] for i in range(len(index_all)) if i not in removed_indices]\n",
    "  \n",
    "    return filtered_nested_statements,index_all_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02553638",
   "metadata": {},
   "source": [
    "true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6cddc500",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_code_attr_true= get_all_statement(code_lineList_token_true,attribute_num_code_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f63e58d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 9)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(index_true),len(type_code_attr_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc436d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "daa6bafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 由均值而来 iqr\n",
    "type_list_true = [\n",
    "    ('MethodDeclaration',0.143),\n",
    "    ('variableDeclaration',0.087),\n",
    "    ('trystatement',0.102),\n",
    "    ('returnstatement',0.129)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "01e80a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 由均值而来 Winsorization \n",
    "type_list_true_1 = [\n",
    "    ('MethodDeclaration',0.182),\n",
    "    ('variableDeclaration',0.09),\n",
    "    ('trystatement',0.100),\n",
    "    ('returnstatement',0.144)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62441a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_statements_true,filter_true_index = get_filter_pair(type_code_attr_true, type_list_true,index_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bd10320c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 7, 13]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_true_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3216821f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('returnstatement',\n",
       "   'return ( insertions . size () > 0 || ! unresolvedInsertions . isEmpty () || deletions . size () > 0 );',\n",
       "   tensor(0.0590, dtype=torch.float64)),\n",
       "  ('MethodDeclaration',\n",
       "   'public boolean areInsertionsOrDeletionsQueued () {',\n",
       "   tensor(0.1059, dtype=torch.float64))],\n",
       " [('returnstatement',\n",
       "   'return Lists . transform ( type . getFieldList (), GET _ TYPE );',\n",
       "   tensor(0.0478, dtype=torch.float64)),\n",
       "  ('MethodDeclaration',\n",
       "   'public static List < RelDataType > getFieldTypeList ( final RelDataType type ) {',\n",
       "   tensor(0.0580, dtype=torch.float64))],\n",
       " [('ifstatement',\n",
       "   'if ( txtPattern == null ) {',\n",
       "   tensor(0.0214, dtype=torch.float64)),\n",
       "  ('variableDeclaration',\n",
       "   'txtPattern = new ZapTextField ();',\n",
       "   tensor(0.0512, dtype=torch.float64)),\n",
       "  ('returnstatement',\n",
       "   'return txtPattern ;',\n",
       "   tensor(0.0719, dtype=torch.float64)),\n",
       "  ('MethodDeclaration',\n",
       "   'public ZapTextField getTxtPattern () {',\n",
       "   tensor(0.0075, dtype=torch.float64))],\n",
       " [('returnstatement',\n",
       "   'return Float . valueOf ( getOptional (\" kylin . hbase . region . cut \", \" 5 . 0 \"));',\n",
       "   tensor(0.0979, dtype=torch.float64)),\n",
       "  ('MethodDeclaration',\n",
       "   'public float getKylinHBaseRegionCut () {',\n",
       "   tensor(0.0519, dtype=torch.float64))]]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_statements_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "409d8e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打开一个txt文件用于写入\n",
    "with open(\"linetype_attribution_index_true.txt\", \"w\") as file:\n",
    "    max_length = max(len(filtered_statements_true), len(filter_true_index))\n",
    "    \n",
    "    for i in range(max_length):\n",
    "        # 如果当前索引在第一个列表的范围内，写入奇数行\n",
    "        if i < len(filtered_statements_true):\n",
    "            file.write(str(filtered_statements_true[i]) + \"\\n\")\n",
    "        # 如果当前索引在第二个列表的范围内，写入偶数行\n",
    "        if i < len(filter_true_index):\n",
    "            file.write(str(filter_true_index[i]) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282a0f29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f883fae0",
   "metadata": {},
   "source": [
    "false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a2588f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_code_attr_false= get_all_statement(code_lineList_token_false,attribute_num_code_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e56019e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 7)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(index_false),len(type_code_attr_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b868e384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 由均值而来 iqr\n",
    "type_list_false = [\n",
    "    ('MethodDeclaration',0.176),\n",
    "    ('whilestatement',0.100),\n",
    "    ('trystatement',0.102),\n",
    "    ('returnstatement',0.139)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4ffdb0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 由均值而来 Winsorization \n",
    "type_list_false_1 = [\n",
    "    ('MethodDeclaration',0.21),\n",
    "    ('whilestatement',0.106),\n",
    "    ('trystatement',0.094),\n",
    "    ('returnstatement',0.159)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5e8400",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_statements_false,filter_false_index = get_filter_pair(type_code_attr_false, type_list_false,index_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fba3594a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 6, 14]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_false_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "704d6be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"linetype_attribution_index_false.txt\", \"w\") as file:\n",
    "    max_length = max(len(filtered_statements_false), len(filter_false_index))\n",
    "    \n",
    "    for i in range(max_length):\n",
    "        # 如果当前索引在第一个列表的范围内，写入奇数行\n",
    "        if i < len(filtered_statements_false):\n",
    "            file.write(str(filtered_statements_false[i]) + \"\\n\")\n",
    "        # 如果当前索引在第二个列表的范围内，写入偶数行\n",
    "        if i < len(filter_false_index):\n",
    "            file.write(str(filter_false_index[i]) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbf7526",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8db5c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leitx",
   "language": "python",
   "name": "leitx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
