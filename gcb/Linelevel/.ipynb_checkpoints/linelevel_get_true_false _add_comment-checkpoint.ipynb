{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ad6ca09",
   "metadata": {},
   "source": [
    "此 .ipynb为按照行级，获得预测正确和错误的不同行级元素的贡献值分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e84e3fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "\n",
    "\n",
    "from captum.attr import visualization as viz\n",
    "from captum.attr import LayerConductance, LayerIntegratedGradients\n",
    "from captum.attr import configure_interpretable_embedding_layer, remove_interpretable_embedding_layer\n",
    "\n",
    "# 解决服务器挂掉的问题\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff062613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device( \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf31e07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 1024\n",
    "MAX_EPOCHS = 10\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 1e-5\n",
    "NUM_CLASSES = 2\n",
    "WEIGTH_DECAY = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b8e3dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_test_data():\n",
    "    test_param = pd.read_json(\"D:/BERT_learing/code_comment_inconsistency_detection/data/param/test.json\")\n",
    "    test_return = pd.read_json(\"D:/BERT_learing/code_comment_inconsistency_detection/data/return/test.json\")\n",
    "    test_summary = pd.read_json(\"D:/BERT_learing/code_comment_inconsistency_detection/data/summary/test.json\")\n",
    "    test_df = pd.concat([test_summary,test_param, test_return], axis=0)\n",
    "    test_df = test_df[:20]\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "    return test_df\n",
    "test_df = retrieve_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11e4d12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>comment_type</th>\n",
       "      <th>old_comment_raw</th>\n",
       "      <th>old_comment_subtokens</th>\n",
       "      <th>new_comment_raw</th>\n",
       "      <th>new_comment_subtokens</th>\n",
       "      <th>span_minimal_diff_comment_subtokens</th>\n",
       "      <th>old_code_raw</th>\n",
       "      <th>old_code_subtokens</th>\n",
       "      <th>new_code_raw</th>\n",
       "      <th>new_code_subtokens</th>\n",
       "      <th>span_diff_code_subtokens</th>\n",
       "      <th>token_diff_code_subtokens</th>\n",
       "      <th>line_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apache_calcite-896-FirstSentence-0</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Creates elastic node as single member of a clu...</td>\n",
       "      <td>[creates, elastic, node, as, single, member, o...</td>\n",
       "      <td>Creates an instance with existing settings</td>\n",
       "      <td>[creates, an, instance, with, existing, settings]</td>\n",
       "      <td>[&lt;REPLACE_OLD&gt;, elastic, node, as, single, mem...</td>\n",
       "      <td>public static EmbeddedElasticsearchNode crea...</td>\n",
       "      <td>[public, static, embedded, elasticsearch, node...</td>\n",
       "      <td>private static EmbeddedElasticsearchNode cre...</td>\n",
       "      <td>[private, static, embedded, elasticsearch, nod...</td>\n",
       "      <td>[&lt;REPLACE_OLD&gt;, public, &lt;REPLACE_NEW&gt;, private...</td>\n",
       "      <td>[&lt;REPLACE_OLD&gt;, public, &lt;REPLACE_NEW&gt;, private...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hibernate_hibernate_orm-1601-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Check whether any insertion or deletion action...</td>\n",
       "      <td>[check, whether, any, insertion, or, deletion,...</td>\n",
       "      <td>Check whether any insertion or deletion action...</td>\n",
       "      <td>[check, whether, any, insertion, or, deletion,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>\\tpublic boolean areInsertionsOrDeletionsQueue...</td>\n",
       "      <td>[public, boolean, are, insertions, or, deletio...</td>\n",
       "      <td>\\tpublic boolean areInsertionsOrDeletionsQueue...</td>\n",
       "      <td>[public, boolean, are, insertions, or, deletio...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, boolean, are, insertions, or,...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, boolean, &lt;KEEP&gt;, are,...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apache_giraph-33-Associations-FirstSentence</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Marshal the aggregator values of to a JSONArra...</td>\n",
       "      <td>[marshal, the, aggregator, values, of, to, a, ...</td>\n",
       "      <td>Marshal the aggregator values of the worker to...</td>\n",
       "      <td>[marshal, the, aggregator, values, of, the, wo...</td>\n",
       "      <td>[&lt;INSERT_OLD_KEEP_BEFORE&gt;, of, &lt;INSERT_NEW_KEE...</td>\n",
       "      <td>private JSONArray marshalAggregatorValues(lo...</td>\n",
       "      <td>[private, jsonarray, marshal, aggregator, valu...</td>\n",
       "      <td>private byte[] marshalAggregatorValues(long ...</td>\n",
       "      <td>[private, byte, [, ], marshal, aggregator, val...</td>\n",
       "      <td>[&lt;KEEP&gt;, private, &lt;KEEP_END&gt;, &lt;REPLACE_OLD&gt;, j...</td>\n",
       "      <td>[&lt;KEEP&gt;, private, &lt;REPLACE_OLD&gt;, jsonarray, &lt;R...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apache_calcite-677-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Returns a list of the types of the fields in a...</td>\n",
       "      <td>[returns, a, list, of, the, types, of, the, fi...</td>\n",
       "      <td>Returns a list of the types of the fields in a...</td>\n",
       "      <td>[returns, a, list, of, the, types, of, the, fi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>public static List&lt;RelDataType&gt; getFieldType...</td>\n",
       "      <td>[public, static, list, &lt;, rel, data, type, &gt;, ...</td>\n",
       "      <td>public static List&lt;RelDataType&gt; getFieldType...</td>\n",
       "      <td>[public, static, list, &lt;, rel, data, type, &gt;, ...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, list, &lt;, rel, data, t...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;KEEP&gt;, list,...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apache_calcite-315-Associations-FirstSentence</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Create an instance based on current maven prof...</td>\n",
       "      <td>[create, an, instance, based, on, current, mav...</td>\n",
       "      <td>Creates an instance based on current maven pro...</td>\n",
       "      <td>[creates, an, instance, based, on, current, ma...</td>\n",
       "      <td>[&lt;REPLACE_OLD&gt;, create, &lt;REPLACE_NEW&gt;, creates...</td>\n",
       "      <td>static MongoDatabaseRule create() {\\n    fin...</td>\n",
       "      <td>[static, mongo, database, rule, create, (, ), ...</td>\n",
       "      <td>static MongoDatabasePolicy create() {\\n    f...</td>\n",
       "      <td>[static, mongo, database, policy, create, (, )...</td>\n",
       "      <td>[&lt;KEEP&gt;, static, mongo, database, &lt;KEEP_END&gt;, ...</td>\n",
       "      <td>[&lt;KEEP&gt;, static, &lt;KEEP&gt;, mongo, &lt;KEEP&gt;, databa...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              id  label comment_type  \\\n",
       "0             apache_calcite-896-FirstSentence-0      1      Summary   \n",
       "1   hibernate_hibernate_orm-1601-FirstSentence-0      0      Summary   \n",
       "2    apache_giraph-33-Associations-FirstSentence      1      Summary   \n",
       "3             apache_calcite-677-FirstSentence-0      0      Summary   \n",
       "4  apache_calcite-315-Associations-FirstSentence      1      Summary   \n",
       "\n",
       "                                     old_comment_raw  \\\n",
       "0  Creates elastic node as single member of a clu...   \n",
       "1  Check whether any insertion or deletion action...   \n",
       "2  Marshal the aggregator values of to a JSONArra...   \n",
       "3  Returns a list of the types of the fields in a...   \n",
       "4  Create an instance based on current maven prof...   \n",
       "\n",
       "                               old_comment_subtokens  \\\n",
       "0  [creates, elastic, node, as, single, member, o...   \n",
       "1  [check, whether, any, insertion, or, deletion,...   \n",
       "2  [marshal, the, aggregator, values, of, to, a, ...   \n",
       "3  [returns, a, list, of, the, types, of, the, fi...   \n",
       "4  [create, an, instance, based, on, current, mav...   \n",
       "\n",
       "                                     new_comment_raw  \\\n",
       "0         Creates an instance with existing settings   \n",
       "1  Check whether any insertion or deletion action...   \n",
       "2  Marshal the aggregator values of the worker to...   \n",
       "3  Returns a list of the types of the fields in a...   \n",
       "4  Creates an instance based on current maven pro...   \n",
       "\n",
       "                               new_comment_subtokens  \\\n",
       "0  [creates, an, instance, with, existing, settings]   \n",
       "1  [check, whether, any, insertion, or, deletion,...   \n",
       "2  [marshal, the, aggregator, values, of, the, wo...   \n",
       "3  [returns, a, list, of, the, types, of, the, fi...   \n",
       "4  [creates, an, instance, based, on, current, ma...   \n",
       "\n",
       "                 span_minimal_diff_comment_subtokens  \\\n",
       "0  [<REPLACE_OLD>, elastic, node, as, single, mem...   \n",
       "1                                                 []   \n",
       "2  [<INSERT_OLD_KEEP_BEFORE>, of, <INSERT_NEW_KEE...   \n",
       "3                                                 []   \n",
       "4  [<REPLACE_OLD>, create, <REPLACE_NEW>, creates...   \n",
       "\n",
       "                                        old_code_raw  \\\n",
       "0    public static EmbeddedElasticsearchNode crea...   \n",
       "1  \\tpublic boolean areInsertionsOrDeletionsQueue...   \n",
       "2    private JSONArray marshalAggregatorValues(lo...   \n",
       "3    public static List<RelDataType> getFieldType...   \n",
       "4    static MongoDatabaseRule create() {\\n    fin...   \n",
       "\n",
       "                                  old_code_subtokens  \\\n",
       "0  [public, static, embedded, elasticsearch, node...   \n",
       "1  [public, boolean, are, insertions, or, deletio...   \n",
       "2  [private, jsonarray, marshal, aggregator, valu...   \n",
       "3  [public, static, list, <, rel, data, type, >, ...   \n",
       "4  [static, mongo, database, rule, create, (, ), ...   \n",
       "\n",
       "                                        new_code_raw  \\\n",
       "0    private static EmbeddedElasticsearchNode cre...   \n",
       "1  \\tpublic boolean areInsertionsOrDeletionsQueue...   \n",
       "2    private byte[] marshalAggregatorValues(long ...   \n",
       "3    public static List<RelDataType> getFieldType...   \n",
       "4    static MongoDatabasePolicy create() {\\n    f...   \n",
       "\n",
       "                                  new_code_subtokens  \\\n",
       "0  [private, static, embedded, elasticsearch, nod...   \n",
       "1  [public, boolean, are, insertions, or, deletio...   \n",
       "2  [private, byte, [, ], marshal, aggregator, val...   \n",
       "3  [public, static, list, <, rel, data, type, >, ...   \n",
       "4  [static, mongo, database, policy, create, (, )...   \n",
       "\n",
       "                            span_diff_code_subtokens  \\\n",
       "0  [<REPLACE_OLD>, public, <REPLACE_NEW>, private...   \n",
       "1  [<KEEP>, public, boolean, are, insertions, or,...   \n",
       "2  [<KEEP>, private, <KEEP_END>, <REPLACE_OLD>, j...   \n",
       "3  [<KEEP>, public, static, list, <, rel, data, t...   \n",
       "4  [<KEEP>, static, mongo, database, <KEEP_END>, ...   \n",
       "\n",
       "                           token_diff_code_subtokens  line_counts  \n",
       "0  [<REPLACE_OLD>, public, <REPLACE_NEW>, private...            6  \n",
       "1  [<KEEP>, public, <KEEP>, boolean, <KEEP>, are,...            4  \n",
       "2  [<KEEP>, private, <REPLACE_OLD>, jsonarray, <R...           28  \n",
       "3  [<KEEP>, public, <KEEP>, static, <KEEP>, list,...            4  \n",
       "4  [<KEEP>, static, <KEEP>, mongo, <KEEP>, databa...           16  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_lines_count(df):\n",
    "    line_counts = []\n",
    "    for i in range(len(df)):\n",
    "        string = df.loc[i]['new_code_raw']\n",
    "        line_count = len(string.split('\\n'))\n",
    "        line_counts.append(line_count)\n",
    "    df['line_counts'] = line_counts\n",
    "    return df\n",
    "test_df = get_lines_count(test_df)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef5ae8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e42afc18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>comment_type</th>\n",
       "      <th>old_comment_raw</th>\n",
       "      <th>old_comment_subtokens</th>\n",
       "      <th>new_comment_raw</th>\n",
       "      <th>new_comment_subtokens</th>\n",
       "      <th>span_minimal_diff_comment_subtokens</th>\n",
       "      <th>old_code_raw</th>\n",
       "      <th>old_code_subtokens</th>\n",
       "      <th>new_code_raw</th>\n",
       "      <th>new_code_subtokens</th>\n",
       "      <th>span_diff_code_subtokens</th>\n",
       "      <th>token_diff_code_subtokens</th>\n",
       "      <th>line_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apache_calcite-896-FirstSentence-0</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Creates elastic node as single member of a clu...</td>\n",
       "      <td>[creates, elastic, node, as, single, member, o...</td>\n",
       "      <td>Creates an instance with existing settings</td>\n",
       "      <td>[creates, an, instance, with, existing, settings]</td>\n",
       "      <td>[&lt;REPLACE_OLD&gt;, elastic, node, as, single, mem...</td>\n",
       "      <td>public static EmbeddedElasticsearchNode crea...</td>\n",
       "      <td>[public, static, embedded, elasticsearch, node...</td>\n",
       "      <td>private static EmbeddedElasticsearchNode cre...</td>\n",
       "      <td>[private, static, embedded, elasticsearch, nod...</td>\n",
       "      <td>[&lt;REPLACE_OLD&gt;, public, &lt;REPLACE_NEW&gt;, private...</td>\n",
       "      <td>[&lt;REPLACE_OLD&gt;, public, &lt;REPLACE_NEW&gt;, private...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hibernate_hibernate_orm-1601-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Check whether any insertion or deletion action...</td>\n",
       "      <td>[check, whether, any, insertion, or, deletion,...</td>\n",
       "      <td>Check whether any insertion or deletion action...</td>\n",
       "      <td>[check, whether, any, insertion, or, deletion,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>\\tpublic boolean areInsertionsOrDeletionsQueue...</td>\n",
       "      <td>[public, boolean, are, insertions, or, deletio...</td>\n",
       "      <td>\\tpublic boolean areInsertionsOrDeletionsQueue...</td>\n",
       "      <td>[public, boolean, are, insertions, or, deletio...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, boolean, are, insertions, or,...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, boolean, &lt;KEEP&gt;, are,...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apache_giraph-33-Associations-FirstSentence</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Marshal the aggregator values of to a JSONArra...</td>\n",
       "      <td>[marshal, the, aggregator, values, of, to, a, ...</td>\n",
       "      <td>Marshal the aggregator values of the worker to...</td>\n",
       "      <td>[marshal, the, aggregator, values, of, the, wo...</td>\n",
       "      <td>[&lt;INSERT_OLD_KEEP_BEFORE&gt;, of, &lt;INSERT_NEW_KEE...</td>\n",
       "      <td>private JSONArray marshalAggregatorValues(lo...</td>\n",
       "      <td>[private, jsonarray, marshal, aggregator, valu...</td>\n",
       "      <td>private byte[] marshalAggregatorValues(long ...</td>\n",
       "      <td>[private, byte, [, ], marshal, aggregator, val...</td>\n",
       "      <td>[&lt;KEEP&gt;, private, &lt;KEEP_END&gt;, &lt;REPLACE_OLD&gt;, j...</td>\n",
       "      <td>[&lt;KEEP&gt;, private, &lt;REPLACE_OLD&gt;, jsonarray, &lt;R...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apache_calcite-677-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Returns a list of the types of the fields in a...</td>\n",
       "      <td>[returns, a, list, of, the, types, of, the, fi...</td>\n",
       "      <td>Returns a list of the types of the fields in a...</td>\n",
       "      <td>[returns, a, list, of, the, types, of, the, fi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>public static List&lt;RelDataType&gt; getFieldType...</td>\n",
       "      <td>[public, static, list, &lt;, rel, data, type, &gt;, ...</td>\n",
       "      <td>public static List&lt;RelDataType&gt; getFieldType...</td>\n",
       "      <td>[public, static, list, &lt;, rel, data, type, &gt;, ...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, list, &lt;, rel, data, t...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;KEEP&gt;, list,...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apache_calcite-315-Associations-FirstSentence</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Create an instance based on current maven prof...</td>\n",
       "      <td>[create, an, instance, based, on, current, mav...</td>\n",
       "      <td>Creates an instance based on current maven pro...</td>\n",
       "      <td>[creates, an, instance, based, on, current, ma...</td>\n",
       "      <td>[&lt;REPLACE_OLD&gt;, create, &lt;REPLACE_NEW&gt;, creates...</td>\n",
       "      <td>static MongoDatabaseRule create() {\\n    fin...</td>\n",
       "      <td>[static, mongo, database, rule, create, (, ), ...</td>\n",
       "      <td>static MongoDatabasePolicy create() {\\n    f...</td>\n",
       "      <td>[static, mongo, database, policy, create, (, )...</td>\n",
       "      <td>[&lt;KEEP&gt;, static, mongo, database, &lt;KEEP_END&gt;, ...</td>\n",
       "      <td>[&lt;KEEP&gt;, static, &lt;KEEP&gt;, mongo, &lt;KEEP&gt;, databa...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              id  label comment_type  \\\n",
       "0             apache_calcite-896-FirstSentence-0      1      Summary   \n",
       "1   hibernate_hibernate_orm-1601-FirstSentence-0      0      Summary   \n",
       "2    apache_giraph-33-Associations-FirstSentence      1      Summary   \n",
       "3             apache_calcite-677-FirstSentence-0      0      Summary   \n",
       "4  apache_calcite-315-Associations-FirstSentence      1      Summary   \n",
       "\n",
       "                                     old_comment_raw  \\\n",
       "0  Creates elastic node as single member of a clu...   \n",
       "1  Check whether any insertion or deletion action...   \n",
       "2  Marshal the aggregator values of to a JSONArra...   \n",
       "3  Returns a list of the types of the fields in a...   \n",
       "4  Create an instance based on current maven prof...   \n",
       "\n",
       "                               old_comment_subtokens  \\\n",
       "0  [creates, elastic, node, as, single, member, o...   \n",
       "1  [check, whether, any, insertion, or, deletion,...   \n",
       "2  [marshal, the, aggregator, values, of, to, a, ...   \n",
       "3  [returns, a, list, of, the, types, of, the, fi...   \n",
       "4  [create, an, instance, based, on, current, mav...   \n",
       "\n",
       "                                     new_comment_raw  \\\n",
       "0         Creates an instance with existing settings   \n",
       "1  Check whether any insertion or deletion action...   \n",
       "2  Marshal the aggregator values of the worker to...   \n",
       "3  Returns a list of the types of the fields in a...   \n",
       "4  Creates an instance based on current maven pro...   \n",
       "\n",
       "                               new_comment_subtokens  \\\n",
       "0  [creates, an, instance, with, existing, settings]   \n",
       "1  [check, whether, any, insertion, or, deletion,...   \n",
       "2  [marshal, the, aggregator, values, of, the, wo...   \n",
       "3  [returns, a, list, of, the, types, of, the, fi...   \n",
       "4  [creates, an, instance, based, on, current, ma...   \n",
       "\n",
       "                 span_minimal_diff_comment_subtokens  \\\n",
       "0  [<REPLACE_OLD>, elastic, node, as, single, mem...   \n",
       "1                                                 []   \n",
       "2  [<INSERT_OLD_KEEP_BEFORE>, of, <INSERT_NEW_KEE...   \n",
       "3                                                 []   \n",
       "4  [<REPLACE_OLD>, create, <REPLACE_NEW>, creates...   \n",
       "\n",
       "                                        old_code_raw  \\\n",
       "0    public static EmbeddedElasticsearchNode crea...   \n",
       "1  \\tpublic boolean areInsertionsOrDeletionsQueue...   \n",
       "2    private JSONArray marshalAggregatorValues(lo...   \n",
       "3    public static List<RelDataType> getFieldType...   \n",
       "4    static MongoDatabaseRule create() {\\n    fin...   \n",
       "\n",
       "                                  old_code_subtokens  \\\n",
       "0  [public, static, embedded, elasticsearch, node...   \n",
       "1  [public, boolean, are, insertions, or, deletio...   \n",
       "2  [private, jsonarray, marshal, aggregator, valu...   \n",
       "3  [public, static, list, <, rel, data, type, >, ...   \n",
       "4  [static, mongo, database, rule, create, (, ), ...   \n",
       "\n",
       "                                        new_code_raw  \\\n",
       "0    private static EmbeddedElasticsearchNode cre...   \n",
       "1  \\tpublic boolean areInsertionsOrDeletionsQueue...   \n",
       "2    private byte[] marshalAggregatorValues(long ...   \n",
       "3    public static List<RelDataType> getFieldType...   \n",
       "4    static MongoDatabasePolicy create() {\\n    f...   \n",
       "\n",
       "                                  new_code_subtokens  \\\n",
       "0  [private, static, embedded, elasticsearch, nod...   \n",
       "1  [public, boolean, are, insertions, or, deletio...   \n",
       "2  [private, byte, [, ], marshal, aggregator, val...   \n",
       "3  [public, static, list, <, rel, data, type, >, ...   \n",
       "4  [static, mongo, database, policy, create, (, )...   \n",
       "\n",
       "                            span_diff_code_subtokens  \\\n",
       "0  [<REPLACE_OLD>, public, <REPLACE_NEW>, private...   \n",
       "1  [<KEEP>, public, boolean, are, insertions, or,...   \n",
       "2  [<KEEP>, private, <KEEP_END>, <REPLACE_OLD>, j...   \n",
       "3  [<KEEP>, public, static, list, <, rel, data, t...   \n",
       "4  [<KEEP>, static, mongo, database, <KEEP_END>, ...   \n",
       "\n",
       "                           token_diff_code_subtokens  line_counts  \n",
       "0  [<REPLACE_OLD>, public, <REPLACE_NEW>, private...            6  \n",
       "1  [<KEEP>, public, <KEEP>, boolean, <KEEP>, are,...            4  \n",
       "2  [<KEEP>, private, <REPLACE_OLD>, jsonarray, <R...           28  \n",
       "3  [<KEEP>, public, <KEEP>, static, <KEEP>, list,...            4  \n",
       "4  [<KEEP>, static, <KEEP>, mongo, <KEEP>, databa...           16  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = test_df\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c90c464d",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_list = df_clean['new_code_raw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db25cdb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  private static EmbeddedElasticsearchNode create(Settings settings) {\\n    // ensure PainlessPlugin is installed or otherwise scripted fields would not work\\n    Node node = new LocalNode(settings, Arrays.asList(Netty4Plugin.class, PainlessPlugin.class));\\n    return new EmbeddedElasticsearchNode(node);\\n  }\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcd1d3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8fa6eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  private static EmbeddedElasticsearchNode create(Settings settings) {\\n    // ensure PainlessPlugin is installed or otherwise scripted fields would not work\\n    Node node = new LocalNode(settings, Arrays.asList(Netty4Plugin.class, PainlessPlugin.class));\\n    return new EmbeddedElasticsearchNode(node);\\n  }\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.loc[0]['new_code_raw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2095c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf598e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = torch.load('save_GCBmodel.pt',map_location=torch.device('cuda:0'))\n",
    "model = torch.load('D:/BERT_learing/CCDP/for_captum/save_model/save_GCBmodel.pt',map_location=torch.device('cpu'))\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d76cca9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1+cpu\n",
      "None\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())  #输出为True，则安装无误\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db0b8ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aba07f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"D:/BERT_learing/code_comment_inconsistency_detection/graphcodebert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea322f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaEmbeddings(\n",
       "  (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "  (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "  (token_type_embeddings): Embedding(1, 768)\n",
       "  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.roberta.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db6de6fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaLayer(\n",
       "  (attention): RobertaAttention(\n",
       "    (self): RobertaSelfAttention(\n",
       "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (output): RobertaSelfOutput(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (intermediate): RobertaIntermediate(\n",
       "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    (intermediate_act_fn): GELUActivation()\n",
       "  )\n",
       "  (output): RobertaOutput(\n",
       "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.roberta.encoder.layer[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e79e32eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_embeddings = model.get_input_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ca9012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f64e8e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c241dc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict和squad_pos_forward_func可以合成一个\n",
    "def predict(inputs, position_ids=None, attention_mask=None):\n",
    "    output = model(inputs,\n",
    "                   position_ids=position_ids,\n",
    "                  attention_mask=attention_mask )\n",
    "    \n",
    "    prediction = output.logits\n",
    "    prediction_1 = nn.functional.softmax(prediction, dim=1)\n",
    "    prediction = prediction_1.max(1).values\n",
    "    out = torch.argmax(prediction_1, dim=-1)\n",
    "    # prediction：每个输入样本的最大预测概率。\n",
    "    # out：预测的类别标签。\n",
    "    # prediction_1：所有类别的预测概率。    \n",
    "    return prediction,out,prediction_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4de032c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squad_pos_forward_func(inputs,position_ids=None, attention_mask=None, position=0):\n",
    "    pred ,_,_= predict(inputs,\n",
    "                     position_ids=position_ids,\n",
    "                   attention_mask=attention_mask)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c1bd6f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_token_id = tokenizer.pad_token_id # 0\n",
    "sep_token_id = tokenizer.sep_token_id # 101\n",
    "cls_token_id = tokenizer.cls_token_id # 102\n",
    "ref_token_id,sep_token_id,cls_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63d48d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意长度\n",
    "def truncate(ids,len_tru = 512):\n",
    "    return ids[:len_tru] if len(ids) > len_tru else ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8206c991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这是单个数据的处理方式，应该要想数据集应该怎么处理\n",
    "def construct_input_ref_pair(comment,AST_type,  ref_token_id, sep_token_id, cls_token_id):\n",
    "    comment = tokenizer.encode(comment, add_special_tokens=False,truncation=True,max_length=512)\n",
    "    AST_type = tokenizer.encode(AST_type, add_special_tokens=False,truncation=True,max_length=512)\n",
    "    # construct input token ids\n",
    "    input_ids = [cls_token_id] + comment + [sep_token_id] + AST_type + [sep_token_id]\n",
    "\n",
    "    # construct reference token ids \n",
    "    ref_input_ids = [cls_token_id] + [ref_token_id] * len(comment) + [sep_token_id] + \\\n",
    "        [ref_token_id] * len(AST_type) + [sep_token_id]\n",
    "    input_ids = truncate(input_ids)\n",
    "    ref_input_ids = truncate(ref_input_ids)\n",
    "    return torch.tensor([input_ids], device=device), torch.tensor([ref_input_ids], device=device), len(comment)\n",
    "\n",
    "def construct_input_ref_token_type_pair(input_ids, sep_ind=0):\n",
    "    seq_len = input_ids.size(1)\n",
    "    token_type_ids = torch.tensor([[0 if i <= sep_ind else 1 for i in range(seq_len)]], device=device)\n",
    "    ref_token_type_ids = torch.zeros_like(token_type_ids, device=device)# * -1\n",
    "    return token_type_ids, ref_token_type_ids\n",
    "\n",
    "def construct_input_ref_pos_id_pair(input_ids):\n",
    "    seq_length = input_ids.size(1)\n",
    "    position_ids = torch.arange(seq_length, dtype=torch.long, device=device)\n",
    "    # we could potentially also use random permutation with `torch.randperm(seq_length, device=device)`\n",
    "    ref_position_ids = torch.zeros(seq_length, dtype=torch.long, device=device)\n",
    "\n",
    "    position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "    ref_position_ids = ref_position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "    return position_ids, ref_position_ids\n",
    "\n",
    "def construct_attention_mask(input_ids):\n",
    "    return torch.ones_like(input_ids)\n",
    "\n",
    "def construct_whole_bert_embeddings(input_ids, ref_input_ids, \\\n",
    "                                    token_type_ids=None, ref_token_type_ids=None, \\\n",
    "                                    position_ids=None, ref_position_ids=None):\n",
    "    input_embeddings = model.roberta.embeddings(input_ids, token_type_ids=token_type_ids, position_ids=position_ids)\n",
    "    ref_input_embeddings = model.roberta.embeddings(ref_input_ids, token_type_ids=ref_token_type_ids, position_ids=ref_position_ids)\n",
    "    \n",
    "    return input_embeddings, ref_input_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0582b7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_data_list(AST_list,comment_list):\n",
    "    input_ids_all = []\n",
    "    ref_input_ids_all = []\n",
    "    position_ids_all = []\n",
    "    attention_mask_all = []\n",
    "    token_type_ids_all = []\n",
    "    all_tokens_all = []\n",
    "    for i in range(len(AST_list)):\n",
    "        input_ids, ref_input_ids, comment_len = construct_input_ref_pair(comment_list[i],AST_list[i], ref_token_id,\\\n",
    "                                                                         sep_token_id, cls_token_id)\n",
    "        token_type_ids, ref_token_type_ids = construct_input_ref_token_type_pair(input_ids, comment_len)\n",
    "        position_ids, ref_position_ids = construct_input_ref_pos_id_pair(input_ids)\n",
    "        attention_mask = construct_attention_mask(input_ids)\n",
    "        \n",
    "        indices = input_ids[0].detach().tolist()\n",
    "        \n",
    "        all_tokens = []                                       ###\n",
    "        for _, token in enumerate(indices):\n",
    "            all_tokens.append(tokenizer.decode([token]))\n",
    "        \n",
    "        input_ids_all.append(input_ids)\n",
    "        ref_input_ids_all.append(ref_input_ids)\n",
    "        position_ids_all.append(position_ids)\n",
    "        attention_mask_all.append(attention_mask)\n",
    "        token_type_ids_all.append(token_type_ids)\n",
    "        all_tokens_all.append(all_tokens)\n",
    "\n",
    "    return input_ids_all,ref_input_ids_all,position_ids_all,attention_mask_all,token_type_ids_all,all_tokens_all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a4cabf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1094ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前k个贡献最高的word 和 token_type 和 position\n",
    "# return value为归因贡献值  indices为词对应的索引  top_tokens为 词或位置或token_type\n",
    "def get_topk_attributed_tokens(attrs,all_token_t, k=5):\n",
    "    values_max, indices_max = torch.topk(attrs, k)\n",
    "    top_tokens_max = [all_token_t[idx] for idx in indices_max]\n",
    "    values_min, indices_min = torch.topk(attrs, k, largest=False)\n",
    "    top_tokens_min = [all_token_t[idx] for idx in indices_min] \n",
    "    \n",
    "    return top_tokens_max, values_max, indices_max,top_tokens_min,values_min,indices_min\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1c77cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def split_punctuation(s):\n",
    "    # 使用正则表达式匹配连续的标点符号或者字母和标点符号之间的位置\n",
    "    splits = re.finditer(r'(?<=\\w)(?=[{}])|(?<=[{}])(?=\\w)'.format(string.punctuation, string.punctuation), s)\n",
    "    \n",
    "    # 获取所有分割位置\n",
    "    split_positions = [match.start() for match in splits]\n",
    "    \n",
    "    # 在分割位置插入空格\n",
    "    for pos in reversed(split_positions):\n",
    "        s = s[:pos] + ' ' + s[pos:]\n",
    "        \n",
    "    s = s.replace(\"< s >\", \"<s>\")\n",
    "    s = s.replace(\"</ s >\", \"</s>\")\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6453886d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从 all_tokens 还原为 原单词 ，并且计算归因值\n",
    "def get_restore_words(code,comment,input_ids,all_tokens,attribution_num):\n",
    "    all_tokens_decode = tokenizer.decode(input_ids)\n",
    "    len_all_tokens_decode = len(all_tokens_decode) + 4\n",
    "    # 使用decode获得的序列，去掉分词之后的空格    例 ' a' -> 'a'\n",
    "    all_tokens_clean = []\n",
    "    for token in all_tokens:\n",
    "        s_without_leading_space = token.lstrip()\n",
    "        all_tokens_clean.append(s_without_leading_space)\n",
    "#     print('all_tokens_clean:\\n',all_tokens_clean)\n",
    "#     print('all_tokens_clean:\\n',len(all_tokens_clean))\n",
    "    \n",
    "\n",
    "    # 获得 code_comment_baseline\n",
    "    code = tokenizer.encode(code, add_special_tokens=False,truncation=True,max_length=512)\n",
    "    comment = tokenizer.encode(comment, add_special_tokens=False,truncation=True,max_length=512)\n",
    "    code_decode = tokenizer.decode(code)\n",
    "    comment_decode = tokenizer.decode(comment)\n",
    "    \n",
    "    code_comment_baseline = tokenizer.decode(tokenizer.cls_token_id) + ' '+ comment_decode \\\n",
    "                            + ' '+ tokenizer.decode(tokenizer.sep_token_id) + ' ' + code_decode \\\n",
    "                            + ' ' + tokenizer.decode(tokenizer.sep_token_id)\n",
    "    \n",
    "    code_comment_baseline = code_comment_baseline[:len_all_tokens_decode]\n",
    "    code_comment_baseline = split_punctuation(code_comment_baseline)\n",
    "    code_comment_baseline = code_comment_baseline.split()\n",
    "\n",
    "#     print('code_comment_baseline:\\n',code_comment_baseline)\n",
    "#     print('code_comment_baseline_len:\\n',len(code_comment_baseline))\n",
    "\n",
    "    \n",
    "    # 获得 相邻有几个token合并在一块的列表times  为了以后再计算attribute时求和\n",
    "    times = []\n",
    "    token_index = 0\n",
    "    for code_comment in code_comment_baseline:\n",
    "        temp = ''\n",
    "        time = 0\n",
    "        while temp != code_comment:\n",
    "            temp = temp + all_tokens_clean[token_index]\n",
    "            token_index = token_index + 1\n",
    "            time = time + 1\n",
    "        times.append(time)\n",
    "#     print('times:\\n',times)\n",
    "    \n",
    "    attribute_sum = []\n",
    "    start = 0\n",
    "    for time in times:\n",
    "        end = start + time\n",
    "        attribute = sum(attribution_num[start:end]) / time\n",
    "        attribute_sum.append(attribute)\n",
    "        start = end\n",
    "#     print('attribute_sum:\\n',attribute_sum)\n",
    "    return code_comment_baseline ,attribute_sum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea788594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_line_code_and_attribute(code,code_all_tokens,attributions_num):\n",
    "    # 特殊符号前  加空格\n",
    "    code = split_punctuation(code)\n",
    "    \n",
    "    # 把  行前空格去掉  便于单词与行之间匹配\n",
    "    code = [line.lstrip() for line in code.splitlines()]\n",
    "    code = '\\n'.join(code)  \n",
    "    code_lineList = code.split('\\n')\n",
    "    code_lineList = [' '.join(x.split()) for x in code_lineList]\n",
    "    # 有空行，把空行去掉\n",
    "    code_lineList = [item for item in code_lineList if item != '']\n",
    "    \n",
    "    attribute = []\n",
    "    i = 0  \n",
    "    for code_line in code_lineList:\n",
    "        count = 0\n",
    "        if i < len(code_all_tokens):\n",
    "            temp = code_all_tokens[i]\n",
    "            attr = attributions_num[i]\n",
    "            i = i + 1\n",
    "        while((i < len(code_all_tokens)) and(temp != code_line)):\n",
    "            attr = attr + attributions_num[i]\n",
    "            temp = temp + ' ' + code_all_tokens[i]\n",
    "            i = i + 1\n",
    "            count = count + 1\n",
    "        attribute.append(attr/count)\n",
    "\n",
    "    return code_lineList,attribute   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1432edfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_before_and_including(lst, element):\n",
    "    if element in lst:\n",
    "        index = lst.index(element)\n",
    "        lst_c = lst[index+1:]\n",
    "        if element in lst_c:\n",
    "            lst_c.remove(element)\n",
    "        return lst_c\n",
    "    else:\n",
    "        return lst\n",
    "    \n",
    "def remove_after_including(lst, element):\n",
    "    if element in lst:\n",
    "        index = lst.index(element)\n",
    "        return lst[:index + 1]\n",
    "    else:\n",
    "        return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e8dca6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comment_attribution(all_tokens,attributions_num):\n",
    "    \n",
    "    comment_all_tokens = remove_after_including(all_tokens,'</s>')   \n",
    "    index = all_tokens.index('</s>')\n",
    "    comment_all_tokens = comment_all_tokens[1:-1]\n",
    "    attribute_comment = attributions_num[1:index]\n",
    "    \n",
    "    return comment_all_tokens,attribute_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8635954e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_all_attribute(code,all_tokens,attributions_num):\n",
    "    # 删除 all_token 列表中的<s>注释</s>  </s>\n",
    "    code_all_tokens = remove_before_and_including(all_tokens,'</s>')\n",
    "    comment_all_tokens = remove_after_including(all_tokens,'</s>')  \n",
    "    index = all_tokens.index('</s>')\n",
    "    attribute_comment = attributions_num[:index+1]\n",
    "#     print(attribute_comment)\n",
    "    \n",
    "    attribute_code = attributions_num[index+1:-1]\n",
    "#     print(attribute_code,len(attribute_code))\n",
    "    code_lineList_token,attribute_num_code = get_line_code_and_attribute(code,code_all_tokens,attribute_code)\n",
    "##     print(attribute_num_code)\n",
    "    attribute_num_code = torch.stack(attribute_num_code)\n",
    "    \n",
    "    new_all_tokens = comment_all_tokens + code_lineList_token\n",
    "    attributions_num_all = torch.cat((attribute_comment, attribute_num_code))\n",
    "\n",
    "#     attributions_num_all = attribute_comment + attribute_num_code\n",
    "#     print(len(attribute_comment),len(attribute_num_code))\n",
    "#     print(new_all_tokens)\n",
    "    return new_all_tokens,attributions_num_all,code_lineList_token,attribute_num_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450e5303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "25d196c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import LayerIntegratedGradients\n",
    "from captum.attr import visualization as viz\n",
    "\n",
    "lig = LayerIntegratedGradients(squad_pos_forward_func,input_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b270703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_sentence_2(code,comment,old_code,input_ids,ref_input_ids, token_type_ids,\\\n",
    "                         position_ids, attention_mask, all_tokens):\n",
    "    pre ,out,_ = predict(input_ids,  position_ids=position_ids,attention_mask=attention_mask)\n",
    "  \n",
    "    attributions_ig, delta_ig = lig.attribute(input_ids, baselines=ref_input_ids,\\\n",
    "                           additional_forward_args=(position_ids,attention_mask,0),return_convergence_delta=True,internal_batch_size=8)\n",
    "    \n",
    "    attributions = attributions_ig.sum(dim=2).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "#     print(delta_ig)\n",
    "#     print(attributions)\n",
    "    try:\n",
    "        all_tokens ,attributions = get_restore_words(code,comment,input_ids[0],all_tokens,attributions)     # 合并为一个单词\n",
    "        attributions = torch.tensor(attributions)\n",
    "        \n",
    "        comment_token,comment_attribute = get_comment_attribution(all_tokens,attributions)\n",
    "       \n",
    "        # code_lineList_token 和 attribute_num_code 用于后续统计分析\n",
    "        new_all_tokens,attributions_num_all,code_lineList_token,attribute_num_code = final_all_attribute(code,all_tokens,attributions)\n",
    "\n",
    "        return out,code_lineList_token,attribute_num_code,comment_token,comment_attribute \n",
    "    except Exception as e:\n",
    "#         pass\n",
    "        print(\"解析错误\")\n",
    "        return -1,_,_,_,_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b26fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bafb88a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346ef47e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19adae4e",
   "metadata": {},
   "source": [
    "判断行级贡献值分布情况，将一些特殊语句变为一个具有代表性的词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "227bba4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单个示例获取各种statement 的函数\n",
    "def get_ifstatement(code_line,attribution_num):\n",
    "    code_contains_if = [(i, s) for i, s in enumerate(code_line) if 'if' in s]\n",
    "    attr_contains_if = [attribution_num[code_contains_if[i][0]] for i in range(len(code_contains_if))]\n",
    "    return code_contains_if,attr_contains_if\n",
    "def get_forstatement(code_line,attribution_num):\n",
    "    code_contains_for = [(i, s) for i, s in enumerate(code_line) if 'for' in s]\n",
    "    attr_contains_for = [attribution_num[code_contains_for[i][0]] for i in range(len(code_contains_for))]\n",
    "    return code_contains_for,attr_contains_for\n",
    "def get_whilestatement(code_line,attribution_num):\n",
    "    code_contains_while = [(i, s) for i, s in enumerate(code_line) if 'while' in s]\n",
    "    attr_contains_while = [attribution_num[code_contains_while[i][0]] for i in range(len(code_contains_while))]\n",
    "    return code_contains_while,attr_contains_while\n",
    "def get_variableDeclaration(code_line,attribution_num):\n",
    "    code_contains_new = [(i, s) for i, s in enumerate(code_line) if 'new' in s]\n",
    "    attr_contains_new = [attribution_num[code_contains_new[i][0]] for i in range(len(code_contains_new))]\n",
    "    return code_contains_new,attr_contains_new\n",
    "def get_expression(code_line,attribution_num):\n",
    "    code_contains_exp = [(i, s) for i, s in enumerate(code_line) if '=' in s]\n",
    "    attr_contains_exp = [attribution_num[code_contains_exp[i][0]] for i in range(len(code_contains_exp))]\n",
    "    return code_contains_exp,attr_contains_exp\n",
    "def get_try_catch(code_line,attribution_num):\n",
    "    code_contains_try_catch = [(i, s) for i, s in enumerate(code_line) if 'try' in s]\n",
    "    attr_contains_try_catch = [attribution_num[code_contains_try_catch[i][0]] for i in range(len(code_contains_try_catch))]\n",
    "    return code_contains_try_catch,attr_contains_try_catch\n",
    "def get_return(code_line,attribution_num):\n",
    "    code_contains_return = [(i, s) for i, s in enumerate(code_line) if 'return' in s]\n",
    "    attr_contains_return = [attribution_num[code_contains_return[i][0]] for i in range(len(code_contains_return))]\n",
    "    return code_contains_return,attr_contains_return\n",
    "def get_MethodDeclaration(code_line,attribution_num):\n",
    "    code_contains_Method = [code_line[0]]\n",
    "    attr_contains_Method = [attribution_num[0]]\n",
    "    return code_contains_Method,attr_contains_Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "17c3536d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 集成到数据集中 , 对返回值进行数据分析 , 六个列表试着画小提琴图\n",
    "def get_all_statement(code_line_list,attribution_num_list):\n",
    "    ifstatement ,ifstatement_num = [],[]\n",
    "    forstatement ,forstatement_num = [],[]\n",
    "    whilestatement ,whilestatement_num = [],[]\n",
    "    variableDeclaration ,variableDeclaration_num = [],[]\n",
    "    expression ,expression_num = [],[]\n",
    "    trystatement ,trystatement_num = [],[]\n",
    "    returnstatement ,returnstatement_num = [],[]\n",
    "    MethodDeclaration ,MethodDeclaration_num = [],[]\n",
    "    for (code_line,attribution_num) in zip(code_line_list,attribution_num_list):\n",
    "#         print(code_line,attribution_num)\n",
    "        code_contains_if,attr_contains_if = get_ifstatement(code_line,attribution_num)\n",
    "        code_contains_for,attr_contains_for = get_forstatement(code_line,attribution_num)\n",
    "        code_contains_while,attr_contains_while = get_whilestatement(code_line,attribution_num)\n",
    "        code_contains_new,attr_contains_new = get_variableDeclaration(code_line,attribution_num)\n",
    "        code_contains_exp,attr_contains_exp = get_expression(code_line,attribution_num)\n",
    "        code_contains_try_catch,attr_contains_try_catch = get_try_catch(code_line,attribution_num)\n",
    "        code_contains_return,attr_contains_return = get_return(code_line,attribution_num)\n",
    "        code_contains_Method,attr_contains_Method = get_MethodDeclaration(code_line,attribution_num)\n",
    "        \n",
    "        ifstatement.append(code_contains_if ) if code_contains_if != [] else None\n",
    "        ifstatement_num.append(attr_contains_if ) if attr_contains_if != [] else None\n",
    "        forstatement.append(code_contains_for ) if code_contains_for != [] else None\n",
    "        forstatement_num.append(attr_contains_for) if attr_contains_for != [] else None\n",
    "        whilestatement.append(code_contains_while ) if code_contains_while != [] else None\n",
    "        whilestatement_num.append(attr_contains_while ) if attr_contains_while != [] else None\n",
    "        variableDeclaration.append(code_contains_new ) if code_contains_new != [] else None\n",
    "        variableDeclaration_num.append(attr_contains_new) if attr_contains_new != [] else None\n",
    "        expression.append(code_contains_exp ) if code_contains_exp != [] else None\n",
    "        expression_num.append(attr_contains_exp ) if attr_contains_exp != [] else None  \n",
    "        \n",
    "        trystatement.append(code_contains_try_catch ) if code_contains_try_catch != [] else None\n",
    "        trystatement_num.append(attr_contains_try_catch ) if attr_contains_try_catch != [] else None \n",
    "        \n",
    "        returnstatement.append(code_contains_return ) if code_contains_return != [] else None\n",
    "        returnstatement_num.append(attr_contains_return ) if attr_contains_return != [] else None               \n",
    "        MethodDeclaration.append(code_contains_Method ) if code_contains_Method != [] else None\n",
    "        MethodDeclaration_num.append(attr_contains_Method ) if attr_contains_Method != [] else None\n",
    "        \n",
    "    return ifstatement_num,forstatement_num,whilestatement_num,variableDeclaration_num,expression_num,\\\n",
    "           trystatement_num,returnstatement_num,MethodDeclaration_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e1c50634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 展开内部列表,便于统计\n",
    "def flattened_list(lst):\n",
    "    flattened_lst = [item for sublist in lst for item in sublist]\n",
    "    return flattened_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d82ffcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_line_attribution(df):\n",
    "    code_list = df['new_code_raw']\n",
    "    comment_list = df['old_comment_raw']\n",
    "    code_list_old = df['old_code_raw']\n",
    "    ground_lable = df['label']\n",
    "    \n",
    "    input_ids_all,ref_input_ids_all,position_ids_all,attention_mask_all,\\\n",
    "    token_type_ids_all,all_tokens_all= input_data_list(code_list,comment_list)\n",
    "    \n",
    "    code_lineList_token_true = []\n",
    "    attribute_num_code_true = []\n",
    "    comment_token_true = []\n",
    "    comment_attribute_true = []\n",
    "    index_true = []\n",
    "    \n",
    "    code_lineList_token_false = []\n",
    "    attribute_num_code_false = []\n",
    "    comment_token_false = []\n",
    "    comment_attribute_false = []\n",
    "    index_false = []\n",
    "\n",
    "    for i in range(len(code_list)): \n",
    "        out,code_lineList_token,attribute_num_code,comment_token,comment_attribute  \\\n",
    "        = interpret_sentence_2(code_list[i],comment_list[i],\\\n",
    "                               code_list_old[i],input_ids_all[i],\\\n",
    "                               ref_input_ids_all[i], token_type_ids_all[i],\\\n",
    "                               position_ids_all[i],attention_mask_all[i], all_tokens_all[i])\n",
    "        if out != -1:\n",
    "            if out == ground_lable[i]:\n",
    "                index_true.append(i)\n",
    "                code_lineList_token_true.append(code_lineList_token)\n",
    "                attribute_num_code_true.append(attribute_num_code)\n",
    "                comment_token_true.append(comment_token)\n",
    "                comment_attribute_true.append(comment_attribute)\n",
    "\n",
    "            else :\n",
    "                index_false.append(i)\n",
    "                code_lineList_token_false.append(code_lineList_token)\n",
    "                attribute_num_code_false.append(attribute_num_code)\n",
    "                comment_token_false.append(comment_token)\n",
    "                comment_attribute_false.append(comment_attribute)\n",
    "    return index_true,index_false,\\\n",
    "           code_lineList_token_true,attribute_num_code_true,\\\n",
    "           code_lineList_token_false,attribute_num_code_false,\\\n",
    "           comment_token_true,comment_attribute_true,\\\n",
    "           comment_token_false,comment_attribute_false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19b1183",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8c211d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "解析错误\n",
      "解析错误\n",
      "解析错误\n",
      "解析错误\n"
     ]
    }
   ],
   "source": [
    "index_true,index_false,\\\n",
    "code_lineList_token_true,attribute_num_code_true,\\\n",
    "code_lineList_token_false,attribute_num_code_false,\\\n",
    "comment_token_true,comment_attribute_true,\\\n",
    "comment_token_false,comment_attribute_false\\\n",
    "= analyse_line_attribution(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e89d43fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_true = df_clean.loc[index_true]\n",
    "# df_true['O_index'] = index_true\n",
    "# df_true.to_json('linelevel_pre_true.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3db632f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_false = df_clean.loc[index_false]\n",
    "# df_true['O_index'] = index_false\n",
    "# df_false.to_json('linelevel_pre_false.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "894e0fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# true comment\n",
    "with open('comment_attribute_true.txt', 'w') as f:\n",
    "    for key, value in zip(comment_token_true, comment_attribute_true):\n",
    "        value_list = value.tolist()\n",
    "        f.write(f\"{key}\\n{value_list}\\n\")\n",
    "# false comment\n",
    "with open('comment_attribute_false.txt', 'w') as f:\n",
    "    for key, value in zip(comment_token_false, comment_attribute_false):\n",
    "        value_list = value.tolist()\n",
    "        f.write(f\"{key}\\n{value_list}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaec1819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0a1f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_print_df(df, name):\n",
    "    col_list = []\n",
    "    for i in range(len(df)):\n",
    "        if df.loc[i]['key'] == name:\n",
    "            attr = df.loc[i]['value']\n",
    "            col_list.append(attr)\n",
    "    df = pd.DataFrame(col_list, columns=[name])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9a9711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_df(df):\n",
    "    unique_values = df['key'].value_counts().index\n",
    "    plt.figure(figsize=(40,10))\n",
    "\n",
    "    for uniq in unique_values:\n",
    "        attr = get_list_print_df(df, uniq)\n",
    "\n",
    "        sns.kdeplot(data=attr, x=uniq, label=uniq, bw_adjust=8)\n",
    "\n",
    "        xticks = np.arange(min(attr[uniq]), max(attr[uniq]), step=0.5)\n",
    "        plt.xticks(xticks)\n",
    "        # 添加图例\n",
    "    plt.legend()\n",
    "    plt.axvline(x=0, color='r', linestyle='--')  # 在 x=0 的位置添加一条红色的虚线\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02553638",
   "metadata": {},
   "source": [
    "true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cddc500",
   "metadata": {},
   "outputs": [],
   "source": [
    "ifstatement_num,forstatement_num,whilestatement_num,variableDeclaration_num,\\\n",
    "expression_num,trystatement_num,returnstatement_num,MethodDeclaration_num = get_all_statement(code_lineList_token_true,attribute_num_code_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63e58d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ifstatement_num = flattened_list(ifstatement_num)\n",
    "forstatement_num = flattened_list(forstatement_num)\n",
    "whilestatement_num = flattened_list(whilestatement_num)\n",
    "variableDeclaration_num = flattened_list(variableDeclaration_num)\n",
    "expression_num = flattened_list(expression_num)\n",
    "trystatement_num = flattened_list(trystatement_num)\n",
    "returnstatement_num = flattened_list(returnstatement_num)\n",
    "MethodDeclaration_num = flattened_list(MethodDeclaration_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad07169f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [ifstatement_num,forstatement_num,whilestatement_num,variableDeclaration_num,\\\n",
    "        expression_num,trystatement_num,returnstatement_num,MethodDeclaration_num ]\n",
    "keys = ['ifstatement_num', 'forstatement_num', 'whilestatement_num', 'variableDeclaration_num',\n",
    "        'expression_num', 'trystatement_num', 'returnstatement_num', 'MethodDeclaration_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94615e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_df = pd.DataFrame()\n",
    "\n",
    "for key, values in zip(keys, data):\n",
    "    temp_df = pd.DataFrame()\n",
    "    temp_df['value'] = values\n",
    "    temp_df['key'] = key\n",
    "    line_df = pd.concat([line_df, temp_df])\n",
    "line_df = line_df.reset_index(drop=True)\n",
    "line_df['value'] = line_df['value'].apply(lambda x: x.item())\n",
    "line_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad2dd6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(line_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10063ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# line_df.to_json('linelevel_attribution_true.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b84c3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用seaborn绘制小提琴图\n",
    "plt.figure(figsize=(20,7))\n",
    "sns.violinplot(x='key', y='value', data=line_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282a0f29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9870e3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values = line_df['key'].value_counts().index\n",
    "unique_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33b3c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "attr = get_list_print_df(line_df, unique_values[0])\n",
    "attr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba12636a",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_df(line_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbf7526",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f883fae0",
   "metadata": {},
   "source": [
    "false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fcdc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "ifstatement_num,forstatement_num,whilestatement_num,variableDeclaration_num,\\\n",
    "expression_num,trystatement_num,returnstatement_num,MethodDeclaration_num = get_all_statement(code_lineList_token_false,attribute_num_code_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b75b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "ifstatement_num = flattened_list(ifstatement_num)\n",
    "forstatement_num = flattened_list(forstatement_num)\n",
    "whilestatement_num = flattened_list(whilestatement_num)\n",
    "variableDeclaration_num = flattened_list(variableDeclaration_num)\n",
    "expression_num = flattened_list(expression_num)\n",
    "trystatement_num = flattened_list(trystatement_num)\n",
    "returnstatement_num = flattened_list(returnstatement_num)\n",
    "MethodDeclaration_num = flattened_list(MethodDeclaration_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4ad8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [ifstatement_num,forstatement_num,whilestatement_num,variableDeclaration_num,\\\n",
    "        expression_num,trystatement_num,returnstatement_num,MethodDeclaration_num ]\n",
    "keys = ['ifstatement_num', 'forstatement_num', 'whilestatement_num', 'variableDeclaration_num',\n",
    "        'expression_num', 'trystatement_num', 'returnstatement_num', 'MethodDeclaration_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1496346a",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_df = pd.DataFrame()\n",
    "\n",
    "for key, values in zip(keys, data):\n",
    "    temp_df = pd.DataFrame()\n",
    "    temp_df['value'] = values\n",
    "    temp_df['key'] = key\n",
    "    line_df = pd.concat([line_df, temp_df])\n",
    "line_df = line_df.reset_index(drop=True)\n",
    "line_df['value'] = line_df['value'].apply(lambda x: x.item())\n",
    "line_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3311176d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# line_df.to_json('linelevel_attribution_false.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7849a687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用seaborn绘制小提琴图\n",
    "plt.figure(figsize=(20,7))\n",
    "sns.violinplot(x='key', y='value', data=line_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a69414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ec710c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values = line_df['key'].value_counts().index\n",
    "unique_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88e44e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "attr = get_list_print_df(line_df, unique_values[0])\n",
    "attr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbd97e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_df(line_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b868e384",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leitx",
   "language": "python",
   "name": "leitx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
