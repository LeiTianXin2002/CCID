{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ad6ca09",
   "metadata": {},
   "source": [
    "此  .ipynb  把测试集代码的 ast 进行归因贡献值计算，并且对父节点(AST_statement)的不同类型。根据统计分析结果。\n",
    "<br>打印出 <br>\n",
    "[('MethodDeclaration', 0.022379315476190476)]<br>\n",
    "[('树级语句类型','贡献值')]<br>\n",
    "0<br>\n",
    "索引<br>\n",
    "挑出实例，不用挑太多"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d654ff16",
   "metadata": {},
   "source": [
    "将每个实例中的类别贡献值与统计分析中的绝对值均值进行大小比较，大于绝对值均值的保留"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e84e3fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import javalang\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "\n",
    "\n",
    "from captum.attr import visualization as viz\n",
    "from captum.attr import LayerConductance, LayerIntegratedGradients\n",
    "from captum.attr import configure_interpretable_embedding_layer, remove_interpretable_embedding_layer\n",
    "\n",
    "# 解决服务器挂掉的问题\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ff062613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device( \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bf31e07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 1024\n",
    "MAX_EPOCHS = 10\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 1e-5\n",
    "NUM_CLASSES = 2\n",
    "WEIGTH_DECAY = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9449ad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_test_data():\n",
    "    test_param = pd.read_json(\"D:/BERT_learing/code_comment_inconsistency_detection/data/param/test.json\")\n",
    "    test_return = pd.read_json(\"D:/BERT_learing/code_comment_inconsistency_detection/data/return/test.json\")\n",
    "    test_summary = pd.read_json(\"D:/BERT_learing/code_comment_inconsistency_detection/data/summary/test.json\")\n",
    "    test_df = pd.concat([test_summary,test_param, test_return], axis=0)\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "    return test_df\n",
    "def retrieve_train_data():\n",
    "    test_param = pd.read_json(\"D:/BERT_learing/code_comment_inconsistency_detection/data/param/train.json\")\n",
    "    test_return = pd.read_json(\"D:/BERT_learing/code_comment_inconsistency_detection/data/return/train.json\")\n",
    "    test_summary = pd.read_json(\"D:/BERT_learing/code_comment_inconsistency_detection/data/summary/train.json\")\n",
    "    test_df = pd.concat([test_summary,test_param, test_return], axis=0)\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "    return test_df\n",
    "test_df = retrieve_test_data()\n",
    "train_df = retrieve_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8e1ea51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_1 = train_df[610:611]\n",
    "train_df_2 = train_df[716:717]\n",
    "test_df_3 = test_df[65:66]\n",
    "train_df_4 = train_df[363:364]\n",
    "\n",
    "test_df = pd.concat([train_df_1,train_df_2, test_df_3,train_df_4], axis=0)\n",
    "test_df = test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9eda5d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>comment_type</th>\n",
       "      <th>old_comment_raw</th>\n",
       "      <th>old_comment_subtokens</th>\n",
       "      <th>new_comment_raw</th>\n",
       "      <th>new_comment_subtokens</th>\n",
       "      <th>span_minimal_diff_comment_subtokens</th>\n",
       "      <th>old_code_raw</th>\n",
       "      <th>old_code_subtokens</th>\n",
       "      <th>new_code_raw</th>\n",
       "      <th>new_code_subtokens</th>\n",
       "      <th>span_diff_code_subtokens</th>\n",
       "      <th>token_diff_code_subtokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>orientechnologies_orientdb-1949-FirstSentence-0</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Returns a OrientBaseGraph implementation from ...</td>\n",
       "      <td>[returns, a, orient, base, graph, implementati...</td>\n",
       "      <td>Returns a Transactional OrientGraph implementa...</td>\n",
       "      <td>[returns, a, transactional, orient, graph, imp...</td>\n",
       "      <td>[&lt;INSERT_OLD_KEEP_BEFORE&gt;, a, &lt;INSERT_NEW_KEEP...</td>\n",
       "      <td>public static OrientBaseGraph getGraph() {\\n...</td>\n",
       "      <td>[public, static, orient, base, graph, get, gra...</td>\n",
       "      <td>public static OrientBaseGraph getGraph() {\\n...</td>\n",
       "      <td>[public, static, orient, base, graph, get, gra...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, orient, base, graph, ...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;KEEP&gt;, orien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spring_projects_spring_boot-882-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Creates a  exception tag based on the  Class#g...</td>\n",
       "      <td>[creates, a, exception, tag, based, on, the, c...</td>\n",
       "      <td>Creates a  exception tag based on the  Class#g...</td>\n",
       "      <td>[creates, a, exception, tag, based, on, the, c...</td>\n",
       "      <td>[]</td>\n",
       "      <td>\\tpublic static Tag exception(Throwable except...</td>\n",
       "      <td>[public, static, tag, exception, (, throwable,...</td>\n",
       "      <td>\\tpublic static Tag exception(Throwable except...</td>\n",
       "      <td>[public, static, tag, exception, (, throwable,...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, tag, exception, (, th...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;KEEP&gt;, tag, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stanfordnlp_CoreNLP-191-Associations-FirstSent...</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Returns all currently displayed sentences in p...</td>\n",
       "      <td>[returns, all, currently, displayed, sentences...</td>\n",
       "      <td>Returns all currently displayed sentences in s...</td>\n",
       "      <td>[returns, all, currently, displayed, sentences...</td>\n",
       "      <td>[&lt;INSERT_OLD_KEEP_BEFORE&gt;, in, &lt;INSERT_NEW_KEE...</td>\n",
       "      <td>public String getMatchedSentences() {\\n    S...</td>\n",
       "      <td>[public, string, get, matched, sentences, (, )...</td>\n",
       "      <td>public StringBuffer getMatchedSentences() {\\...</td>\n",
       "      <td>[public, string, buffer, get, matched, sentenc...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, string, &lt;KEEP_END&gt;, &lt;INSERT&gt;,...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, string, &lt;INSERT&gt;, buf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>raphw_byte_buddy-1042-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Creates a  net.bytebuddy.implementation.Defaul...</td>\n",
       "      <td>[creates, a, net, ., bytebuddy, ., implementat...</td>\n",
       "      <td>Creates a  net.bytebuddy.implementation.Defaul...</td>\n",
       "      <td>[creates, a, net, ., bytebuddy, ., implementat...</td>\n",
       "      <td>[]</td>\n",
       "      <td>public static Implementation prioritize(It...</td>\n",
       "      <td>[public, static, implementation, prioritize, (...</td>\n",
       "      <td>public static Implementation prioritize(It...</td>\n",
       "      <td>[public, static, implementation, prioritize, (...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, implementation, prior...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;KEEP&gt;, imple...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  label comment_type  \\\n",
       "0    orientechnologies_orientdb-1949-FirstSentence-0      1      Summary   \n",
       "1    spring_projects_spring_boot-882-FirstSentence-0      0      Summary   \n",
       "2  stanfordnlp_CoreNLP-191-Associations-FirstSent...      1      Summary   \n",
       "3              raphw_byte_buddy-1042-FirstSentence-0      0      Summary   \n",
       "\n",
       "                                     old_comment_raw  \\\n",
       "0  Returns a OrientBaseGraph implementation from ...   \n",
       "1  Creates a  exception tag based on the  Class#g...   \n",
       "2  Returns all currently displayed sentences in p...   \n",
       "3  Creates a  net.bytebuddy.implementation.Defaul...   \n",
       "\n",
       "                               old_comment_subtokens  \\\n",
       "0  [returns, a, orient, base, graph, implementati...   \n",
       "1  [creates, a, exception, tag, based, on, the, c...   \n",
       "2  [returns, all, currently, displayed, sentences...   \n",
       "3  [creates, a, net, ., bytebuddy, ., implementat...   \n",
       "\n",
       "                                     new_comment_raw  \\\n",
       "0  Returns a Transactional OrientGraph implementa...   \n",
       "1  Creates a  exception tag based on the  Class#g...   \n",
       "2  Returns all currently displayed sentences in s...   \n",
       "3  Creates a  net.bytebuddy.implementation.Defaul...   \n",
       "\n",
       "                               new_comment_subtokens  \\\n",
       "0  [returns, a, transactional, orient, graph, imp...   \n",
       "1  [creates, a, exception, tag, based, on, the, c...   \n",
       "2  [returns, all, currently, displayed, sentences...   \n",
       "3  [creates, a, net, ., bytebuddy, ., implementat...   \n",
       "\n",
       "                 span_minimal_diff_comment_subtokens  \\\n",
       "0  [<INSERT_OLD_KEEP_BEFORE>, a, <INSERT_NEW_KEEP...   \n",
       "1                                                 []   \n",
       "2  [<INSERT_OLD_KEEP_BEFORE>, in, <INSERT_NEW_KEE...   \n",
       "3                                                 []   \n",
       "\n",
       "                                        old_code_raw  \\\n",
       "0    public static OrientBaseGraph getGraph() {\\n...   \n",
       "1  \\tpublic static Tag exception(Throwable except...   \n",
       "2    public String getMatchedSentences() {\\n    S...   \n",
       "3      public static Implementation prioritize(It...   \n",
       "\n",
       "                                  old_code_subtokens  \\\n",
       "0  [public, static, orient, base, graph, get, gra...   \n",
       "1  [public, static, tag, exception, (, throwable,...   \n",
       "2  [public, string, get, matched, sentences, (, )...   \n",
       "3  [public, static, implementation, prioritize, (...   \n",
       "\n",
       "                                        new_code_raw  \\\n",
       "0    public static OrientBaseGraph getGraph() {\\n...   \n",
       "1  \\tpublic static Tag exception(Throwable except...   \n",
       "2    public StringBuffer getMatchedSentences() {\\...   \n",
       "3      public static Implementation prioritize(It...   \n",
       "\n",
       "                                  new_code_subtokens  \\\n",
       "0  [public, static, orient, base, graph, get, gra...   \n",
       "1  [public, static, tag, exception, (, throwable,...   \n",
       "2  [public, string, buffer, get, matched, sentenc...   \n",
       "3  [public, static, implementation, prioritize, (...   \n",
       "\n",
       "                            span_diff_code_subtokens  \\\n",
       "0  [<KEEP>, public, static, orient, base, graph, ...   \n",
       "1  [<KEEP>, public, static, tag, exception, (, th...   \n",
       "2  [<KEEP>, public, string, <KEEP_END>, <INSERT>,...   \n",
       "3  [<KEEP>, public, static, implementation, prior...   \n",
       "\n",
       "                           token_diff_code_subtokens  \n",
       "0  [<KEEP>, public, <KEEP>, static, <KEEP>, orien...  \n",
       "1  [<KEEP>, public, <KEEP>, static, <KEEP>, tag, ...  \n",
       "2  [<KEEP>, public, <KEEP>, string, <INSERT>, buf...  \n",
       "3  [<KEEP>, public, <KEEP>, static, <KEEP>, imple...  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bf819be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "57d3ce75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用这个，这个对了\n",
    "def get_blocks_improved_BFS_code(root):\n",
    "    queue = []\n",
    "    nodes = []\n",
    "    queue.append(root)\n",
    "    level = 0\n",
    "    while queue:\n",
    "        level = level + 1\n",
    "        for i in range(len(queue)):\n",
    "            node = queue.pop(0)\n",
    "            nodes.append(node)\n",
    "            if hasattr(node, 'children'):\n",
    "                for child in node.children:\n",
    "                    queue.append(child)\n",
    "            else:\n",
    "                try:\n",
    "                    len_node = len(node)\n",
    "                    for i in range(len_node):\n",
    "                        if hasattr(node[i], 'children'):\n",
    "                            for child in node[i].children:\n",
    "                                 queue.append(child)\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "    for node in nodes:\n",
    "        if isinstance(node, javalang.tree.Node):\n",
    "            index = nodes.index(node)\n",
    "            nodes[index] = type(node).__name__\n",
    "        if isinstance(node, list):\n",
    "            for no in node:\n",
    "                if isinstance(no, javalang.tree.Node):\n",
    "                    index = node.index(no)\n",
    "                    node[index] = type(no).__name__\n",
    "\n",
    "            \n",
    "    return level,nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0c5aab33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>comment_type</th>\n",
       "      <th>old_comment_raw</th>\n",
       "      <th>old_comment_subtokens</th>\n",
       "      <th>new_comment_raw</th>\n",
       "      <th>new_comment_subtokens</th>\n",
       "      <th>span_minimal_diff_comment_subtokens</th>\n",
       "      <th>old_code_raw</th>\n",
       "      <th>old_code_subtokens</th>\n",
       "      <th>new_code_raw</th>\n",
       "      <th>new_code_subtokens</th>\n",
       "      <th>span_diff_code_subtokens</th>\n",
       "      <th>token_diff_code_subtokens</th>\n",
       "      <th>AST_level</th>\n",
       "      <th>AST_BFSnodes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>orientechnologies_orientdb-1949-FirstSentence-0</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Returns a OrientBaseGraph implementation from ...</td>\n",
       "      <td>[returns, a, orient, base, graph, implementati...</td>\n",
       "      <td>Returns a Transactional OrientGraph implementa...</td>\n",
       "      <td>[returns, a, transactional, orient, graph, imp...</td>\n",
       "      <td>[&lt;INSERT_OLD_KEEP_BEFORE&gt;, a, &lt;INSERT_NEW_KEEP...</td>\n",
       "      <td>public static OrientBaseGraph getGraph() {\\n...</td>\n",
       "      <td>[public, static, orient, base, graph, get, gra...</td>\n",
       "      <td>public static OrientBaseGraph getGraph() {\\n...</td>\n",
       "      <td>[public, static, orient, base, graph, get, gra...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, orient, base, graph, ...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;KEEP&gt;, orien...</td>\n",
       "      <td>8</td>\n",
       "      <td>[MethodDeclaration, None, {static, public}, []...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spring_projects_spring_boot-882-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Creates a  exception tag based on the  Class#g...</td>\n",
       "      <td>[creates, a, exception, tag, based, on, the, c...</td>\n",
       "      <td>Creates a  exception tag based on the  Class#g...</td>\n",
       "      <td>[creates, a, exception, tag, based, on, the, c...</td>\n",
       "      <td>[]</td>\n",
       "      <td>\\tpublic static Tag exception(Throwable except...</td>\n",
       "      <td>[public, static, tag, exception, (, throwable,...</td>\n",
       "      <td>\\tpublic static Tag exception(Throwable except...</td>\n",
       "      <td>[public, static, tag, exception, (, throwable,...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, tag, exception, (, th...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;KEEP&gt;, tag, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>[MethodDeclaration, None, {static, public}, []...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stanfordnlp_CoreNLP-191-Associations-FirstSent...</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Returns all currently displayed sentences in p...</td>\n",
       "      <td>[returns, all, currently, displayed, sentences...</td>\n",
       "      <td>Returns all currently displayed sentences in s...</td>\n",
       "      <td>[returns, all, currently, displayed, sentences...</td>\n",
       "      <td>[&lt;INSERT_OLD_KEEP_BEFORE&gt;, in, &lt;INSERT_NEW_KEE...</td>\n",
       "      <td>public String getMatchedSentences() {\\n    S...</td>\n",
       "      <td>[public, string, get, matched, sentences, (, )...</td>\n",
       "      <td>public StringBuffer getMatchedSentences() {\\...</td>\n",
       "      <td>[public, string, buffer, get, matched, sentenc...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, string, &lt;KEEP_END&gt;, &lt;INSERT&gt;,...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, string, &lt;INSERT&gt;, buf...</td>\n",
       "      <td>10</td>\n",
       "      <td>[MethodDeclaration, None, {public}, [], None, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>raphw_byte_buddy-1042-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Creates a  net.bytebuddy.implementation.Defaul...</td>\n",
       "      <td>[creates, a, net, ., bytebuddy, ., implementat...</td>\n",
       "      <td>Creates a  net.bytebuddy.implementation.Defaul...</td>\n",
       "      <td>[creates, a, net, ., bytebuddy, ., implementat...</td>\n",
       "      <td>[]</td>\n",
       "      <td>public static Implementation prioritize(It...</td>\n",
       "      <td>[public, static, implementation, prioritize, (...</td>\n",
       "      <td>public static Implementation prioritize(It...</td>\n",
       "      <td>[public, static, implementation, prioritize, (...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, implementation, prior...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;KEEP&gt;, imple...</td>\n",
       "      <td>9</td>\n",
       "      <td>[MethodDeclaration, None, {static, public}, []...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  label comment_type  \\\n",
       "0    orientechnologies_orientdb-1949-FirstSentence-0      1      Summary   \n",
       "1    spring_projects_spring_boot-882-FirstSentence-0      0      Summary   \n",
       "2  stanfordnlp_CoreNLP-191-Associations-FirstSent...      1      Summary   \n",
       "3              raphw_byte_buddy-1042-FirstSentence-0      0      Summary   \n",
       "\n",
       "                                     old_comment_raw  \\\n",
       "0  Returns a OrientBaseGraph implementation from ...   \n",
       "1  Creates a  exception tag based on the  Class#g...   \n",
       "2  Returns all currently displayed sentences in p...   \n",
       "3  Creates a  net.bytebuddy.implementation.Defaul...   \n",
       "\n",
       "                               old_comment_subtokens  \\\n",
       "0  [returns, a, orient, base, graph, implementati...   \n",
       "1  [creates, a, exception, tag, based, on, the, c...   \n",
       "2  [returns, all, currently, displayed, sentences...   \n",
       "3  [creates, a, net, ., bytebuddy, ., implementat...   \n",
       "\n",
       "                                     new_comment_raw  \\\n",
       "0  Returns a Transactional OrientGraph implementa...   \n",
       "1  Creates a  exception tag based on the  Class#g...   \n",
       "2  Returns all currently displayed sentences in s...   \n",
       "3  Creates a  net.bytebuddy.implementation.Defaul...   \n",
       "\n",
       "                               new_comment_subtokens  \\\n",
       "0  [returns, a, transactional, orient, graph, imp...   \n",
       "1  [creates, a, exception, tag, based, on, the, c...   \n",
       "2  [returns, all, currently, displayed, sentences...   \n",
       "3  [creates, a, net, ., bytebuddy, ., implementat...   \n",
       "\n",
       "                 span_minimal_diff_comment_subtokens  \\\n",
       "0  [<INSERT_OLD_KEEP_BEFORE>, a, <INSERT_NEW_KEEP...   \n",
       "1                                                 []   \n",
       "2  [<INSERT_OLD_KEEP_BEFORE>, in, <INSERT_NEW_KEE...   \n",
       "3                                                 []   \n",
       "\n",
       "                                        old_code_raw  \\\n",
       "0    public static OrientBaseGraph getGraph() {\\n...   \n",
       "1  \\tpublic static Tag exception(Throwable except...   \n",
       "2    public String getMatchedSentences() {\\n    S...   \n",
       "3      public static Implementation prioritize(It...   \n",
       "\n",
       "                                  old_code_subtokens  \\\n",
       "0  [public, static, orient, base, graph, get, gra...   \n",
       "1  [public, static, tag, exception, (, throwable,...   \n",
       "2  [public, string, get, matched, sentences, (, )...   \n",
       "3  [public, static, implementation, prioritize, (...   \n",
       "\n",
       "                                        new_code_raw  \\\n",
       "0    public static OrientBaseGraph getGraph() {\\n...   \n",
       "1  \\tpublic static Tag exception(Throwable except...   \n",
       "2    public StringBuffer getMatchedSentences() {\\...   \n",
       "3      public static Implementation prioritize(It...   \n",
       "\n",
       "                                  new_code_subtokens  \\\n",
       "0  [public, static, orient, base, graph, get, gra...   \n",
       "1  [public, static, tag, exception, (, throwable,...   \n",
       "2  [public, string, buffer, get, matched, sentenc...   \n",
       "3  [public, static, implementation, prioritize, (...   \n",
       "\n",
       "                            span_diff_code_subtokens  \\\n",
       "0  [<KEEP>, public, static, orient, base, graph, ...   \n",
       "1  [<KEEP>, public, static, tag, exception, (, th...   \n",
       "2  [<KEEP>, public, string, <KEEP_END>, <INSERT>,...   \n",
       "3  [<KEEP>, public, static, implementation, prior...   \n",
       "\n",
       "                           token_diff_code_subtokens  AST_level  \\\n",
       "0  [<KEEP>, public, <KEEP>, static, <KEEP>, orien...          8   \n",
       "1  [<KEEP>, public, <KEEP>, static, <KEEP>, tag, ...          9   \n",
       "2  [<KEEP>, public, <KEEP>, string, <INSERT>, buf...         10   \n",
       "3  [<KEEP>, public, <KEEP>, static, <KEEP>, imple...          9   \n",
       "\n",
       "                                        AST_BFSnodes  \n",
       "0  [MethodDeclaration, None, {static, public}, []...  \n",
       "1  [MethodDeclaration, None, {static, public}, []...  \n",
       "2  [MethodDeclaration, None, {public}, [], None, ...  \n",
       "3  [MethodDeclaration, None, {static, public}, []...  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用javalang解析数据，将AST的层数,和ASTnodes(ast层次遍历结果)  变为dataframe中的一列，返回新的dataframe\n",
    "\n",
    "def get_BFS_df(df):\n",
    "\n",
    "    error_index = []\n",
    "    asts = []\n",
    "    levels = []\n",
    "    nodes = []\n",
    "    for i in range(len(df)):\n",
    "        tokens_t = javalang.tokenizer.tokenize(df.loc[i]['new_code_raw'])\n",
    "        try:\n",
    "            parser = javalang.parse.Parser(tokens_t)\n",
    "        except Exception as e:\n",
    "            error_index.append(i)\n",
    "            continue\n",
    "        asts.append(parser)  \n",
    "\n",
    "    for i in range(len(asts)):\n",
    "        try:\n",
    "            # 尝试解析Java代码\n",
    "            test = asts[i].parse_member_declaration()\n",
    "            depth,node = get_blocks_improved_BFS_code(test)\n",
    "            levels.append(depth) \n",
    "            nodes.append(node)\n",
    "        except javalang.parser.JavaSyntaxError:\n",
    "            # 如果出现JavaSyntaxError，打印错误并跳过\n",
    "            error_index.append(i)\n",
    "            print(f\"解析错误索引为ast[{i}]，跳过有问题的代码\")\n",
    "            continue \n",
    "            \n",
    "    for i in error_index:\n",
    "        df.drop(i, inplace=True)\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    df['AST_level'] = levels\n",
    "    df['AST_BFSnodes'] = nodes\n",
    "    return df\n",
    "test_df_ast = get_BFS_df(test_df)\n",
    "test_df_ast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3f31379a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这个前序遍历 不能和层序遍历  在一个函数中连着使用 ， 最后用的是这个\n",
    "\n",
    "def preorder_traversal_a(node,pre_nodes):\n",
    "    if hasattr(node, 'children'):\n",
    "        for child_node in node.children:\n",
    "            pre_nodes.append(child_node)\n",
    "            preorder_traversal_a(child_node,pre_nodes)\n",
    "    else:\n",
    "        try:\n",
    "            len_node = len(node)\n",
    "            for i in range(len_node):\n",
    "                if hasattr(node[i], 'children'):\n",
    "                    for child in node[i].children:\n",
    "                        pre_nodes.append(child)\n",
    "                        preorder_traversal_a(child,pre_nodes)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    return pre_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "974492f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这个前序遍历 不能和层序遍历  在一个函数中连着使用 ， 最后用的是这个\n",
    "\n",
    "def preorder_traversal_a_n(node,pre_nodes,depth=0):\n",
    "    if depth == 0:\n",
    "        pre_nodes.append(node)\n",
    "\n",
    "    if hasattr(node, 'children'):\n",
    "        for child_node in node.children:\n",
    "            pre_nodes.append(child_node)\n",
    "            preorder_traversal_a_n(child_node,pre_nodes,depth+1)\n",
    "    else:\n",
    "        try:\n",
    "            len_node = len(node)\n",
    "            for i in range(len_node):\n",
    "                if hasattr(node[i], 'children'):\n",
    "                    for child in node[i].children:\n",
    "                        pre_nodes.append(child)\n",
    "                        preorder_traversal_a_n(child,pre_nodes,depth+1)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    return pre_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "46579c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>comment_type</th>\n",
       "      <th>old_comment_raw</th>\n",
       "      <th>old_comment_subtokens</th>\n",
       "      <th>new_comment_raw</th>\n",
       "      <th>new_comment_subtokens</th>\n",
       "      <th>span_minimal_diff_comment_subtokens</th>\n",
       "      <th>old_code_raw</th>\n",
       "      <th>old_code_subtokens</th>\n",
       "      <th>new_code_raw</th>\n",
       "      <th>new_code_subtokens</th>\n",
       "      <th>span_diff_code_subtokens</th>\n",
       "      <th>token_diff_code_subtokens</th>\n",
       "      <th>AST_level</th>\n",
       "      <th>AST_BFSnodes</th>\n",
       "      <th>AST_PFSnodes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>orientechnologies_orientdb-1949-FirstSentence-0</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Returns a OrientBaseGraph implementation from ...</td>\n",
       "      <td>[returns, a, orient, base, graph, implementati...</td>\n",
       "      <td>Returns a Transactional OrientGraph implementa...</td>\n",
       "      <td>[returns, a, transactional, orient, graph, imp...</td>\n",
       "      <td>[&lt;INSERT_OLD_KEEP_BEFORE&gt;, a, &lt;INSERT_NEW_KEEP...</td>\n",
       "      <td>public static OrientBaseGraph getGraph() {\\n...</td>\n",
       "      <td>[public, static, orient, base, graph, get, gra...</td>\n",
       "      <td>public static OrientBaseGraph getGraph() {\\n...</td>\n",
       "      <td>[public, static, orient, base, graph, get, gra...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, orient, base, graph, ...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;KEEP&gt;, orien...</td>\n",
       "      <td>8</td>\n",
       "      <td>[MethodDeclaration, None, {static, public}, []...</td>\n",
       "      <td>[MethodDeclaration, None, {static, public}, []...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spring_projects_spring_boot-882-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Creates a  exception tag based on the  Class#g...</td>\n",
       "      <td>[creates, a, exception, tag, based, on, the, c...</td>\n",
       "      <td>Creates a  exception tag based on the  Class#g...</td>\n",
       "      <td>[creates, a, exception, tag, based, on, the, c...</td>\n",
       "      <td>[]</td>\n",
       "      <td>\\tpublic static Tag exception(Throwable except...</td>\n",
       "      <td>[public, static, tag, exception, (, throwable,...</td>\n",
       "      <td>\\tpublic static Tag exception(Throwable except...</td>\n",
       "      <td>[public, static, tag, exception, (, throwable,...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, tag, exception, (, th...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;KEEP&gt;, tag, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>[MethodDeclaration, None, {static, public}, []...</td>\n",
       "      <td>[MethodDeclaration, None, {static, public}, []...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stanfordnlp_CoreNLP-191-Associations-FirstSent...</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Returns all currently displayed sentences in p...</td>\n",
       "      <td>[returns, all, currently, displayed, sentences...</td>\n",
       "      <td>Returns all currently displayed sentences in s...</td>\n",
       "      <td>[returns, all, currently, displayed, sentences...</td>\n",
       "      <td>[&lt;INSERT_OLD_KEEP_BEFORE&gt;, in, &lt;INSERT_NEW_KEE...</td>\n",
       "      <td>public String getMatchedSentences() {\\n    S...</td>\n",
       "      <td>[public, string, get, matched, sentences, (, )...</td>\n",
       "      <td>public StringBuffer getMatchedSentences() {\\...</td>\n",
       "      <td>[public, string, buffer, get, matched, sentenc...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, string, &lt;KEEP_END&gt;, &lt;INSERT&gt;,...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, string, &lt;INSERT&gt;, buf...</td>\n",
       "      <td>10</td>\n",
       "      <td>[MethodDeclaration, None, {public}, [], None, ...</td>\n",
       "      <td>[MethodDeclaration, None, {public}, [], None, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>raphw_byte_buddy-1042-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Creates a  net.bytebuddy.implementation.Defaul...</td>\n",
       "      <td>[creates, a, net, ., bytebuddy, ., implementat...</td>\n",
       "      <td>Creates a  net.bytebuddy.implementation.Defaul...</td>\n",
       "      <td>[creates, a, net, ., bytebuddy, ., implementat...</td>\n",
       "      <td>[]</td>\n",
       "      <td>public static Implementation prioritize(It...</td>\n",
       "      <td>[public, static, implementation, prioritize, (...</td>\n",
       "      <td>public static Implementation prioritize(It...</td>\n",
       "      <td>[public, static, implementation, prioritize, (...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, implementation, prior...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;KEEP&gt;, imple...</td>\n",
       "      <td>9</td>\n",
       "      <td>[MethodDeclaration, None, {static, public}, []...</td>\n",
       "      <td>[MethodDeclaration, None, {static, public}, []...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  label comment_type  \\\n",
       "0    orientechnologies_orientdb-1949-FirstSentence-0      1      Summary   \n",
       "1    spring_projects_spring_boot-882-FirstSentence-0      0      Summary   \n",
       "2  stanfordnlp_CoreNLP-191-Associations-FirstSent...      1      Summary   \n",
       "3              raphw_byte_buddy-1042-FirstSentence-0      0      Summary   \n",
       "\n",
       "                                     old_comment_raw  \\\n",
       "0  Returns a OrientBaseGraph implementation from ...   \n",
       "1  Creates a  exception tag based on the  Class#g...   \n",
       "2  Returns all currently displayed sentences in p...   \n",
       "3  Creates a  net.bytebuddy.implementation.Defaul...   \n",
       "\n",
       "                               old_comment_subtokens  \\\n",
       "0  [returns, a, orient, base, graph, implementati...   \n",
       "1  [creates, a, exception, tag, based, on, the, c...   \n",
       "2  [returns, all, currently, displayed, sentences...   \n",
       "3  [creates, a, net, ., bytebuddy, ., implementat...   \n",
       "\n",
       "                                     new_comment_raw  \\\n",
       "0  Returns a Transactional OrientGraph implementa...   \n",
       "1  Creates a  exception tag based on the  Class#g...   \n",
       "2  Returns all currently displayed sentences in s...   \n",
       "3  Creates a  net.bytebuddy.implementation.Defaul...   \n",
       "\n",
       "                               new_comment_subtokens  \\\n",
       "0  [returns, a, transactional, orient, graph, imp...   \n",
       "1  [creates, a, exception, tag, based, on, the, c...   \n",
       "2  [returns, all, currently, displayed, sentences...   \n",
       "3  [creates, a, net, ., bytebuddy, ., implementat...   \n",
       "\n",
       "                 span_minimal_diff_comment_subtokens  \\\n",
       "0  [<INSERT_OLD_KEEP_BEFORE>, a, <INSERT_NEW_KEEP...   \n",
       "1                                                 []   \n",
       "2  [<INSERT_OLD_KEEP_BEFORE>, in, <INSERT_NEW_KEE...   \n",
       "3                                                 []   \n",
       "\n",
       "                                        old_code_raw  \\\n",
       "0    public static OrientBaseGraph getGraph() {\\n...   \n",
       "1  \\tpublic static Tag exception(Throwable except...   \n",
       "2    public String getMatchedSentences() {\\n    S...   \n",
       "3      public static Implementation prioritize(It...   \n",
       "\n",
       "                                  old_code_subtokens  \\\n",
       "0  [public, static, orient, base, graph, get, gra...   \n",
       "1  [public, static, tag, exception, (, throwable,...   \n",
       "2  [public, string, get, matched, sentences, (, )...   \n",
       "3  [public, static, implementation, prioritize, (...   \n",
       "\n",
       "                                        new_code_raw  \\\n",
       "0    public static OrientBaseGraph getGraph() {\\n...   \n",
       "1  \\tpublic static Tag exception(Throwable except...   \n",
       "2    public StringBuffer getMatchedSentences() {\\...   \n",
       "3      public static Implementation prioritize(It...   \n",
       "\n",
       "                                  new_code_subtokens  \\\n",
       "0  [public, static, orient, base, graph, get, gra...   \n",
       "1  [public, static, tag, exception, (, throwable,...   \n",
       "2  [public, string, buffer, get, matched, sentenc...   \n",
       "3  [public, static, implementation, prioritize, (...   \n",
       "\n",
       "                            span_diff_code_subtokens  \\\n",
       "0  [<KEEP>, public, static, orient, base, graph, ...   \n",
       "1  [<KEEP>, public, static, tag, exception, (, th...   \n",
       "2  [<KEEP>, public, string, <KEEP_END>, <INSERT>,...   \n",
       "3  [<KEEP>, public, static, implementation, prior...   \n",
       "\n",
       "                           token_diff_code_subtokens  AST_level  \\\n",
       "0  [<KEEP>, public, <KEEP>, static, <KEEP>, orien...          8   \n",
       "1  [<KEEP>, public, <KEEP>, static, <KEEP>, tag, ...          9   \n",
       "2  [<KEEP>, public, <KEEP>, string, <INSERT>, buf...         10   \n",
       "3  [<KEEP>, public, <KEEP>, static, <KEEP>, imple...          9   \n",
       "\n",
       "                                        AST_BFSnodes  \\\n",
       "0  [MethodDeclaration, None, {static, public}, []...   \n",
       "1  [MethodDeclaration, None, {static, public}, []...   \n",
       "2  [MethodDeclaration, None, {public}, [], None, ...   \n",
       "3  [MethodDeclaration, None, {static, public}, []...   \n",
       "\n",
       "                                        AST_PFSnodes  \n",
       "0  [MethodDeclaration, None, {static, public}, []...  \n",
       "1  [MethodDeclaration, None, {static, public}, []...  \n",
       "2  [MethodDeclaration, None, {public}, [], None, ...  \n",
       "3  [MethodDeclaration, None, {static, public}, []...  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获得前序遍历\n",
    "\n",
    "def get_PFS_df(df):\n",
    "    \n",
    "    asts = []\n",
    "    nodes_pfs = []\n",
    "    for i in range(len(df)):\n",
    "        tokens_t = javalang.tokenizer.tokenize(df.loc[i]['new_code_raw'])\n",
    "        parser = javalang.parse.Parser(tokens_t)\n",
    "\n",
    "        asts.append(parser)  \n",
    "\n",
    "    for i in range(len(asts)):  \n",
    "        try:\n",
    "            # 尝试解析Java代码\n",
    "#             print(i)\n",
    "            test = asts[i].parse_member_declaration()\n",
    "\n",
    "            pre_nodes_test = []\n",
    "            node_p = preorder_traversal_a_n(test,pre_nodes_test)\n",
    "            \n",
    "            for node in node_p:   # 处理 node_p  \n",
    "                if isinstance(node, javalang.tree.Node):\n",
    "                    index = node_p.index(node)\n",
    "                    node_p[index] = type(node).__name__\n",
    "                if isinstance(node, list):\n",
    "                    for no in node:\n",
    "                        if isinstance(no, javalang.tree.Node):\n",
    "                            index = node.index(no)\n",
    "                            node[index] = type(no).__name__\n",
    "                            \n",
    "            nodes_pfs.append(node_p)\n",
    "        except javalang.parser.JavaSyntaxError:\n",
    "            continue \n",
    "    \n",
    "    df['AST_PFSnodes'] = nodes_pfs\n",
    "\n",
    "    return df\n",
    "test_df_ast = get_PFS_df(test_df_ast)\n",
    "test_df_ast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61dc65b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e77f5967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可以把这个和下面的合并在一块\n",
    "def get_clean_list(lst):\n",
    "    lst = [x for x in lst if x is not None]\n",
    "    lst = [x for x in lst if x != []]\n",
    "    lst = [x for x in lst if x != '']\n",
    "    return lst\n",
    "# 去除多余的元素\n",
    "def flatten_to_string(lst):\n",
    "    result = []\n",
    "    for i in lst:\n",
    "        if isinstance(i, list):\n",
    "            result.extend(flatten_to_string(i))\n",
    "        elif isinstance(i, set):\n",
    "            result.extend(flatten_to_string(list(i)))\n",
    "        elif not isinstance(i, bool):\n",
    "            result.append(i)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4bbe2985",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>comment_type</th>\n",
       "      <th>old_comment_raw</th>\n",
       "      <th>old_comment_subtokens</th>\n",
       "      <th>new_comment_raw</th>\n",
       "      <th>new_comment_subtokens</th>\n",
       "      <th>span_minimal_diff_comment_subtokens</th>\n",
       "      <th>old_code_raw</th>\n",
       "      <th>old_code_subtokens</th>\n",
       "      <th>new_code_raw</th>\n",
       "      <th>new_code_subtokens</th>\n",
       "      <th>span_diff_code_subtokens</th>\n",
       "      <th>token_diff_code_subtokens</th>\n",
       "      <th>AST_level</th>\n",
       "      <th>AST_BFSnodes</th>\n",
       "      <th>AST_PFSnodes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>orientechnologies_orientdb-1949-FirstSentence-0</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Returns a OrientBaseGraph implementation from ...</td>\n",
       "      <td>[returns, a, orient, base, graph, implementati...</td>\n",
       "      <td>Returns a Transactional OrientGraph implementa...</td>\n",
       "      <td>[returns, a, transactional, orient, graph, imp...</td>\n",
       "      <td>[&lt;INSERT_OLD_KEEP_BEFORE&gt;, a, &lt;INSERT_NEW_KEEP...</td>\n",
       "      <td>public static OrientBaseGraph getGraph() {\\n...</td>\n",
       "      <td>[public, static, orient, base, graph, get, gra...</td>\n",
       "      <td>public static OrientBaseGraph getGraph() {\\n...</td>\n",
       "      <td>[public, static, orient, base, graph, get, gra...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, orient, base, graph, ...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;KEEP&gt;, orien...</td>\n",
       "      <td>8</td>\n",
       "      <td>[MethodDeclaration, static, public, ReferenceT...</td>\n",
       "      <td>[MethodDeclaration, static, public, ReferenceT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spring_projects_spring_boot-882-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Creates a  exception tag based on the  Class#g...</td>\n",
       "      <td>[creates, a, exception, tag, based, on, the, c...</td>\n",
       "      <td>Creates a  exception tag based on the  Class#g...</td>\n",
       "      <td>[creates, a, exception, tag, based, on, the, c...</td>\n",
       "      <td>[]</td>\n",
       "      <td>\\tpublic static Tag exception(Throwable except...</td>\n",
       "      <td>[public, static, tag, exception, (, throwable,...</td>\n",
       "      <td>\\tpublic static Tag exception(Throwable except...</td>\n",
       "      <td>[public, static, tag, exception, (, throwable,...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, tag, exception, (, th...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;KEEP&gt;, tag, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>[MethodDeclaration, static, public, ReferenceT...</td>\n",
       "      <td>[MethodDeclaration, static, public, ReferenceT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stanfordnlp_CoreNLP-191-Associations-FirstSent...</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Returns all currently displayed sentences in p...</td>\n",
       "      <td>[returns, all, currently, displayed, sentences...</td>\n",
       "      <td>Returns all currently displayed sentences in s...</td>\n",
       "      <td>[returns, all, currently, displayed, sentences...</td>\n",
       "      <td>[&lt;INSERT_OLD_KEEP_BEFORE&gt;, in, &lt;INSERT_NEW_KEE...</td>\n",
       "      <td>public String getMatchedSentences() {\\n    S...</td>\n",
       "      <td>[public, string, get, matched, sentences, (, )...</td>\n",
       "      <td>public StringBuffer getMatchedSentences() {\\...</td>\n",
       "      <td>[public, string, buffer, get, matched, sentenc...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, string, &lt;KEEP_END&gt;, &lt;INSERT&gt;,...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, string, &lt;INSERT&gt;, buf...</td>\n",
       "      <td>10</td>\n",
       "      <td>[MethodDeclaration, public, ReferenceType, get...</td>\n",
       "      <td>[MethodDeclaration, public, ReferenceType, Str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>raphw_byte_buddy-1042-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Creates a  net.bytebuddy.implementation.Defaul...</td>\n",
       "      <td>[creates, a, net, ., bytebuddy, ., implementat...</td>\n",
       "      <td>Creates a  net.bytebuddy.implementation.Defaul...</td>\n",
       "      <td>[creates, a, net, ., bytebuddy, ., implementat...</td>\n",
       "      <td>[]</td>\n",
       "      <td>public static Implementation prioritize(It...</td>\n",
       "      <td>[public, static, implementation, prioritize, (...</td>\n",
       "      <td>public static Implementation prioritize(It...</td>\n",
       "      <td>[public, static, implementation, prioritize, (...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, implementation, prior...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;KEEP&gt;, imple...</td>\n",
       "      <td>9</td>\n",
       "      <td>[MethodDeclaration, static, public, ReferenceT...</td>\n",
       "      <td>[MethodDeclaration, static, public, ReferenceT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  label comment_type  \\\n",
       "0    orientechnologies_orientdb-1949-FirstSentence-0      1      Summary   \n",
       "1    spring_projects_spring_boot-882-FirstSentence-0      0      Summary   \n",
       "2  stanfordnlp_CoreNLP-191-Associations-FirstSent...      1      Summary   \n",
       "3              raphw_byte_buddy-1042-FirstSentence-0      0      Summary   \n",
       "\n",
       "                                     old_comment_raw  \\\n",
       "0  Returns a OrientBaseGraph implementation from ...   \n",
       "1  Creates a  exception tag based on the  Class#g...   \n",
       "2  Returns all currently displayed sentences in p...   \n",
       "3  Creates a  net.bytebuddy.implementation.Defaul...   \n",
       "\n",
       "                               old_comment_subtokens  \\\n",
       "0  [returns, a, orient, base, graph, implementati...   \n",
       "1  [creates, a, exception, tag, based, on, the, c...   \n",
       "2  [returns, all, currently, displayed, sentences...   \n",
       "3  [creates, a, net, ., bytebuddy, ., implementat...   \n",
       "\n",
       "                                     new_comment_raw  \\\n",
       "0  Returns a Transactional OrientGraph implementa...   \n",
       "1  Creates a  exception tag based on the  Class#g...   \n",
       "2  Returns all currently displayed sentences in s...   \n",
       "3  Creates a  net.bytebuddy.implementation.Defaul...   \n",
       "\n",
       "                               new_comment_subtokens  \\\n",
       "0  [returns, a, transactional, orient, graph, imp...   \n",
       "1  [creates, a, exception, tag, based, on, the, c...   \n",
       "2  [returns, all, currently, displayed, sentences...   \n",
       "3  [creates, a, net, ., bytebuddy, ., implementat...   \n",
       "\n",
       "                 span_minimal_diff_comment_subtokens  \\\n",
       "0  [<INSERT_OLD_KEEP_BEFORE>, a, <INSERT_NEW_KEEP...   \n",
       "1                                                 []   \n",
       "2  [<INSERT_OLD_KEEP_BEFORE>, in, <INSERT_NEW_KEE...   \n",
       "3                                                 []   \n",
       "\n",
       "                                        old_code_raw  \\\n",
       "0    public static OrientBaseGraph getGraph() {\\n...   \n",
       "1  \\tpublic static Tag exception(Throwable except...   \n",
       "2    public String getMatchedSentences() {\\n    S...   \n",
       "3      public static Implementation prioritize(It...   \n",
       "\n",
       "                                  old_code_subtokens  \\\n",
       "0  [public, static, orient, base, graph, get, gra...   \n",
       "1  [public, static, tag, exception, (, throwable,...   \n",
       "2  [public, string, get, matched, sentences, (, )...   \n",
       "3  [public, static, implementation, prioritize, (...   \n",
       "\n",
       "                                        new_code_raw  \\\n",
       "0    public static OrientBaseGraph getGraph() {\\n...   \n",
       "1  \\tpublic static Tag exception(Throwable except...   \n",
       "2    public StringBuffer getMatchedSentences() {\\...   \n",
       "3      public static Implementation prioritize(It...   \n",
       "\n",
       "                                  new_code_subtokens  \\\n",
       "0  [public, static, orient, base, graph, get, gra...   \n",
       "1  [public, static, tag, exception, (, throwable,...   \n",
       "2  [public, string, buffer, get, matched, sentenc...   \n",
       "3  [public, static, implementation, prioritize, (...   \n",
       "\n",
       "                            span_diff_code_subtokens  \\\n",
       "0  [<KEEP>, public, static, orient, base, graph, ...   \n",
       "1  [<KEEP>, public, static, tag, exception, (, th...   \n",
       "2  [<KEEP>, public, string, <KEEP_END>, <INSERT>,...   \n",
       "3  [<KEEP>, public, static, implementation, prior...   \n",
       "\n",
       "                           token_diff_code_subtokens  AST_level  \\\n",
       "0  [<KEEP>, public, <KEEP>, static, <KEEP>, orien...          8   \n",
       "1  [<KEEP>, public, <KEEP>, static, <KEEP>, tag, ...          9   \n",
       "2  [<KEEP>, public, <KEEP>, string, <INSERT>, buf...         10   \n",
       "3  [<KEEP>, public, <KEEP>, static, <KEEP>, imple...          9   \n",
       "\n",
       "                                        AST_BFSnodes  \\\n",
       "0  [MethodDeclaration, static, public, ReferenceT...   \n",
       "1  [MethodDeclaration, static, public, ReferenceT...   \n",
       "2  [MethodDeclaration, public, ReferenceType, get...   \n",
       "3  [MethodDeclaration, static, public, ReferenceT...   \n",
       "\n",
       "                                        AST_PFSnodes  \n",
       "0  [MethodDeclaration, static, public, ReferenceT...  \n",
       "1  [MethodDeclaration, static, public, ReferenceT...  \n",
       "2  [MethodDeclaration, public, ReferenceType, Str...  \n",
       "3  [MethodDeclaration, static, public, ReferenceT...  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 整理一下 将 里面的列表括号 和 多余元素删除  ( AST_PFSnodes 列和 AST_BFSnodes 列 )\n",
    "def clean_ASTNodes(df):\n",
    "    AST_BFSnodes = []\n",
    "    AST_PFSnodes = []\n",
    "    for node in df['AST_PFSnodes']:\n",
    "        PFS_nodes = get_clean_list(node)\n",
    "        PFS_nodes = flatten_to_string(PFS_nodes)\n",
    "        AST_PFSnodes.append(PFS_nodes)\n",
    "    for node in df['AST_BFSnodes']:\n",
    "        BFS_nodes = get_clean_list(node)\n",
    "        BFS_nodes = flatten_to_string(BFS_nodes)\n",
    "        AST_BFSnodes.append(BFS_nodes)    \n",
    "    \n",
    "    df['AST_BFSnodes'] = AST_BFSnodes\n",
    "    df['AST_PFSnodes'] = AST_PFSnodes\n",
    "    return df\n",
    "cleaned_test_df_ast = clean_ASTNodes(test_df_ast)\n",
    "cleaned_test_df_ast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe7eda7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d2e21089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.5"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_test_df_ast.AST_PFSnodes.apply(len).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7b8cf3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cleaned_test_df_ast.AST_PFSnodes.apply(len) < 100).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "13b3336d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_AST_level = cleaned_test_df_ast['AST_level'].mean()\n",
    "average_AST_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ebf9eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a702b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cae05751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def split_punctuation(s):\n",
    "    # 使用正则表达式匹配连续的标点符号或者字母和标点符号之间的位置\n",
    "    splits = re.finditer(r'(?<=\\w)(?=[{}])|(?<=[{}])(?=\\w)'.format(string.punctuation, string.punctuation), s)\n",
    "    \n",
    "    # 获取所有分割位置\n",
    "    split_positions = [match.start() for match in splits]\n",
    "    \n",
    "    # 在分割位置插入空格\n",
    "    for pos in reversed(split_positions):\n",
    "        s = s[:pos] + ' ' + s[pos:]\n",
    "        \n",
    "    s = s.replace(\"< s >\", \"<s>\")\n",
    "    s = s.replace(\"</ s >\", \"</s>\")\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1f9fa405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>comment_type</th>\n",
       "      <th>old_comment_raw</th>\n",
       "      <th>old_comment_subtokens</th>\n",
       "      <th>new_comment_raw</th>\n",
       "      <th>new_comment_subtokens</th>\n",
       "      <th>span_minimal_diff_comment_subtokens</th>\n",
       "      <th>old_code_raw</th>\n",
       "      <th>old_code_subtokens</th>\n",
       "      <th>new_code_raw</th>\n",
       "      <th>new_code_subtokens</th>\n",
       "      <th>span_diff_code_subtokens</th>\n",
       "      <th>token_diff_code_subtokens</th>\n",
       "      <th>AST_level</th>\n",
       "      <th>AST_BFSnodes</th>\n",
       "      <th>AST_PFSnodes</th>\n",
       "      <th>Child_Node_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>orientechnologies_orientdb-1949-FirstSentence-0</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Returns a OrientBaseGraph implementation from ...</td>\n",
       "      <td>[returns, a, orient, base, graph, implementati...</td>\n",
       "      <td>Returns a Transactional OrientGraph implementa...</td>\n",
       "      <td>[returns, a, transactional, orient, graph, imp...</td>\n",
       "      <td>[&lt;INSERT_OLD_KEEP_BEFORE&gt;, a, &lt;INSERT_NEW_KEEP...</td>\n",
       "      <td>public static OrientBaseGraph getGraph() {\\n...</td>\n",
       "      <td>[public, static, orient, base, graph, get, gra...</td>\n",
       "      <td>public static OrientBaseGraph getGraph() {\\n...</td>\n",
       "      <td>[public, static, orient, base, graph, get, gra...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, orient, base, graph, ...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;KEEP&gt;, orien...</td>\n",
       "      <td>8</td>\n",
       "      <td>[MethodDeclaration, static, public, ReferenceT...</td>\n",
       "      <td>[MethodDeclaration, static, public, ReferenceT...</td>\n",
       "      <td>[7, 1, 2, 2, 1, 1, 2, 1, 3, 1, 1, 1, 3, 1, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spring_projects_spring_boot-882-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Creates a  exception tag based on the  Class#g...</td>\n",
       "      <td>[creates, a, exception, tag, based, on, the, c...</td>\n",
       "      <td>Creates a  exception tag based on the  Class#g...</td>\n",
       "      <td>[creates, a, exception, tag, based, on, the, c...</td>\n",
       "      <td>[]</td>\n",
       "      <td>\\tpublic static Tag exception(Throwable except...</td>\n",
       "      <td>[public, static, tag, exception, (, throwable,...</td>\n",
       "      <td>\\tpublic static Tag exception(Throwable except...</td>\n",
       "      <td>[public, static, tag, exception, (, throwable,...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, tag, exception, (, th...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;KEEP&gt;, tag, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>[MethodDeclaration, static, public, ReferenceT...</td>\n",
       "      <td>[MethodDeclaration, static, public, ReferenceT...</td>\n",
       "      <td>[7, 1, 2, 1, 2, 1, 3, 1, 1, 2, 2, 1, 1, 2, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stanfordnlp_CoreNLP-191-Associations-FirstSent...</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Returns all currently displayed sentences in p...</td>\n",
       "      <td>[returns, all, currently, displayed, sentences...</td>\n",
       "      <td>Returns all currently displayed sentences in s...</td>\n",
       "      <td>[returns, all, currently, displayed, sentences...</td>\n",
       "      <td>[&lt;INSERT_OLD_KEEP_BEFORE&gt;, in, &lt;INSERT_NEW_KEE...</td>\n",
       "      <td>public String getMatchedSentences() {\\n    S...</td>\n",
       "      <td>[public, string, get, matched, sentences, (, )...</td>\n",
       "      <td>public StringBuffer getMatchedSentences() {\\...</td>\n",
       "      <td>[public, string, buffer, get, matched, sentenc...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, string, &lt;KEEP_END&gt;, &lt;INSERT&gt;,...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, string, &lt;INSERT&gt;, buf...</td>\n",
       "      <td>10</td>\n",
       "      <td>[MethodDeclaration, public, ReferenceType, get...</td>\n",
       "      <td>[MethodDeclaration, public, ReferenceType, Str...</td>\n",
       "      <td>[6, 1, 2, 2, 1, 1, 2, 1, 1, 3, 2, 1, 2, 1, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>raphw_byte_buddy-1042-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Creates a  net.bytebuddy.implementation.Defaul...</td>\n",
       "      <td>[creates, a, net, ., bytebuddy, ., implementat...</td>\n",
       "      <td>Creates a  net.bytebuddy.implementation.Defaul...</td>\n",
       "      <td>[creates, a, net, ., bytebuddy, ., implementat...</td>\n",
       "      <td>[]</td>\n",
       "      <td>public static Implementation prioritize(It...</td>\n",
       "      <td>[public, static, implementation, prioritize, (...</td>\n",
       "      <td>public static Implementation prioritize(It...</td>\n",
       "      <td>[public, static, implementation, prioritize, (...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, implementation, prior...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;KEEP&gt;, imple...</td>\n",
       "      <td>9</td>\n",
       "      <td>[MethodDeclaration, static, public, ReferenceT...</td>\n",
       "      <td>[MethodDeclaration, static, public, ReferenceT...</td>\n",
       "      <td>[8, 1, 2, 2, 2, 2, 0, 2, 2, 1, 2, 1, 2, 0, 2, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  label comment_type  \\\n",
       "0    orientechnologies_orientdb-1949-FirstSentence-0      1      Summary   \n",
       "1    spring_projects_spring_boot-882-FirstSentence-0      0      Summary   \n",
       "2  stanfordnlp_CoreNLP-191-Associations-FirstSent...      1      Summary   \n",
       "3              raphw_byte_buddy-1042-FirstSentence-0      0      Summary   \n",
       "\n",
       "                                     old_comment_raw  \\\n",
       "0  Returns a OrientBaseGraph implementation from ...   \n",
       "1  Creates a  exception tag based on the  Class#g...   \n",
       "2  Returns all currently displayed sentences in p...   \n",
       "3  Creates a  net.bytebuddy.implementation.Defaul...   \n",
       "\n",
       "                               old_comment_subtokens  \\\n",
       "0  [returns, a, orient, base, graph, implementati...   \n",
       "1  [creates, a, exception, tag, based, on, the, c...   \n",
       "2  [returns, all, currently, displayed, sentences...   \n",
       "3  [creates, a, net, ., bytebuddy, ., implementat...   \n",
       "\n",
       "                                     new_comment_raw  \\\n",
       "0  Returns a Transactional OrientGraph implementa...   \n",
       "1  Creates a  exception tag based on the  Class#g...   \n",
       "2  Returns all currently displayed sentences in s...   \n",
       "3  Creates a  net.bytebuddy.implementation.Defaul...   \n",
       "\n",
       "                               new_comment_subtokens  \\\n",
       "0  [returns, a, transactional, orient, graph, imp...   \n",
       "1  [creates, a, exception, tag, based, on, the, c...   \n",
       "2  [returns, all, currently, displayed, sentences...   \n",
       "3  [creates, a, net, ., bytebuddy, ., implementat...   \n",
       "\n",
       "                 span_minimal_diff_comment_subtokens  \\\n",
       "0  [<INSERT_OLD_KEEP_BEFORE>, a, <INSERT_NEW_KEEP...   \n",
       "1                                                 []   \n",
       "2  [<INSERT_OLD_KEEP_BEFORE>, in, <INSERT_NEW_KEE...   \n",
       "3                                                 []   \n",
       "\n",
       "                                        old_code_raw  \\\n",
       "0    public static OrientBaseGraph getGraph() {\\n...   \n",
       "1  \\tpublic static Tag exception(Throwable except...   \n",
       "2    public String getMatchedSentences() {\\n    S...   \n",
       "3      public static Implementation prioritize(It...   \n",
       "\n",
       "                                  old_code_subtokens  \\\n",
       "0  [public, static, orient, base, graph, get, gra...   \n",
       "1  [public, static, tag, exception, (, throwable,...   \n",
       "2  [public, string, get, matched, sentences, (, )...   \n",
       "3  [public, static, implementation, prioritize, (...   \n",
       "\n",
       "                                        new_code_raw  \\\n",
       "0    public static OrientBaseGraph getGraph() {\\n...   \n",
       "1  \\tpublic static Tag exception(Throwable except...   \n",
       "2    public StringBuffer getMatchedSentences() {\\...   \n",
       "3      public static Implementation prioritize(It...   \n",
       "\n",
       "                                  new_code_subtokens  \\\n",
       "0  [public, static, orient, base, graph, get, gra...   \n",
       "1  [public, static, tag, exception, (, throwable,...   \n",
       "2  [public, string, buffer, get, matched, sentenc...   \n",
       "3  [public, static, implementation, prioritize, (...   \n",
       "\n",
       "                            span_diff_code_subtokens  \\\n",
       "0  [<KEEP>, public, static, orient, base, graph, ...   \n",
       "1  [<KEEP>, public, static, tag, exception, (, th...   \n",
       "2  [<KEEP>, public, string, <KEEP_END>, <INSERT>,...   \n",
       "3  [<KEEP>, public, static, implementation, prior...   \n",
       "\n",
       "                           token_diff_code_subtokens  AST_level  \\\n",
       "0  [<KEEP>, public, <KEEP>, static, <KEEP>, orien...          8   \n",
       "1  [<KEEP>, public, <KEEP>, static, <KEEP>, tag, ...          9   \n",
       "2  [<KEEP>, public, <KEEP>, string, <INSERT>, buf...         10   \n",
       "3  [<KEEP>, public, <KEEP>, static, <KEEP>, imple...          9   \n",
       "\n",
       "                                        AST_BFSnodes  \\\n",
       "0  [MethodDeclaration, static, public, ReferenceT...   \n",
       "1  [MethodDeclaration, static, public, ReferenceT...   \n",
       "2  [MethodDeclaration, public, ReferenceType, get...   \n",
       "3  [MethodDeclaration, static, public, ReferenceT...   \n",
       "\n",
       "                                        AST_PFSnodes  \\\n",
       "0  [MethodDeclaration, static, public, ReferenceT...   \n",
       "1  [MethodDeclaration, static, public, ReferenceT...   \n",
       "2  [MethodDeclaration, public, ReferenceType, Str...   \n",
       "3  [MethodDeclaration, static, public, ReferenceT...   \n",
       "\n",
       "                                    Child_Node_count  \n",
       "0  [7, 1, 2, 2, 1, 1, 2, 1, 3, 1, 1, 1, 3, 1, 2, ...  \n",
       "1  [7, 1, 2, 1, 2, 1, 3, 1, 1, 2, 2, 1, 1, 2, 3, ...  \n",
       "2  [6, 1, 2, 2, 1, 1, 2, 1, 1, 3, 2, 1, 2, 1, 3, ...  \n",
       "3  [8, 1, 2, 2, 2, 2, 0, 2, 2, 1, 2, 1, 2, 0, 2, ...  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获得父节点对应孩子的个数,前序遍历\n",
    "\n",
    "def get_Child_Node_count(df):\n",
    "    \n",
    "    asts = []\n",
    "    codes = []\n",
    "    child_Node_count = []\n",
    "    for i in range(len(df)):\n",
    "        tokens_t = javalang.tokenizer.tokenize(df.loc[i]['new_code_raw'])\n",
    "        parser = javalang.parse.Parser(tokens_t)\n",
    "        \n",
    "        codes.append(df.loc[i]['new_code_raw'])\n",
    "        asts.append(parser)  \n",
    "\n",
    "    for i in range(len(asts)):  \n",
    "        try:\n",
    "            # 尝试解析Java代码\n",
    "#             print(i)\n",
    "            test = asts[i].parse_member_declaration()\n",
    "\n",
    "            pre_nodes_test = []\n",
    "            node_p = preorder_traversal_a_n(test,pre_nodes_test)\n",
    "            \n",
    "            code = codes[i]\n",
    "            tokens = split_punctuation(code)\n",
    "            tokens = ' '.join(tokens.split()).split()\n",
    "            \n",
    "            pre_child_num = []\n",
    "            for nodes in node_p:\n",
    "                if hasattr(nodes, 'children'):\n",
    "                    num = 0\n",
    "                    for child_node in nodes.children:\n",
    "                        if isinstance(child_node, javalang.tree.Node):\n",
    "                            num = num + 1\n",
    "                        elif isinstance(child_node, list):\n",
    "                            num = num + len(child_node)\n",
    "                        elif isinstance(child_node, set):\n",
    "                            num = num + len(child_node)\n",
    "                        elif child_node in tokens:\n",
    "                            num = num + 1\n",
    "                    pre_child_num.append(num)\n",
    "                else:\n",
    "                    try:\n",
    "                        len_node = len(nodes)\n",
    "                        for i in range(len_node):\n",
    "                            if hasattr(nodes[i], 'children'):\n",
    "                                num = 0\n",
    "                                for child_node in nodes[i].children:\n",
    "                                    if isinstance(child_node, javalang.tree.Node):\n",
    "                                        num = num + 1\n",
    "                                    elif isinstance(child_node, list):\n",
    "                                        num = num + len(child_node)\n",
    "                                    elif isinstance(child_node, set):\n",
    "                                        num = num + len(child_node)\n",
    "                                    elif child_node in tokens:\n",
    "                                        num = num + 1\n",
    "                                pre_child_num.append(num)\n",
    "                    except Exception as e:\n",
    "                        pass\n",
    "            # 父节点的个数 + 子节点的个数 为树节点的个数\n",
    "            # print(len(pre_child_num) )\n",
    "            child_Node_count.append(pre_child_num)\n",
    "        except javalang.parser.JavaSyntaxError:\n",
    "            continue \n",
    "    \n",
    "    df['Child_Node_count'] = child_Node_count\n",
    "\n",
    "    return df\n",
    "cleaned_test_df_ast_after_get_child = get_Child_Node_count(cleaned_test_df_ast)\n",
    "cleaned_test_df_ast_after_get_child.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1731c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04000ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e42afc18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>comment_type</th>\n",
       "      <th>old_comment_raw</th>\n",
       "      <th>old_comment_subtokens</th>\n",
       "      <th>new_comment_raw</th>\n",
       "      <th>new_comment_subtokens</th>\n",
       "      <th>span_minimal_diff_comment_subtokens</th>\n",
       "      <th>old_code_raw</th>\n",
       "      <th>old_code_subtokens</th>\n",
       "      <th>new_code_raw</th>\n",
       "      <th>new_code_subtokens</th>\n",
       "      <th>span_diff_code_subtokens</th>\n",
       "      <th>token_diff_code_subtokens</th>\n",
       "      <th>AST_level</th>\n",
       "      <th>AST_BFSnodes</th>\n",
       "      <th>AST_PFSnodes</th>\n",
       "      <th>Child_Node_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>orientechnologies_orientdb-1949-FirstSentence-0</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Returns a OrientBaseGraph implementation from ...</td>\n",
       "      <td>[returns, a, orient, base, graph, implementati...</td>\n",
       "      <td>Returns a Transactional OrientGraph implementa...</td>\n",
       "      <td>[returns, a, transactional, orient, graph, imp...</td>\n",
       "      <td>[&lt;INSERT_OLD_KEEP_BEFORE&gt;, a, &lt;INSERT_NEW_KEEP...</td>\n",
       "      <td>public static OrientBaseGraph getGraph() {\\n...</td>\n",
       "      <td>[public, static, orient, base, graph, get, gra...</td>\n",
       "      <td>public static OrientBaseGraph getGraph() {\\n...</td>\n",
       "      <td>[public, static, orient, base, graph, get, gra...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, orient, base, graph, ...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;KEEP&gt;, orien...</td>\n",
       "      <td>8</td>\n",
       "      <td>[MethodDeclaration, static, public, ReferenceT...</td>\n",
       "      <td>[MethodDeclaration, static, public, ReferenceT...</td>\n",
       "      <td>[7, 1, 2, 2, 1, 1, 2, 1, 3, 1, 1, 1, 3, 1, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spring_projects_spring_boot-882-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Creates a  exception tag based on the  Class#g...</td>\n",
       "      <td>[creates, a, exception, tag, based, on, the, c...</td>\n",
       "      <td>Creates a  exception tag based on the  Class#g...</td>\n",
       "      <td>[creates, a, exception, tag, based, on, the, c...</td>\n",
       "      <td>[]</td>\n",
       "      <td>\\tpublic static Tag exception(Throwable except...</td>\n",
       "      <td>[public, static, tag, exception, (, throwable,...</td>\n",
       "      <td>\\tpublic static Tag exception(Throwable except...</td>\n",
       "      <td>[public, static, tag, exception, (, throwable,...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, tag, exception, (, th...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;KEEP&gt;, tag, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>[MethodDeclaration, static, public, ReferenceT...</td>\n",
       "      <td>[MethodDeclaration, static, public, ReferenceT...</td>\n",
       "      <td>[7, 1, 2, 1, 2, 1, 3, 1, 1, 2, 2, 1, 1, 2, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stanfordnlp_CoreNLP-191-Associations-FirstSent...</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Returns all currently displayed sentences in p...</td>\n",
       "      <td>[returns, all, currently, displayed, sentences...</td>\n",
       "      <td>Returns all currently displayed sentences in s...</td>\n",
       "      <td>[returns, all, currently, displayed, sentences...</td>\n",
       "      <td>[&lt;INSERT_OLD_KEEP_BEFORE&gt;, in, &lt;INSERT_NEW_KEE...</td>\n",
       "      <td>public String getMatchedSentences() {\\n    S...</td>\n",
       "      <td>[public, string, get, matched, sentences, (, )...</td>\n",
       "      <td>public StringBuffer getMatchedSentences() {\\...</td>\n",
       "      <td>[public, string, buffer, get, matched, sentenc...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, string, &lt;KEEP_END&gt;, &lt;INSERT&gt;,...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, string, &lt;INSERT&gt;, buf...</td>\n",
       "      <td>10</td>\n",
       "      <td>[MethodDeclaration, public, ReferenceType, get...</td>\n",
       "      <td>[MethodDeclaration, public, ReferenceType, Str...</td>\n",
       "      <td>[6, 1, 2, 2, 1, 1, 2, 1, 1, 3, 2, 1, 2, 1, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>raphw_byte_buddy-1042-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Creates a  net.bytebuddy.implementation.Defaul...</td>\n",
       "      <td>[creates, a, net, ., bytebuddy, ., implementat...</td>\n",
       "      <td>Creates a  net.bytebuddy.implementation.Defaul...</td>\n",
       "      <td>[creates, a, net, ., bytebuddy, ., implementat...</td>\n",
       "      <td>[]</td>\n",
       "      <td>public static Implementation prioritize(It...</td>\n",
       "      <td>[public, static, implementation, prioritize, (...</td>\n",
       "      <td>public static Implementation prioritize(It...</td>\n",
       "      <td>[public, static, implementation, prioritize, (...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, implementation, prior...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;KEEP&gt;, imple...</td>\n",
       "      <td>9</td>\n",
       "      <td>[MethodDeclaration, static, public, ReferenceT...</td>\n",
       "      <td>[MethodDeclaration, static, public, ReferenceT...</td>\n",
       "      <td>[8, 1, 2, 2, 2, 2, 0, 2, 2, 1, 2, 1, 2, 0, 2, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  label comment_type  \\\n",
       "0    orientechnologies_orientdb-1949-FirstSentence-0      1      Summary   \n",
       "1    spring_projects_spring_boot-882-FirstSentence-0      0      Summary   \n",
       "2  stanfordnlp_CoreNLP-191-Associations-FirstSent...      1      Summary   \n",
       "3              raphw_byte_buddy-1042-FirstSentence-0      0      Summary   \n",
       "\n",
       "                                     old_comment_raw  \\\n",
       "0  Returns a OrientBaseGraph implementation from ...   \n",
       "1  Creates a  exception tag based on the  Class#g...   \n",
       "2  Returns all currently displayed sentences in p...   \n",
       "3  Creates a  net.bytebuddy.implementation.Defaul...   \n",
       "\n",
       "                               old_comment_subtokens  \\\n",
       "0  [returns, a, orient, base, graph, implementati...   \n",
       "1  [creates, a, exception, tag, based, on, the, c...   \n",
       "2  [returns, all, currently, displayed, sentences...   \n",
       "3  [creates, a, net, ., bytebuddy, ., implementat...   \n",
       "\n",
       "                                     new_comment_raw  \\\n",
       "0  Returns a Transactional OrientGraph implementa...   \n",
       "1  Creates a  exception tag based on the  Class#g...   \n",
       "2  Returns all currently displayed sentences in s...   \n",
       "3  Creates a  net.bytebuddy.implementation.Defaul...   \n",
       "\n",
       "                               new_comment_subtokens  \\\n",
       "0  [returns, a, transactional, orient, graph, imp...   \n",
       "1  [creates, a, exception, tag, based, on, the, c...   \n",
       "2  [returns, all, currently, displayed, sentences...   \n",
       "3  [creates, a, net, ., bytebuddy, ., implementat...   \n",
       "\n",
       "                 span_minimal_diff_comment_subtokens  \\\n",
       "0  [<INSERT_OLD_KEEP_BEFORE>, a, <INSERT_NEW_KEEP...   \n",
       "1                                                 []   \n",
       "2  [<INSERT_OLD_KEEP_BEFORE>, in, <INSERT_NEW_KEE...   \n",
       "3                                                 []   \n",
       "\n",
       "                                        old_code_raw  \\\n",
       "0    public static OrientBaseGraph getGraph() {\\n...   \n",
       "1  \\tpublic static Tag exception(Throwable except...   \n",
       "2    public String getMatchedSentences() {\\n    S...   \n",
       "3      public static Implementation prioritize(It...   \n",
       "\n",
       "                                  old_code_subtokens  \\\n",
       "0  [public, static, orient, base, graph, get, gra...   \n",
       "1  [public, static, tag, exception, (, throwable,...   \n",
       "2  [public, string, get, matched, sentences, (, )...   \n",
       "3  [public, static, implementation, prioritize, (...   \n",
       "\n",
       "                                        new_code_raw  \\\n",
       "0    public static OrientBaseGraph getGraph() {\\n...   \n",
       "1  \\tpublic static Tag exception(Throwable except...   \n",
       "2    public StringBuffer getMatchedSentences() {\\...   \n",
       "3      public static Implementation prioritize(It...   \n",
       "\n",
       "                                  new_code_subtokens  \\\n",
       "0  [public, static, orient, base, graph, get, gra...   \n",
       "1  [public, static, tag, exception, (, throwable,...   \n",
       "2  [public, string, buffer, get, matched, sentenc...   \n",
       "3  [public, static, implementation, prioritize, (...   \n",
       "\n",
       "                            span_diff_code_subtokens  \\\n",
       "0  [<KEEP>, public, static, orient, base, graph, ...   \n",
       "1  [<KEEP>, public, static, tag, exception, (, th...   \n",
       "2  [<KEEP>, public, string, <KEEP_END>, <INSERT>,...   \n",
       "3  [<KEEP>, public, static, implementation, prior...   \n",
       "\n",
       "                           token_diff_code_subtokens  AST_level  \\\n",
       "0  [<KEEP>, public, <KEEP>, static, <KEEP>, orien...          8   \n",
       "1  [<KEEP>, public, <KEEP>, static, <KEEP>, tag, ...          9   \n",
       "2  [<KEEP>, public, <KEEP>, string, <INSERT>, buf...         10   \n",
       "3  [<KEEP>, public, <KEEP>, static, <KEEP>, imple...          9   \n",
       "\n",
       "                                        AST_BFSnodes  \\\n",
       "0  [MethodDeclaration, static, public, ReferenceT...   \n",
       "1  [MethodDeclaration, static, public, ReferenceT...   \n",
       "2  [MethodDeclaration, public, ReferenceType, get...   \n",
       "3  [MethodDeclaration, static, public, ReferenceT...   \n",
       "\n",
       "                                        AST_PFSnodes  \\\n",
       "0  [MethodDeclaration, static, public, ReferenceT...   \n",
       "1  [MethodDeclaration, static, public, ReferenceT...   \n",
       "2  [MethodDeclaration, public, ReferenceType, Str...   \n",
       "3  [MethodDeclaration, static, public, ReferenceT...   \n",
       "\n",
       "                                    Child_Node_count  \n",
       "0  [7, 1, 2, 2, 1, 1, 2, 1, 3, 1, 1, 1, 3, 1, 2, ...  \n",
       "1  [7, 1, 2, 1, 2, 1, 3, 1, 1, 2, 2, 1, 1, 2, 3, ...  \n",
       "2  [6, 1, 2, 2, 1, 1, 2, 1, 1, 3, 2, 1, 2, 1, 3, ...  \n",
       "3  [8, 1, 2, 2, 2, 2, 0, 2, 2, 1, 2, 1, 2, 0, 2, ...  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = cleaned_test_df_ast_after_get_child\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a2095c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cf598e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = torch.load('save_GCBmodel.pt',map_location=torch.device('cuda:0'))\n",
    "model = torch.load('D:/BERT_learing/CCDP/for_captum/save_model/save_GCBmodel.pt',map_location=torch.device('cpu'))\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d76cca9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1+cpu\n",
      "None\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())  #输出为True，则安装无误\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "db0b8ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "aba07f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"D:/BERT_learing/code_comment_inconsistency_detection/graphcodebert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ea322f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaEmbeddings(\n",
       "  (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "  (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "  (token_type_embeddings): Embedding(1, 768)\n",
       "  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.roberta.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "db6de6fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaLayer(\n",
       "  (attention): RobertaAttention(\n",
       "    (self): RobertaSelfAttention(\n",
       "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (output): RobertaSelfOutput(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (intermediate): RobertaIntermediate(\n",
       "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    (intermediate_act_fn): GELUActivation()\n",
       "  )\n",
       "  (output): RobertaOutput(\n",
       "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.roberta.encoder.layer[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e79e32eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_embeddings = model.get_input_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ca9012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f64e8e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c241dc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict和squad_pos_forward_func可以合成一个\n",
    "def predict(inputs, position_ids=None, attention_mask=None):\n",
    "    output = model(inputs,\n",
    "                   position_ids=position_ids,\n",
    "                  attention_mask=attention_mask )\n",
    "    \n",
    "    prediction = output.logits\n",
    "    prediction_1 = nn.functional.softmax(prediction, dim=1)\n",
    "    prediction = prediction_1.max(1).values\n",
    "    out = torch.argmax(prediction_1, dim=-1)\n",
    "    # prediction：每个输入样本的最大预测概率。\n",
    "    # out：预测的类别标签。\n",
    "    # prediction_1：所有类别的预测概率。    \n",
    "    return prediction,out,prediction_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c4de032c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squad_pos_forward_func(inputs,position_ids=None, attention_mask=None, position=0):\n",
    "    pred ,_,_= predict(inputs,\n",
    "                     position_ids=position_ids,\n",
    "                   attention_mask=attention_mask)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7c1bd6f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 0)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_token_id = tokenizer.pad_token_id\n",
    "sep_token_id = tokenizer.sep_token_id\n",
    "cls_token_id = tokenizer.cls_token_id\n",
    "ref_token_id,sep_token_id,cls_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "63d48d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意长度\n",
    "def truncate(ids,len_tru = 512):\n",
    "    return ids[:len_tru] if len(ids) > len_tru else ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8206c991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这是单个数据的处理方式，应该要想数据集应该怎么处理\n",
    "def construct_input_ref_pair(comment,AST_type,  ref_token_id, sep_token_id, cls_token_id):\n",
    "    comment = tokenizer.encode(comment, add_special_tokens=False,truncation=True,max_length=512)\n",
    "    AST_type = tokenizer.encode(AST_type, add_special_tokens=False,truncation=True,max_length=512)\n",
    "    # construct input token ids\n",
    "    input_ids = [cls_token_id] + comment + [sep_token_id] + AST_type + [sep_token_id]\n",
    "\n",
    "    # construct reference token ids \n",
    "    ref_input_ids = [cls_token_id] + [ref_token_id] * len(comment) + [sep_token_id] + \\\n",
    "        [ref_token_id] * len(AST_type) + [sep_token_id]\n",
    "    input_ids = truncate(input_ids)\n",
    "    ref_input_ids = truncate(ref_input_ids)\n",
    "    return torch.tensor([input_ids], device=device), torch.tensor([ref_input_ids], device=device), len(comment)\n",
    "\n",
    "def construct_input_ref_token_type_pair(input_ids, sep_ind=0):\n",
    "    seq_len = input_ids.size(1)\n",
    "    token_type_ids = torch.tensor([[0 if i <= sep_ind else 1 for i in range(seq_len)]], device=device)\n",
    "    ref_token_type_ids = torch.zeros_like(token_type_ids, device=device)# * -1\n",
    "    return token_type_ids, ref_token_type_ids\n",
    "\n",
    "def construct_input_ref_pos_id_pair(input_ids):\n",
    "    seq_length = input_ids.size(1)\n",
    "    position_ids = torch.arange(seq_length, dtype=torch.long, device=device)\n",
    "    # we could potentially also use random permutation with `torch.randperm(seq_length, device=device)`\n",
    "    ref_position_ids = torch.zeros(seq_length, dtype=torch.long, device=device)\n",
    "\n",
    "    position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "    ref_position_ids = ref_position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "    return position_ids, ref_position_ids\n",
    "\n",
    "def construct_attention_mask(input_ids):\n",
    "    return torch.ones_like(input_ids)\n",
    "\n",
    "def construct_whole_bert_embeddings(input_ids, ref_input_ids, \\\n",
    "                                    token_type_ids=None, ref_token_type_ids=None, \\\n",
    "                                    position_ids=None, ref_position_ids=None):\n",
    "    input_embeddings = model.roberta.embeddings(input_ids, token_type_ids=token_type_ids, position_ids=position_ids)\n",
    "    ref_input_embeddings = model.roberta.embeddings(ref_input_ids, token_type_ids=ref_token_type_ids, position_ids=ref_position_ids)\n",
    "    \n",
    "    return input_embeddings, ref_input_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb71303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8e0e4a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_data_list(AST_list,comment_list):\n",
    "    input_ids_all = []\n",
    "    ref_input_ids_all = []\n",
    "    position_ids_all = []\n",
    "    attention_mask_all = []\n",
    "    token_type_ids_all = []\n",
    "    all_tokens_all = []\n",
    "    for i in range(len(AST_list)):\n",
    "        input_ids, ref_input_ids, comment_len = construct_input_ref_pair(comment_list[i],AST_list[i], ref_token_id, sep_token_id, cls_token_id)\n",
    "        token_type_ids, ref_token_type_ids = construct_input_ref_token_type_pair(input_ids, comment_len)\n",
    "        position_ids, ref_position_ids = construct_input_ref_pos_id_pair(input_ids)\n",
    "        attention_mask = construct_attention_mask(input_ids)\n",
    "        \n",
    "        indices = input_ids[0].detach().tolist()\n",
    "        \n",
    "        all_tokens = []                                       ###\n",
    "        for _, token in enumerate(indices):\n",
    "            all_tokens.append(tokenizer.decode([token]))\n",
    "        \n",
    "        input_ids_all.append(input_ids)\n",
    "        ref_input_ids_all.append(ref_input_ids)\n",
    "        position_ids_all.append(position_ids)\n",
    "        attention_mask_all.append(attention_mask)\n",
    "        token_type_ids_all.append(token_type_ids)\n",
    "        all_tokens_all.append(all_tokens)\n",
    "\n",
    "    return input_ids_all,ref_input_ids_all,position_ids_all,attention_mask_all,token_type_ids_all,all_tokens_all \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1b96eb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Annotation', 'AnnotationDeclaration', 'AnnotationMethod', 'ArrayCreator', 'ArrayInitializer', 'ArraySelector', 'AssertStatement', 'Assignment', 'BasicType', 'BinaryOperation', 'BlockStatement', 'BreakStatement', 'Cast', 'CatchClause', 'CatchClauseParameter', 'ClassCreator', 'ClassDeclaration', 'ClassReference', 'CompilationUnit', 'ConstantDeclaration', 'ConstructorDeclaration', 'ContinueStatement', 'Creator', 'Declaration', 'DoStatement', 'Documented', 'ElementArrayValue', 'ElementValuePair', 'EnhancedForControl', 'EnumBody', 'EnumConstantDeclaration', 'EnumDeclaration', 'ExplicitConstructorInvocation', 'Expression', 'FieldDeclaration', 'ForControl', 'ForStatement', 'FormalParameter', 'IfStatement', 'Import', 'InferredFormalParameter', 'InnerClassCreator', 'InterfaceDeclaration', 'Invocation', 'LambdaExpression', 'Literal', 'LocalVariableDeclaration', 'Member', 'MemberReference', 'MethodDeclaration', 'MethodInvocation', 'MethodReference', 'Node', 'PackageDeclaration', 'Primary', 'ReferenceType', 'ReturnStatement', 'Statement', 'StatementExpression', 'SuperConstructorInvocation', 'SuperMemberReference', 'SuperMethodInvocation', 'SwitchStatement', 'SwitchStatementCase', 'SynchronizedStatement', 'TernaryExpression', 'This', 'ThrowStatement', 'TryResource', 'TryStatement', 'Type', 'TypeArgument', 'TypeDeclaration', 'TypeParameter', 'VariableDeclaration', 'VariableDeclarator', 'VoidClassReference', 'WhileStatement'] 78\n"
     ]
    }
   ],
   "source": [
    "import javalang.tree\n",
    "\n",
    "# 获取javalang.tree模块中的所有类\n",
    "# 树节点的所有名称\n",
    "node_classes = [cls for cls in dir(javalang.tree) if isinstance(getattr(javalang.tree, cls), type)]\n",
    "\n",
    "print(node_classes,len(node_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "86337fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建树，用于计算父节点归因值\n",
    "class Node:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.children = []\n",
    "\n",
    "def build_tree(attribution_num, child_num):\n",
    "    # 初始化一个栈\n",
    "    stack = []\n",
    "    #  attribution_num [index]\n",
    "    index = 0\n",
    "    # 创建根节点并入栈\n",
    "    root = Node(attribution_num[0])\n",
    "    # 收集所有的父节点\n",
    "    parents = [root]  \n",
    "    \n",
    "    stack.append((root, child_num[index]))\n",
    "    index += 1\n",
    "    # 遍历 attribution_num\n",
    "    for i in range(1, len(attribution_num)):\n",
    "        \n",
    "        # 创建一个新的节点\n",
    "        node = Node(attribution_num[i])\n",
    "        \n",
    "        # 如果栈顶的节点还有子节点的位置，那么将新的节点添加为栈顶节点的子节点\n",
    "        if stack[-1][1] > 0 and attribution_num[i] != 0 :\n",
    "            stack[-1][0].children.append(node)\n",
    "            stack[-1] = (stack[-1][0], stack[-1][1] - 1)\n",
    "            \n",
    "        # 如果新的节点是一个父节点，那么将其压入栈中\n",
    "        if attribution_num[i] == 0 and stack[-1][1] > 0 and index < len(child_num):\n",
    "            \n",
    "            stack[-1][0].children.append(node)\n",
    "            stack[-1] = (stack[-1][0], stack[-1][1] - 1)\n",
    "            \n",
    "            \n",
    "            parents.append(node)\n",
    "            stack.append((node, child_num[index]))\n",
    "            index += 1\n",
    "            \n",
    "        # 如果栈顶的节点没有子节点的位置了，那么将其从栈中移除\n",
    "        while stack and stack[-1][1] == 0:\n",
    "            stack.pop()\n",
    "    return root,parents\n",
    "\n",
    "# 计算父节点归因值 ，这个对，用这个\n",
    "def calculate_parent_value(node):\n",
    "    if node.children:\n",
    "        node.data = sum(calculate_parent_value(child) for child in node.children) / len(node.children)\n",
    "    return node.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8bf22f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root,parents = build_tree(num_attr, num_child)\n",
    "\n",
    "# parent_values = []\n",
    "\n",
    "# calculate_parent_value(root)\n",
    "\n",
    "# # 返回所有父节点的值\n",
    "# parent_values = [node.data for node in parents]\n",
    "# print(parent_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c276770c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f1094ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前k个贡献最高的word 和 token_type 和 position\n",
    "# return value为归因贡献值  indices为词对应的索引  top_tokens为 词或位置或token_type\n",
    "def get_topk_attributed_tokens(attrs,all_token_t, k=5):\n",
    "    values_max, indices_max = torch.topk(attrs, k)\n",
    "    top_tokens_max = [all_token_t[idx] for idx in indices_max]\n",
    "    values_min, indices_min = torch.topk(attrs, k, largest=False)\n",
    "    top_tokens_min = [all_token_t[idx] for idx in indices_min] \n",
    "    \n",
    "    return top_tokens_max, values_max, indices_max,top_tokens_min,values_min,indices_min\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "72d63d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_t_1 = token\n",
    "# list_t_2 = attribute\n",
    "\n",
    "# list_t_1 为 已经转化token的单词， list_t_2 为 attribute\n",
    "def get_ast_num(nodes,list_t_1,list_t_2):\n",
    "    attr = []    \n",
    "    for node in nodes:\n",
    "        try:\n",
    "            index = list_t_1.index(node)       \n",
    "            del list_t_1[index]\n",
    "            \n",
    "            attr.append(list_t_2[index])\n",
    "            del list_t_2[index]\n",
    "\n",
    "        except Exception as e:\n",
    "            attr.append(0)\n",
    "    return nodes,attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6453886d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从 all_tokens 还原为 原单词 ，并且计算归因值\n",
    "def get_restore_words(code,comment,input_ids,all_tokens,attribution_num):\n",
    "    all_tokens_decode = tokenizer.decode(input_ids)\n",
    "    len_all_tokens_decode = len(all_tokens_decode) + 4\n",
    "    # 使用decode获得的序列，去掉分词之后的空格    例 ' a' -> 'a'\n",
    "    all_tokens_clean = []\n",
    "    for token in all_tokens:\n",
    "        s_without_leading_space = token.lstrip()\n",
    "        all_tokens_clean.append(s_without_leading_space)\n",
    "#     print('all_tokens_clean:\\n',all_tokens_clean)\n",
    "#     print('all_tokens_clean:\\n',len(all_tokens_clean))\n",
    "    \n",
    "\n",
    "    # 获得 code_comment_baseline\n",
    "    code = tokenizer.encode(code, add_special_tokens=False,truncation=True,max_length=512)\n",
    "    comment = tokenizer.encode(comment, add_special_tokens=False,truncation=True,max_length=512)\n",
    "    code_decode = tokenizer.decode(code)\n",
    "    comment_decode = tokenizer.decode(comment)\n",
    "    code_comment_baseline = tokenizer.decode(tokenizer.cls_token_id) + ' '+ comment_decode + ' '+ tokenizer.decode(tokenizer.sep_token_id) + ' ' + code_decode + ' ' + tokenizer.decode(tokenizer.sep_token_id)\n",
    "    code_comment_baseline = code_comment_baseline[:len_all_tokens_decode]\n",
    "    code_comment_baseline = split_punctuation(code_comment_baseline)\n",
    "    code_comment_baseline = code_comment_baseline.split()\n",
    "\n",
    "#     print('code_comment_baseline:\\n',code_comment_baseline)\n",
    "#     print('code_comment_baseline_len:\\n',len(code_comment_baseline))\n",
    "\n",
    "    \n",
    "    # 获得 相邻有几个token合并在一块的列表times  为了以后再计算attribute时求和\n",
    "    times = []\n",
    "    token_index = 0\n",
    "    for code_comment in code_comment_baseline:\n",
    "        temp = ''\n",
    "        time = 0\n",
    "        while temp != code_comment:\n",
    "            temp = temp + all_tokens_clean[token_index]\n",
    "            token_index = token_index + 1\n",
    "            time = time + 1\n",
    "        times.append(time)\n",
    "#     print('times:\\n',times)\n",
    "    \n",
    "    attribute_sum = []\n",
    "    start = 0\n",
    "    for time in times:\n",
    "        end = start + time\n",
    "        attribute = sum(attribution_num[start:end]) / time\n",
    "        attribute_sum.append(attribute)\n",
    "        start = end\n",
    "#     print('attribute_sum:\\n',attribute_sum)\n",
    "    return code_comment_baseline ,attribute_sum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "25d196c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import LayerIntegratedGradients\n",
    "from captum.attr import visualization as viz\n",
    "\n",
    "lig = LayerIntegratedGradients(squad_pos_forward_func,input_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df99693c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b8be1d9",
   "metadata": {},
   "source": [
    "将父节点和归因值进行统计分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f57a3bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_sentence_3(code,comment,PFS,child_num,input_ids,ref_input_ids, token_type_ids,\\\n",
    "                         position_ids, attention_mask, all_tokens):\n",
    "    pre ,out,_ = predict(input_ids, position_ids=position_ids, attention_mask=attention_mask)\n",
    "\n",
    "    attributions_ig, delta_ig = lig.attribute(input_ids, baselines=ref_input_ids,\\\n",
    "                           additional_forward_args=(position_ids,attention_mask,0),return_convergence_delta=True,internal_batch_size=8)\n",
    "    \n",
    "    attributions = attributions_ig.sum(dim=2).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "#     print(delta_ig)\n",
    "#     print(attributions)\n",
    "    try:\n",
    "        all_tokens ,attributions = get_restore_words(code,comment,input_ids[0],all_tokens,attributions)     # 合并为一个单词\n",
    "        attributions = torch.tensor(attributions)\n",
    "       \n",
    "        attributions_copy = attributions.tolist()\n",
    "        all_tokens_copy = all_tokens\n",
    "\n",
    "        nodes,attr = get_ast_num(PFS,all_tokens_copy,attributions_copy)\n",
    "        # 保留5为小数\n",
    "        attr = [round(num, 5) for num in attr]\n",
    "        \n",
    "        root,parents = build_tree(attr, child_num)\n",
    "        parent_values = []\n",
    "        calculate_parent_value(root)\n",
    "        # 返回所有父节点的值\n",
    "        parent_values = [node.data for node in parents]\n",
    "\n",
    "        # 找到parent_value对应的字符，例如 MethodDeclaration：320\n",
    "        parent_node_name = [nodes[i] for i in range(len(nodes)) if attr[i] == 0]\n",
    "        \n",
    "        return out,parent_node_name,parent_values,nodes,attr\n",
    "    except Exception as e:\n",
    "        print(\"解析错误\")\n",
    "        return -1,_,_,_,_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0bafb88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_ASTNode_attribution(df):\n",
    "    code_list = df['new_code_raw']\n",
    "    comment_list = df['old_comment_raw']\n",
    "    ground_lable = df['label']\n",
    "    PFS_list = df['AST_PFSnodes']\n",
    "    child_num_list = df['Child_Node_count']\n",
    "    \n",
    "    input_ids_all,ref_input_ids_all,position_ids_all,attention_mask_all,\\\n",
    "    token_type_ids_all,all_tokens_all= input_data_list(code_list,comment_list)\n",
    "    \n",
    "    parent_node_name_true = []\n",
    "    parent_values_true = []\n",
    "    index_true = []\n",
    "    nodes_true = []\n",
    "    attr_true = []\n",
    "    \n",
    "    parent_node_name_false = []\n",
    "    parent_values_false = []\n",
    "    index_false = []\n",
    "    nodes_false = []\n",
    "    attr_false = []\n",
    "\n",
    "    \n",
    "    for i in range(len(code_list)): \n",
    "#         print(i)\n",
    "        out,parent_node_name,parent_values,nodes,attr\\\n",
    "        = interpret_sentence_3(code_list[i],comment_list[i],PFS_list[i],child_num_list[i],\\\n",
    "                               input_ids_all[i],ref_input_ids_all[i], token_type_ids_all[i],\\\n",
    "                               position_ids_all[i], attention_mask_all[i], all_tokens_all[i])\n",
    "#        解析错误的情况不能直接判断是否相等\n",
    "        if out != -1:\n",
    "            if out == ground_lable[i]:\n",
    "                index_true.append(i)\n",
    "                parent_node_name_true.append(parent_node_name)\n",
    "                parent_values_true.append(parent_values)\n",
    "                nodes_true.append(nodes)\n",
    "                attr_true.append(attr)\n",
    "            else :\n",
    "                index_false.append(i)\n",
    "                parent_node_name_false.append(parent_node_name)\n",
    "                parent_values_false.append(parent_values)\n",
    "                nodes_false.append(nodes)\n",
    "                attr_false.append(attr)\n",
    "\n",
    "    return index_true,index_false,parent_node_name_true,parent_values_true,nodes_true,attr_true,\\\n",
    "                                  parent_node_name_false,parent_values_false,nodes_false,attr_false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "56be760d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "解析错误\n"
     ]
    }
   ],
   "source": [
    "index_true,index_false,\\\n",
    "parent_node_name_true,parent_values_true,nodes_true,attr_true,\\\n",
    "parent_node_name_false,parent_values_false,nodes_false,attr_false\\\n",
    "= analyse_ASTNode_attribution(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d099ec9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解决 parent_node_name 与 parent_values 数量不一致问题\n",
    "def clean_parent_node(parent_node_name,node_class):\n",
    "    final_parent_node = []\n",
    "    for parent_node in parent_node_name:\n",
    "        new_parent_node = []\n",
    "        for p in parent_node:\n",
    "            if p in node_class:\n",
    "                new_parent_node.append(p)\n",
    "        final_parent_node.append(new_parent_node)  \n",
    "    return final_parent_node\n",
    "# node_classes 为 javalang库中树节点的所有成员名称\n",
    "parent_node_name_true = clean_parent_node(parent_node_name_true,node_classes)\n",
    "parent_node_name_false = clean_parent_node(parent_node_name_false,node_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "19b2b040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(parent_node_name_true),len(index_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "29c9a8e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "02a7bc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可以再分析一下原因写进文章里,后六个是我自己加的     这个还得在过滤一下\n",
    "# 用 8 - 10 个就行 画图之后挑出好看的，或者对比幅度大一点的\n",
    "after_filter_name = ['MethodDeclaration','VariableDeclarator','StatementExpression','IfStatement',\n",
    "                    'ForStatement','WhileStatement','TryStatement', 'ReturnStatement']\n",
    "\n",
    "Not_delet_AST_token_type = ['FormalParameter','ClassReference', 'BasicType', 'InterfaceDeclaration',\n",
    "                            'CatchClauseParameter', 'MethodInvocation', 'SuperMethodInvocation', \n",
    "                            'SuperMemberReference', 'ConstructorDeclaration', 'ReferenceType',\n",
    "                            'MethodDeclaration', 'VariableDeclarator', 'IfStatement',\n",
    "                            'WhileStatement', 'DoStatement', 'ForStatement', 'AssertStatement', \n",
    "                            'BreakStatement', 'ContinueStatement', 'ReturnStatement', 'ThrowStatement',\n",
    "                            'SynchronizedStatement', 'TryStatement', 'SwitchStatement', 'BlockStatement', \n",
    "                            'StatementExpression', 'TryResource', 'CatchClause', 'CatchClauseParameter',\n",
    "                            'SwitchStatementCase', 'ForControl', 'EnhancedForControl','BinaryOperation',\n",
    "                            'UnaryOperation','TernaryExpression','SynchronizedStatement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "27d93a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "02c01afc",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('MethodDeclaration', 0.07073160714285713),\n",
       " ('ReferenceType', 0.06289),\n",
       " ('LocalVariableDeclaration', 0.027299583333333335),\n",
       " ('IfStatement', 0.03575916666666667),\n",
       " ('ReturnStatement', 0.00665),\n",
       " ('ReferenceType', 0.00665),\n",
       " ('VariableDeclarator', 0.06486833333333333),\n",
       " ('MethodInvocation', 0.053006666666666674),\n",
       " ('BinaryOperation', 0.053006666666666674),\n",
       " ('MemberReference', 0.07591),\n",
       " ('ReferenceType', 0.0347),\n",
       " ('StatementExpression', 0.01884),\n",
       " ('Assignment', 0.03333166666666667),\n",
       " ('MemberReference', 0.018029999999999997),\n",
       " ('ClassCreator', 0.018029999999999997),\n",
       " ('ReferenceType', 0.0144),\n",
       " ('Cast', 0.0144),\n",
       " ('ReferenceType', 0.04251),\n",
       " ('MemberReference', 0.04251),\n",
       " ('ClassCreator', 0.050855),\n",
       " ('ReferenceType', 0.03111),\n",
       " ('Cast', 0.03111),\n",
       " ('ReferenceType', 0.00636),\n",
       " ('MemberReference', 0.00636))"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = tuple(zip(parent_node_name_true[0], parent_values_true[0]))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3762ff96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('MethodDeclaration', 0.07073160714285713),\n",
       " ('IfStatement', 0.03575916666666667),\n",
       " ('ReturnStatement', 0.00665),\n",
       " ('VariableDeclarator', 0.06486833333333333),\n",
       " ('StatementExpression', 0.01884)]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = tuple(zip(parent_node_name_true[0], parent_values_true[0]))\n",
    "temp = []\n",
    "for element in result:\n",
    "    if element[0] in after_filter_name:\n",
    "        temp.append(element) \n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "966d1316",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[122], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mzip\u001b[39m(parent_node_name_true[\u001b[38;5;241m1\u001b[39m], parent_values_true[\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m      2\u001b[0m result\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "result = tuple(zip(parent_node_name_true[1], parent_values_true[1]))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543b007d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tuple(zip(parent_node_name_true[1], parent_values_true[1]))\n",
    "temp = []\n",
    "for element in result:\n",
    "    if element[0] in after_filter_name:\n",
    "        temp.append(element) \n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a221403",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tuple(zip(parent_node_name_true[2], parent_values_true[2]))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a47e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tuple(zip(parent_node_name_true[2], parent_values_true[2]))\n",
    "temp = []\n",
    "for element in result:\n",
    "    if element[0] in after_filter_name:\n",
    "        temp.append(element) \n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c80f9fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('MethodDeclaration', -0.009139519675925925),\n",
       " ('ForStatement', -0.008795),\n",
       " ('ReturnStatement', -0.01721),\n",
       " ('VariableDeclarator', -0.00038000000000000013),\n",
       " ('VariableDeclarator', -0.011155),\n",
       " ('StatementExpression', -0.00044041666666666556),\n",
       " ('StatementExpression', -0.00044041666666666556),\n",
       " ('VariableDeclarator', -0.00044041666666666556)]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = tuple(zip(parent_node_name_false[0], parent_values_false[0]))\n",
    "temp = []\n",
    "for element in result:\n",
    "    if element[0] in after_filter_name:\n",
    "        temp.append(element) \n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0c4a051e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('MethodDeclaration', -0.0660007763671875),\n",
       " ('ForStatement', -0.012781171875),\n",
       " ('ReturnStatement', -0.0225575),\n",
       " ('VariableDeclarator', -0.0030048437499999997),\n",
       " ('VariableDeclarator', -0.01684),\n",
       " ('StatementExpression', -0.04821875)]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = tuple(zip(parent_node_name_false[1], parent_values_false[1]))\n",
    "temp = []\n",
    "for element in result:\n",
    "    if element[0] in after_filter_name:\n",
    "        temp.append(element) \n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f2a2aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197ea846",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10c9f97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leitx",
   "language": "python",
   "name": "leitx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
