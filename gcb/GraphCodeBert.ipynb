{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50a88c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import time\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import torch.nn as nn\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c00bc998",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94b6abfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at D:/LTX/code_comment_inconsistency_detection/graphcodebert and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"D:/LTX/code_comment_inconsistency_detection/graphcodebert\"\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36f0ff65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaConfig {\n",
       "  \"_name_or_path\": \"D:/LTX/code_comment_inconsistency_detection/graphcodebert\",\n",
       "  \"architectures\": [\n",
       "    \"RobertaForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"max_position_embeddings\": 514,\n",
       "  \"model_type\": \"roberta\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.39.3\",\n",
       "  \"type_vocab_size\": 1,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50265\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac1f476",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "647f4bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 512\n",
    "MAX_EPOCHS = 100\n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 1e-5\n",
    "NUM_CLASSES = 2\n",
    "WEIGTH_DECAY = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b19fa11",
   "metadata": {},
   "source": [
    "处理数据  提取出 old_code_raw old_comment_raw label 三列，并且对old_code_raw的值中的\\n去掉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e93688da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_train_data():\n",
    "    train_param = pd.read_json(\"D:/LTX/code_comment_inconsistency_detection/data/param/train.json\")\n",
    "    train_return = pd.read_json(\"D:/LTX/code_comment_inconsistency_detection/data/return/train.json\")\n",
    "    train_summary = pd.read_json(\"D:/LTX/code_comment_inconsistency_detection/data/summary/train.json\")\n",
    "    train_df = pd.concat([train_summary,train_param, train_return], axis=0)\n",
    "    # train_df = train_df[:8397]\n",
    "    return train_df\n",
    "def retrieve_valid_data():\n",
    "    valid_param = pd.read_json(\"D:/LTX/code_comment_inconsistency_detection/data/param/valid.json\")\n",
    "    valid_return = pd.read_json(\"D:/LTX/code_comment_inconsistency_detection/data/return/valid.json\")\n",
    "    valid_summary = pd.read_json(\"D:/LTX/code_comment_inconsistency_detection/data/summary/valid.json\")\n",
    "    valid_df = pd.concat([valid_summary,valid_param, valid_return ], axis=0)\n",
    "    # valid_df = valid_df[:800]\n",
    "    return valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88eeffc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>comment_type</th>\n",
       "      <th>old_comment_raw</th>\n",
       "      <th>old_comment_subtokens</th>\n",
       "      <th>new_comment_raw</th>\n",
       "      <th>new_comment_subtokens</th>\n",
       "      <th>span_minimal_diff_comment_subtokens</th>\n",
       "      <th>old_code_raw</th>\n",
       "      <th>old_code_subtokens</th>\n",
       "      <th>new_code_raw</th>\n",
       "      <th>new_code_subtokens</th>\n",
       "      <th>span_diff_code_subtokens</th>\n",
       "      <th>token_diff_code_subtokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grails-plugins_grails-plugin-converters-5-Asso...</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Parses the given JSON and returns ether a JSON...</td>\n",
       "      <td>[parses, the, given, json, and, returns, ether...</td>\n",
       "      <td>Parses the given JSON and returns either a JSO...</td>\n",
       "      <td>[parses, the, given, json, and, returns, eithe...</td>\n",
       "      <td>[&lt;REPLACE_OLD&gt;, ether, &lt;REPLACE_NEW&gt;, either, ...</td>\n",
       "      <td>public static JSONElement parse(InputStrea...</td>\n",
       "      <td>[public, static, jsonelement, parse, (, input,...</td>\n",
       "      <td>public static JSONElement parse(InputStrea...</td>\n",
       "      <td>[public, static, jsonelement, parse, (, input,...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, jsonelement, parse, (...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;KEEP&gt;, jsone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jitsi_jitsi-4343-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Loads an image from a given image identifier.</td>\n",
       "      <td>[loads, an, image, from, a, given, image, iden...</td>\n",
       "      <td>Loads an image from a given image identifier.</td>\n",
       "      <td>[loads, an, image, from, a, given, image, iden...</td>\n",
       "      <td>[]</td>\n",
       "      <td>public static byte[] getImageInBytes(Strin...</td>\n",
       "      <td>[public, static, byte, [, ], get, image, in, b...</td>\n",
       "      <td>public static byte[] getImageInBytes(Strin...</td>\n",
       "      <td>[public, static, byte, [, ], get, image, in, b...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, byte, [, ], get, imag...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;KEEP&gt;, byte,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dropwizard_metrics-26-Associations-FirstSentence</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Creates a new  CounterMetric and registers it ...</td>\n",
       "      <td>[creates, a, new, counter, metric, and, regist...</td>\n",
       "      <td>Creates a new  com.yammer.metrics.core.Counter...</td>\n",
       "      <td>[creates, a, new, com, ., yammer, ., metrics, ...</td>\n",
       "      <td>[&lt;INSERT_OLD_KEEP_BEFORE&gt;, new, &lt;INSERT_NEW_KE...</td>\n",
       "      <td>public static CounterMetric newCounter(Cla...</td>\n",
       "      <td>[public, static, counter, metric, new, counter...</td>\n",
       "      <td>public static Counter newCounter(Class&lt;?&gt; ...</td>\n",
       "      <td>[public, static, counter, new, counter, (, cla...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, counter, &lt;KEEP_END&gt;, ...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;KEEP&gt;, count...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>google_ExoPlayer-92-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Derives a sample format corresponding to a giv...</td>\n",
       "      <td>[derives, a, sample, format, corresponding, to...</td>\n",
       "      <td>Derives a sample format corresponding to a giv...</td>\n",
       "      <td>[derives, a, sample, format, corresponding, to...</td>\n",
       "      <td>[]</td>\n",
       "      <td>private static Format getSampleFormat(Format...</td>\n",
       "      <td>[private, static, format, get, sample, format,...</td>\n",
       "      <td>private static Format getSampleFormat(Format...</td>\n",
       "      <td>[private, static, format, get, sample, format,...</td>\n",
       "      <td>[&lt;KEEP&gt;, private, static, format, get, sample,...</td>\n",
       "      <td>[&lt;KEEP&gt;, private, &lt;KEEP&gt;, static, &lt;KEEP&gt;, form...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>slachiewicz_orekit-main-661-Associations-First...</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Revert a rotation/rotation rate pair.</td>\n",
       "      <td>[revert, a, rotation, /, rotation, rate, pair, .]</td>\n",
       "      <td>Revert a rotation/rotation rate/ rotation acce...</td>\n",
       "      <td>[revert, a, rotation, /, rotation, rate, /, ro...</td>\n",
       "      <td>[&lt;REPLACE_OLD&gt;, pair, &lt;REPLACE_NEW&gt;, /, rotati...</td>\n",
       "      <td>public AngularCoordinates revert() {\\n    ...</td>\n",
       "      <td>[public, angular, coordinates, revert, (, ), {...</td>\n",
       "      <td>public AngularCoordinates revert() {\\n    ...</td>\n",
       "      <td>[public, angular, coordinates, revert, (, ), {...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, angular, coordinates, revert,...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, angular, &lt;KEEP&gt;, coor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  label comment_type  \\\n",
       "0  grails-plugins_grails-plugin-converters-5-Asso...      1      Summary   \n",
       "1                   jitsi_jitsi-4343-FirstSentence-0      0      Summary   \n",
       "2   dropwizard_metrics-26-Associations-FirstSentence      1      Summary   \n",
       "3                google_ExoPlayer-92-FirstSentence-0      0      Summary   \n",
       "4  slachiewicz_orekit-main-661-Associations-First...      1      Summary   \n",
       "\n",
       "                                     old_comment_raw  \\\n",
       "0  Parses the given JSON and returns ether a JSON...   \n",
       "1      Loads an image from a given image identifier.   \n",
       "2  Creates a new  CounterMetric and registers it ...   \n",
       "3  Derives a sample format corresponding to a giv...   \n",
       "4              Revert a rotation/rotation rate pair.   \n",
       "\n",
       "                               old_comment_subtokens  \\\n",
       "0  [parses, the, given, json, and, returns, ether...   \n",
       "1  [loads, an, image, from, a, given, image, iden...   \n",
       "2  [creates, a, new, counter, metric, and, regist...   \n",
       "3  [derives, a, sample, format, corresponding, to...   \n",
       "4  [revert, a, rotation, /, rotation, rate, pair, .]   \n",
       "\n",
       "                                     new_comment_raw  \\\n",
       "0  Parses the given JSON and returns either a JSO...   \n",
       "1      Loads an image from a given image identifier.   \n",
       "2  Creates a new  com.yammer.metrics.core.Counter...   \n",
       "3  Derives a sample format corresponding to a giv...   \n",
       "4  Revert a rotation/rotation rate/ rotation acce...   \n",
       "\n",
       "                               new_comment_subtokens  \\\n",
       "0  [parses, the, given, json, and, returns, eithe...   \n",
       "1  [loads, an, image, from, a, given, image, iden...   \n",
       "2  [creates, a, new, com, ., yammer, ., metrics, ...   \n",
       "3  [derives, a, sample, format, corresponding, to...   \n",
       "4  [revert, a, rotation, /, rotation, rate, /, ro...   \n",
       "\n",
       "                 span_minimal_diff_comment_subtokens  \\\n",
       "0  [<REPLACE_OLD>, ether, <REPLACE_NEW>, either, ...   \n",
       "1                                                 []   \n",
       "2  [<INSERT_OLD_KEEP_BEFORE>, new, <INSERT_NEW_KE...   \n",
       "3                                                 []   \n",
       "4  [<REPLACE_OLD>, pair, <REPLACE_NEW>, /, rotati...   \n",
       "\n",
       "                                        old_code_raw  \\\n",
       "0      public static JSONElement parse(InputStrea...   \n",
       "1      public static byte[] getImageInBytes(Strin...   \n",
       "2      public static CounterMetric newCounter(Cla...   \n",
       "3    private static Format getSampleFormat(Format...   \n",
       "4      public AngularCoordinates revert() {\\n    ...   \n",
       "\n",
       "                                  old_code_subtokens  \\\n",
       "0  [public, static, jsonelement, parse, (, input,...   \n",
       "1  [public, static, byte, [, ], get, image, in, b...   \n",
       "2  [public, static, counter, metric, new, counter...   \n",
       "3  [private, static, format, get, sample, format,...   \n",
       "4  [public, angular, coordinates, revert, (, ), {...   \n",
       "\n",
       "                                        new_code_raw  \\\n",
       "0      public static JSONElement parse(InputStrea...   \n",
       "1      public static byte[] getImageInBytes(Strin...   \n",
       "2      public static Counter newCounter(Class<?> ...   \n",
       "3    private static Format getSampleFormat(Format...   \n",
       "4      public AngularCoordinates revert() {\\n    ...   \n",
       "\n",
       "                                  new_code_subtokens  \\\n",
       "0  [public, static, jsonelement, parse, (, input,...   \n",
       "1  [public, static, byte, [, ], get, image, in, b...   \n",
       "2  [public, static, counter, new, counter, (, cla...   \n",
       "3  [private, static, format, get, sample, format,...   \n",
       "4  [public, angular, coordinates, revert, (, ), {...   \n",
       "\n",
       "                            span_diff_code_subtokens  \\\n",
       "0  [<KEEP>, public, static, jsonelement, parse, (...   \n",
       "1  [<KEEP>, public, static, byte, [, ], get, imag...   \n",
       "2  [<KEEP>, public, static, counter, <KEEP_END>, ...   \n",
       "3  [<KEEP>, private, static, format, get, sample,...   \n",
       "4  [<KEEP>, public, angular, coordinates, revert,...   \n",
       "\n",
       "                           token_diff_code_subtokens  \n",
       "0  [<KEEP>, public, <KEEP>, static, <KEEP>, jsone...  \n",
       "1  [<KEEP>, public, <KEEP>, static, <KEEP>, byte,...  \n",
       "2  [<KEEP>, public, <KEEP>, static, <KEEP>, count...  \n",
       "3  [<KEEP>, private, <KEEP>, static, <KEEP>, form...  \n",
       "4  [<KEEP>, public, <KEEP>, angular, <KEEP>, coor...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = retrieve_train_data()\n",
    "valid_df = retrieve_valid_data()\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72db5ace",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>comment_type</th>\n",
       "      <th>old_comment_raw</th>\n",
       "      <th>old_comment_subtokens</th>\n",
       "      <th>new_comment_raw</th>\n",
       "      <th>new_comment_subtokens</th>\n",
       "      <th>span_minimal_diff_comment_subtokens</th>\n",
       "      <th>old_code_raw</th>\n",
       "      <th>old_code_subtokens</th>\n",
       "      <th>new_code_raw</th>\n",
       "      <th>new_code_subtokens</th>\n",
       "      <th>span_diff_code_subtokens</th>\n",
       "      <th>token_diff_code_subtokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>todoroo_astrid-987-FirstSentence-0</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Return SQL selector query for getting tasks wi...</td>\n",
       "      <td>[return, sql, selector, query, for, getting, t...</td>\n",
       "      <td>Return SQL selector query for getting tasks wi...</td>\n",
       "      <td>[return, sql, selector, query, for, getting, t...</td>\n",
       "      <td>[&lt;INSERT_OLD_KEEP_BEFORE&gt;, tag, &lt;INSERT_NEW_KE...</td>\n",
       "      <td>public QueryTemplate queryTemplate(Cri...</td>\n",
       "      <td>[public, query, template, query, template, (, ...</td>\n",
       "      <td>public static QueryTemplate queryTempl...</td>\n",
       "      <td>[public, static, query, template, query, templ...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP_END&gt;, &lt;INSERT&gt;, static,...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;INSERT&gt;, static, &lt;KEEP&gt;, que...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Red5_red5_server-43-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Return period of ghost connections cleanup tas...</td>\n",
       "      <td>[return, period, of, ghost, connections, clean...</td>\n",
       "      <td>Return period of ghost connections cleanup tas...</td>\n",
       "      <td>[return, period, of, ghost, connections, clean...</td>\n",
       "      <td>[]</td>\n",
       "      <td>public int getGhostConnsCleanupPeriod() {\\...</td>\n",
       "      <td>[public, int, get, ghost, conns, cleanup, peri...</td>\n",
       "      <td>public int getGhostConnsCleanupPeriod() {\\...</td>\n",
       "      <td>[public, int, get, ghost, conns, cleanup, peri...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, int, get, ghost, conns, clean...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, int, &lt;KEEP&gt;, get, &lt;KE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nickman_Rindle-11-Associations-FirstSentence</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Allocates an initialized and initially unlocke...</td>\n",
       "      <td>[allocates, an, initialized, and, initially, u...</td>\n",
       "      <td>Allocates an initialized and initially unlocke...</td>\n",
       "      <td>[allocates, an, initialized, and, initially, u...</td>\n",
       "      <td>[&lt;INSERT_OLD_KEEP_BEFORE&gt;, unlocked, &lt;INSERT_N...</td>\n",
       "      <td>\\tpublic static long allocateSpinLock() {\\r\\n\\...</td>\n",
       "      <td>[public, static, long, allocate, spin, lock, (...</td>\n",
       "      <td>\\tpublic static SpinLock allocateSpinLock() {\\...</td>\n",
       "      <td>[public, static, spin, lock, allocate, spin, l...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, &lt;KEEP_END&gt;, &lt;REPLACE_...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;REPLACE_OLD&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>h2oai_h2o_2-427-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Rebalance a frame for load balancing</td>\n",
       "      <td>[rebalance, a, frame, for, load, balancing]</td>\n",
       "      <td>Rebalance a frame for load balancing</td>\n",
       "      <td>[rebalance, a, frame, for, load, balancing]</td>\n",
       "      <td>[]</td>\n",
       "      <td>private Frame reBalance(final Frame fr, bool...</td>\n",
       "      <td>[private, frame, re, balance, (, final, frame,...</td>\n",
       "      <td>private static Frame reBalance(final Frame f...</td>\n",
       "      <td>[private, static, frame, re, balance, (, final...</td>\n",
       "      <td>[&lt;KEEP&gt;, private, &lt;KEEP_END&gt;, &lt;INSERT&gt;, static...</td>\n",
       "      <td>[&lt;KEEP&gt;, private, &lt;INSERT&gt;, static, &lt;KEEP&gt;, fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sonatype_sonatype-aether-11-Associations-First...</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Sets the host of this proxy.</td>\n",
       "      <td>[sets, the, host, of, this, proxy, .]</td>\n",
       "      <td>Sets the host of the proxy.</td>\n",
       "      <td>[sets, the, host, of, the, proxy, .]</td>\n",
       "      <td>[&lt;REPLACE_OLD&gt;, this, &lt;REPLACE_NEW&gt;, the, &lt;REP...</td>\n",
       "      <td>public Proxy setHost( String host )\\n    {...</td>\n",
       "      <td>[public, proxy, set, host, (, string, host, ),...</td>\n",
       "      <td>public Proxy setHost( String host )\\n    {...</td>\n",
       "      <td>[public, proxy, set, host, (, string, host, ),...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, proxy, set, host, (, string, ...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, proxy, &lt;KEEP&gt;, set, &lt;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  label comment_type  \\\n",
       "0                 todoroo_astrid-987-FirstSentence-0      1      Summary   \n",
       "1                Red5_red5_server-43-FirstSentence-0      0      Summary   \n",
       "2       nickman_Rindle-11-Associations-FirstSentence      1      Summary   \n",
       "3                    h2oai_h2o_2-427-FirstSentence-0      0      Summary   \n",
       "4  sonatype_sonatype-aether-11-Associations-First...      1      Summary   \n",
       "\n",
       "                                     old_comment_raw  \\\n",
       "0  Return SQL selector query for getting tasks wi...   \n",
       "1  Return period of ghost connections cleanup tas...   \n",
       "2  Allocates an initialized and initially unlocke...   \n",
       "3               Rebalance a frame for load balancing   \n",
       "4                       Sets the host of this proxy.   \n",
       "\n",
       "                               old_comment_subtokens  \\\n",
       "0  [return, sql, selector, query, for, getting, t...   \n",
       "1  [return, period, of, ghost, connections, clean...   \n",
       "2  [allocates, an, initialized, and, initially, u...   \n",
       "3        [rebalance, a, frame, for, load, balancing]   \n",
       "4              [sets, the, host, of, this, proxy, .]   \n",
       "\n",
       "                                     new_comment_raw  \\\n",
       "0  Return SQL selector query for getting tasks wi...   \n",
       "1  Return period of ghost connections cleanup tas...   \n",
       "2  Allocates an initialized and initially unlocke...   \n",
       "3               Rebalance a frame for load balancing   \n",
       "4                        Sets the host of the proxy.   \n",
       "\n",
       "                               new_comment_subtokens  \\\n",
       "0  [return, sql, selector, query, for, getting, t...   \n",
       "1  [return, period, of, ghost, connections, clean...   \n",
       "2  [allocates, an, initialized, and, initially, u...   \n",
       "3        [rebalance, a, frame, for, load, balancing]   \n",
       "4               [sets, the, host, of, the, proxy, .]   \n",
       "\n",
       "                 span_minimal_diff_comment_subtokens  \\\n",
       "0  [<INSERT_OLD_KEEP_BEFORE>, tag, <INSERT_NEW_KE...   \n",
       "1                                                 []   \n",
       "2  [<INSERT_OLD_KEEP_BEFORE>, unlocked, <INSERT_N...   \n",
       "3                                                 []   \n",
       "4  [<REPLACE_OLD>, this, <REPLACE_NEW>, the, <REP...   \n",
       "\n",
       "                                        old_code_raw  \\\n",
       "0          public QueryTemplate queryTemplate(Cri...   \n",
       "1      public int getGhostConnsCleanupPeriod() {\\...   \n",
       "2  \\tpublic static long allocateSpinLock() {\\r\\n\\...   \n",
       "3    private Frame reBalance(final Frame fr, bool...   \n",
       "4      public Proxy setHost( String host )\\n    {...   \n",
       "\n",
       "                                  old_code_subtokens  \\\n",
       "0  [public, query, template, query, template, (, ...   \n",
       "1  [public, int, get, ghost, conns, cleanup, peri...   \n",
       "2  [public, static, long, allocate, spin, lock, (...   \n",
       "3  [private, frame, re, balance, (, final, frame,...   \n",
       "4  [public, proxy, set, host, (, string, host, ),...   \n",
       "\n",
       "                                        new_code_raw  \\\n",
       "0          public static QueryTemplate queryTempl...   \n",
       "1      public int getGhostConnsCleanupPeriod() {\\...   \n",
       "2  \\tpublic static SpinLock allocateSpinLock() {\\...   \n",
       "3    private static Frame reBalance(final Frame f...   \n",
       "4      public Proxy setHost( String host )\\n    {...   \n",
       "\n",
       "                                  new_code_subtokens  \\\n",
       "0  [public, static, query, template, query, templ...   \n",
       "1  [public, int, get, ghost, conns, cleanup, peri...   \n",
       "2  [public, static, spin, lock, allocate, spin, l...   \n",
       "3  [private, static, frame, re, balance, (, final...   \n",
       "4  [public, proxy, set, host, (, string, host, ),...   \n",
       "\n",
       "                            span_diff_code_subtokens  \\\n",
       "0  [<KEEP>, public, <KEEP_END>, <INSERT>, static,...   \n",
       "1  [<KEEP>, public, int, get, ghost, conns, clean...   \n",
       "2  [<KEEP>, public, static, <KEEP_END>, <REPLACE_...   \n",
       "3  [<KEEP>, private, <KEEP_END>, <INSERT>, static...   \n",
       "4  [<KEEP>, public, proxy, set, host, (, string, ...   \n",
       "\n",
       "                           token_diff_code_subtokens  \n",
       "0  [<KEEP>, public, <INSERT>, static, <KEEP>, que...  \n",
       "1  [<KEEP>, public, <KEEP>, int, <KEEP>, get, <KE...  \n",
       "2  [<KEEP>, public, <KEEP>, static, <REPLACE_OLD>...  \n",
       "3  [<KEEP>, private, <INSERT>, static, <KEEP>, fr...  \n",
       "4  [<KEEP>, public, <KEEP>, proxy, <KEEP>, set, <...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77830c74-15ec-45a8-b175-fd7822b3d1a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32988, 3756)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df),len(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a442d100-5125-4e72-ac90-d08516245acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    16494\n",
      "0    16494\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "1    1878\n",
      "0    1878\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_df['label'].value_counts())\n",
    "print(valid_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651fdca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b946d504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(df):\n",
    "    old_code_raw = df['new_code_raw']\n",
    "    old_code_raw = old_code_raw.values\n",
    "    old_code_raw = [str(ele) for ele in old_code_raw]\n",
    "       \n",
    "    multi_line_old_code = []\n",
    "    for i in range(len(old_code_raw)):\n",
    "        multi_line_test = old_code_raw[i].replace('\\n', ' ')   # 去掉\\n\n",
    "        multi_line_test = ' '.join(multi_line_test.split())    # 把多余空格变成一个空格\n",
    "        multi_line_old_code.append(multi_line_test) \n",
    "     \n",
    "    old_comment_raw = df['old_comment_raw']\n",
    "    old_comment_raw = old_comment_raw.values\n",
    "    old_comment_raw = [str(ele) for ele in old_comment_raw]\n",
    "    multi_line_old_comment = []\n",
    "    for i in range(len(old_comment_raw)):\n",
    "        multi_line_test = ' '.join(old_comment_raw[i].split())    # 把多余空格变成一个空格\n",
    "        multi_line_old_comment.append(multi_line_test)  \n",
    "    \n",
    "    df['new_code_raw'] = multi_line_old_code\n",
    "    df['old_comment_raw'] = multi_line_old_comment\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67d83632",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>comment_type</th>\n",
       "      <th>old_comment_raw</th>\n",
       "      <th>old_comment_subtokens</th>\n",
       "      <th>new_comment_raw</th>\n",
       "      <th>new_comment_subtokens</th>\n",
       "      <th>span_minimal_diff_comment_subtokens</th>\n",
       "      <th>old_code_raw</th>\n",
       "      <th>old_code_subtokens</th>\n",
       "      <th>new_code_raw</th>\n",
       "      <th>new_code_subtokens</th>\n",
       "      <th>span_diff_code_subtokens</th>\n",
       "      <th>token_diff_code_subtokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grails-plugins_grails-plugin-converters-5-Asso...</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Parses the given JSON and returns ether a JSON...</td>\n",
       "      <td>[parses, the, given, json, and, returns, ether...</td>\n",
       "      <td>Parses the given JSON and returns either a JSO...</td>\n",
       "      <td>[parses, the, given, json, and, returns, eithe...</td>\n",
       "      <td>[&lt;REPLACE_OLD&gt;, ether, &lt;REPLACE_NEW&gt;, either, ...</td>\n",
       "      <td>public static JSONElement parse(InputStrea...</td>\n",
       "      <td>[public, static, jsonelement, parse, (, input,...</td>\n",
       "      <td>public static JSONElement parse(InputStream is...</td>\n",
       "      <td>[public, static, jsonelement, parse, (, input,...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, jsonelement, parse, (...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;KEEP&gt;, jsone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jitsi_jitsi-4343-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Loads an image from a given image identifier.</td>\n",
       "      <td>[loads, an, image, from, a, given, image, iden...</td>\n",
       "      <td>Loads an image from a given image identifier.</td>\n",
       "      <td>[loads, an, image, from, a, given, image, iden...</td>\n",
       "      <td>[]</td>\n",
       "      <td>public static byte[] getImageInBytes(Strin...</td>\n",
       "      <td>[public, static, byte, [, ], get, image, in, b...</td>\n",
       "      <td>public static byte[] getImageInBytes(String im...</td>\n",
       "      <td>[public, static, byte, [, ], get, image, in, b...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, byte, [, ], get, imag...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;KEEP&gt;, byte,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dropwizard_metrics-26-Associations-FirstSentence</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Creates a new CounterMetric and registers it u...</td>\n",
       "      <td>[creates, a, new, counter, metric, and, regist...</td>\n",
       "      <td>Creates a new  com.yammer.metrics.core.Counter...</td>\n",
       "      <td>[creates, a, new, com, ., yammer, ., metrics, ...</td>\n",
       "      <td>[&lt;INSERT_OLD_KEEP_BEFORE&gt;, new, &lt;INSERT_NEW_KE...</td>\n",
       "      <td>public static CounterMetric newCounter(Cla...</td>\n",
       "      <td>[public, static, counter, metric, new, counter...</td>\n",
       "      <td>public static Counter newCounter(Class&lt;?&gt; klas...</td>\n",
       "      <td>[public, static, counter, new, counter, (, cla...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, counter, &lt;KEEP_END&gt;, ...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;KEEP&gt;, count...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>google_ExoPlayer-92-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Derives a sample format corresponding to a giv...</td>\n",
       "      <td>[derives, a, sample, format, corresponding, to...</td>\n",
       "      <td>Derives a sample format corresponding to a giv...</td>\n",
       "      <td>[derives, a, sample, format, corresponding, to...</td>\n",
       "      <td>[]</td>\n",
       "      <td>private static Format getSampleFormat(Format...</td>\n",
       "      <td>[private, static, format, get, sample, format,...</td>\n",
       "      <td>private static Format getSampleFormat(Format c...</td>\n",
       "      <td>[private, static, format, get, sample, format,...</td>\n",
       "      <td>[&lt;KEEP&gt;, private, static, format, get, sample,...</td>\n",
       "      <td>[&lt;KEEP&gt;, private, &lt;KEEP&gt;, static, &lt;KEEP&gt;, form...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>slachiewicz_orekit-main-661-Associations-First...</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Revert a rotation/rotation rate pair.</td>\n",
       "      <td>[revert, a, rotation, /, rotation, rate, pair, .]</td>\n",
       "      <td>Revert a rotation/rotation rate/ rotation acce...</td>\n",
       "      <td>[revert, a, rotation, /, rotation, rate, /, ro...</td>\n",
       "      <td>[&lt;REPLACE_OLD&gt;, pair, &lt;REPLACE_NEW&gt;, /, rotati...</td>\n",
       "      <td>public AngularCoordinates revert() {\\n    ...</td>\n",
       "      <td>[public, angular, coordinates, revert, (, ), {...</td>\n",
       "      <td>public AngularCoordinates revert() { return ne...</td>\n",
       "      <td>[public, angular, coordinates, revert, (, ), {...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, angular, coordinates, revert,...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, angular, &lt;KEEP&gt;, coor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  label comment_type  \\\n",
       "0  grails-plugins_grails-plugin-converters-5-Asso...      1      Summary   \n",
       "1                   jitsi_jitsi-4343-FirstSentence-0      0      Summary   \n",
       "2   dropwizard_metrics-26-Associations-FirstSentence      1      Summary   \n",
       "3                google_ExoPlayer-92-FirstSentence-0      0      Summary   \n",
       "4  slachiewicz_orekit-main-661-Associations-First...      1      Summary   \n",
       "\n",
       "                                     old_comment_raw  \\\n",
       "0  Parses the given JSON and returns ether a JSON...   \n",
       "1      Loads an image from a given image identifier.   \n",
       "2  Creates a new CounterMetric and registers it u...   \n",
       "3  Derives a sample format corresponding to a giv...   \n",
       "4              Revert a rotation/rotation rate pair.   \n",
       "\n",
       "                               old_comment_subtokens  \\\n",
       "0  [parses, the, given, json, and, returns, ether...   \n",
       "1  [loads, an, image, from, a, given, image, iden...   \n",
       "2  [creates, a, new, counter, metric, and, regist...   \n",
       "3  [derives, a, sample, format, corresponding, to...   \n",
       "4  [revert, a, rotation, /, rotation, rate, pair, .]   \n",
       "\n",
       "                                     new_comment_raw  \\\n",
       "0  Parses the given JSON and returns either a JSO...   \n",
       "1      Loads an image from a given image identifier.   \n",
       "2  Creates a new  com.yammer.metrics.core.Counter...   \n",
       "3  Derives a sample format corresponding to a giv...   \n",
       "4  Revert a rotation/rotation rate/ rotation acce...   \n",
       "\n",
       "                               new_comment_subtokens  \\\n",
       "0  [parses, the, given, json, and, returns, eithe...   \n",
       "1  [loads, an, image, from, a, given, image, iden...   \n",
       "2  [creates, a, new, com, ., yammer, ., metrics, ...   \n",
       "3  [derives, a, sample, format, corresponding, to...   \n",
       "4  [revert, a, rotation, /, rotation, rate, /, ro...   \n",
       "\n",
       "                 span_minimal_diff_comment_subtokens  \\\n",
       "0  [<REPLACE_OLD>, ether, <REPLACE_NEW>, either, ...   \n",
       "1                                                 []   \n",
       "2  [<INSERT_OLD_KEEP_BEFORE>, new, <INSERT_NEW_KE...   \n",
       "3                                                 []   \n",
       "4  [<REPLACE_OLD>, pair, <REPLACE_NEW>, /, rotati...   \n",
       "\n",
       "                                        old_code_raw  \\\n",
       "0      public static JSONElement parse(InputStrea...   \n",
       "1      public static byte[] getImageInBytes(Strin...   \n",
       "2      public static CounterMetric newCounter(Cla...   \n",
       "3    private static Format getSampleFormat(Format...   \n",
       "4      public AngularCoordinates revert() {\\n    ...   \n",
       "\n",
       "                                  old_code_subtokens  \\\n",
       "0  [public, static, jsonelement, parse, (, input,...   \n",
       "1  [public, static, byte, [, ], get, image, in, b...   \n",
       "2  [public, static, counter, metric, new, counter...   \n",
       "3  [private, static, format, get, sample, format,...   \n",
       "4  [public, angular, coordinates, revert, (, ), {...   \n",
       "\n",
       "                                        new_code_raw  \\\n",
       "0  public static JSONElement parse(InputStream is...   \n",
       "1  public static byte[] getImageInBytes(String im...   \n",
       "2  public static Counter newCounter(Class<?> klas...   \n",
       "3  private static Format getSampleFormat(Format c...   \n",
       "4  public AngularCoordinates revert() { return ne...   \n",
       "\n",
       "                                  new_code_subtokens  \\\n",
       "0  [public, static, jsonelement, parse, (, input,...   \n",
       "1  [public, static, byte, [, ], get, image, in, b...   \n",
       "2  [public, static, counter, new, counter, (, cla...   \n",
       "3  [private, static, format, get, sample, format,...   \n",
       "4  [public, angular, coordinates, revert, (, ), {...   \n",
       "\n",
       "                            span_diff_code_subtokens  \\\n",
       "0  [<KEEP>, public, static, jsonelement, parse, (...   \n",
       "1  [<KEEP>, public, static, byte, [, ], get, imag...   \n",
       "2  [<KEEP>, public, static, counter, <KEEP_END>, ...   \n",
       "3  [<KEEP>, private, static, format, get, sample,...   \n",
       "4  [<KEEP>, public, angular, coordinates, revert,...   \n",
       "\n",
       "                           token_diff_code_subtokens  \n",
       "0  [<KEEP>, public, <KEEP>, static, <KEEP>, jsone...  \n",
       "1  [<KEEP>, public, <KEEP>, static, <KEEP>, byte,...  \n",
       "2  [<KEEP>, public, <KEEP>, static, <KEEP>, count...  \n",
       "3  [<KEEP>, private, <KEEP>, static, <KEEP>, form...  \n",
       "4  [<KEEP>, public, <KEEP>, angular, <KEEP>, coor...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_clean = format_data(train_df)\n",
    "train_df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6abe2714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>comment_type</th>\n",
       "      <th>old_comment_raw</th>\n",
       "      <th>old_comment_subtokens</th>\n",
       "      <th>new_comment_raw</th>\n",
       "      <th>new_comment_subtokens</th>\n",
       "      <th>span_minimal_diff_comment_subtokens</th>\n",
       "      <th>old_code_raw</th>\n",
       "      <th>old_code_subtokens</th>\n",
       "      <th>new_code_raw</th>\n",
       "      <th>new_code_subtokens</th>\n",
       "      <th>span_diff_code_subtokens</th>\n",
       "      <th>token_diff_code_subtokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>todoroo_astrid-987-FirstSentence-0</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Return SQL selector query for getting tasks wi...</td>\n",
       "      <td>[return, sql, selector, query, for, getting, t...</td>\n",
       "      <td>Return SQL selector query for getting tasks wi...</td>\n",
       "      <td>[return, sql, selector, query, for, getting, t...</td>\n",
       "      <td>[&lt;INSERT_OLD_KEEP_BEFORE&gt;, tag, &lt;INSERT_NEW_KE...</td>\n",
       "      <td>public QueryTemplate queryTemplate(Cri...</td>\n",
       "      <td>[public, query, template, query, template, (, ...</td>\n",
       "      <td>public static QueryTemplate queryTemplate(Crit...</td>\n",
       "      <td>[public, static, query, template, query, templ...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP_END&gt;, &lt;INSERT&gt;, static,...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;INSERT&gt;, static, &lt;KEEP&gt;, que...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Red5_red5_server-43-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Return period of ghost connections cleanup tas...</td>\n",
       "      <td>[return, period, of, ghost, connections, clean...</td>\n",
       "      <td>Return period of ghost connections cleanup tas...</td>\n",
       "      <td>[return, period, of, ghost, connections, clean...</td>\n",
       "      <td>[]</td>\n",
       "      <td>public int getGhostConnsCleanupPeriod() {\\...</td>\n",
       "      <td>[public, int, get, ghost, conns, cleanup, peri...</td>\n",
       "      <td>public int getGhostConnsCleanupPeriod() { retu...</td>\n",
       "      <td>[public, int, get, ghost, conns, cleanup, peri...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, int, get, ghost, conns, clean...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, int, &lt;KEEP&gt;, get, &lt;KE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nickman_Rindle-11-Associations-FirstSentence</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Allocates an initialized and initially unlocke...</td>\n",
       "      <td>[allocates, an, initialized, and, initially, u...</td>\n",
       "      <td>Allocates an initialized and initially unlocke...</td>\n",
       "      <td>[allocates, an, initialized, and, initially, u...</td>\n",
       "      <td>[&lt;INSERT_OLD_KEEP_BEFORE&gt;, unlocked, &lt;INSERT_N...</td>\n",
       "      <td>\\tpublic static long allocateSpinLock() {\\r\\n\\...</td>\n",
       "      <td>[public, static, long, allocate, spin, lock, (...</td>\n",
       "      <td>public static SpinLock allocateSpinLock() { lo...</td>\n",
       "      <td>[public, static, spin, lock, allocate, spin, l...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, &lt;KEEP_END&gt;, &lt;REPLACE_...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;REPLACE_OLD&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>h2oai_h2o_2-427-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Rebalance a frame for load balancing</td>\n",
       "      <td>[rebalance, a, frame, for, load, balancing]</td>\n",
       "      <td>Rebalance a frame for load balancing</td>\n",
       "      <td>[rebalance, a, frame, for, load, balancing]</td>\n",
       "      <td>[]</td>\n",
       "      <td>private Frame reBalance(final Frame fr, bool...</td>\n",
       "      <td>[private, frame, re, balance, (, final, frame,...</td>\n",
       "      <td>private static Frame reBalance(final Frame fr,...</td>\n",
       "      <td>[private, static, frame, re, balance, (, final...</td>\n",
       "      <td>[&lt;KEEP&gt;, private, &lt;KEEP_END&gt;, &lt;INSERT&gt;, static...</td>\n",
       "      <td>[&lt;KEEP&gt;, private, &lt;INSERT&gt;, static, &lt;KEEP&gt;, fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sonatype_sonatype-aether-11-Associations-First...</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Sets the host of this proxy.</td>\n",
       "      <td>[sets, the, host, of, this, proxy, .]</td>\n",
       "      <td>Sets the host of the proxy.</td>\n",
       "      <td>[sets, the, host, of, the, proxy, .]</td>\n",
       "      <td>[&lt;REPLACE_OLD&gt;, this, &lt;REPLACE_NEW&gt;, the, &lt;REP...</td>\n",
       "      <td>public Proxy setHost( String host )\\n    {...</td>\n",
       "      <td>[public, proxy, set, host, (, string, host, ),...</td>\n",
       "      <td>public Proxy setHost( String host ) { return n...</td>\n",
       "      <td>[public, proxy, set, host, (, string, host, ),...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, proxy, set, host, (, string, ...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, proxy, &lt;KEEP&gt;, set, &lt;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  label comment_type  \\\n",
       "0                 todoroo_astrid-987-FirstSentence-0      1      Summary   \n",
       "1                Red5_red5_server-43-FirstSentence-0      0      Summary   \n",
       "2       nickman_Rindle-11-Associations-FirstSentence      1      Summary   \n",
       "3                    h2oai_h2o_2-427-FirstSentence-0      0      Summary   \n",
       "4  sonatype_sonatype-aether-11-Associations-First...      1      Summary   \n",
       "\n",
       "                                     old_comment_raw  \\\n",
       "0  Return SQL selector query for getting tasks wi...   \n",
       "1  Return period of ghost connections cleanup tas...   \n",
       "2  Allocates an initialized and initially unlocke...   \n",
       "3               Rebalance a frame for load balancing   \n",
       "4                       Sets the host of this proxy.   \n",
       "\n",
       "                               old_comment_subtokens  \\\n",
       "0  [return, sql, selector, query, for, getting, t...   \n",
       "1  [return, period, of, ghost, connections, clean...   \n",
       "2  [allocates, an, initialized, and, initially, u...   \n",
       "3        [rebalance, a, frame, for, load, balancing]   \n",
       "4              [sets, the, host, of, this, proxy, .]   \n",
       "\n",
       "                                     new_comment_raw  \\\n",
       "0  Return SQL selector query for getting tasks wi...   \n",
       "1  Return period of ghost connections cleanup tas...   \n",
       "2  Allocates an initialized and initially unlocke...   \n",
       "3               Rebalance a frame for load balancing   \n",
       "4                        Sets the host of the proxy.   \n",
       "\n",
       "                               new_comment_subtokens  \\\n",
       "0  [return, sql, selector, query, for, getting, t...   \n",
       "1  [return, period, of, ghost, connections, clean...   \n",
       "2  [allocates, an, initialized, and, initially, u...   \n",
       "3        [rebalance, a, frame, for, load, balancing]   \n",
       "4               [sets, the, host, of, the, proxy, .]   \n",
       "\n",
       "                 span_minimal_diff_comment_subtokens  \\\n",
       "0  [<INSERT_OLD_KEEP_BEFORE>, tag, <INSERT_NEW_KE...   \n",
       "1                                                 []   \n",
       "2  [<INSERT_OLD_KEEP_BEFORE>, unlocked, <INSERT_N...   \n",
       "3                                                 []   \n",
       "4  [<REPLACE_OLD>, this, <REPLACE_NEW>, the, <REP...   \n",
       "\n",
       "                                        old_code_raw  \\\n",
       "0          public QueryTemplate queryTemplate(Cri...   \n",
       "1      public int getGhostConnsCleanupPeriod() {\\...   \n",
       "2  \\tpublic static long allocateSpinLock() {\\r\\n\\...   \n",
       "3    private Frame reBalance(final Frame fr, bool...   \n",
       "4      public Proxy setHost( String host )\\n    {...   \n",
       "\n",
       "                                  old_code_subtokens  \\\n",
       "0  [public, query, template, query, template, (, ...   \n",
       "1  [public, int, get, ghost, conns, cleanup, peri...   \n",
       "2  [public, static, long, allocate, spin, lock, (...   \n",
       "3  [private, frame, re, balance, (, final, frame,...   \n",
       "4  [public, proxy, set, host, (, string, host, ),...   \n",
       "\n",
       "                                        new_code_raw  \\\n",
       "0  public static QueryTemplate queryTemplate(Crit...   \n",
       "1  public int getGhostConnsCleanupPeriod() { retu...   \n",
       "2  public static SpinLock allocateSpinLock() { lo...   \n",
       "3  private static Frame reBalance(final Frame fr,...   \n",
       "4  public Proxy setHost( String host ) { return n...   \n",
       "\n",
       "                                  new_code_subtokens  \\\n",
       "0  [public, static, query, template, query, templ...   \n",
       "1  [public, int, get, ghost, conns, cleanup, peri...   \n",
       "2  [public, static, spin, lock, allocate, spin, l...   \n",
       "3  [private, static, frame, re, balance, (, final...   \n",
       "4  [public, proxy, set, host, (, string, host, ),...   \n",
       "\n",
       "                            span_diff_code_subtokens  \\\n",
       "0  [<KEEP>, public, <KEEP_END>, <INSERT>, static,...   \n",
       "1  [<KEEP>, public, int, get, ghost, conns, clean...   \n",
       "2  [<KEEP>, public, static, <KEEP_END>, <REPLACE_...   \n",
       "3  [<KEEP>, private, <KEEP_END>, <INSERT>, static...   \n",
       "4  [<KEEP>, public, proxy, set, host, (, string, ...   \n",
       "\n",
       "                           token_diff_code_subtokens  \n",
       "0  [<KEEP>, public, <INSERT>, static, <KEEP>, que...  \n",
       "1  [<KEEP>, public, <KEEP>, int, <KEEP>, get, <KE...  \n",
       "2  [<KEEP>, public, <KEEP>, static, <REPLACE_OLD>...  \n",
       "3  [<KEEP>, private, <INSERT>, static, <KEEP>, fr...  \n",
       "4  [<KEEP>, public, <KEEP>, proxy, <KEEP>, set, <...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df_clean = format_data(valid_df)\n",
    "valid_df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6524f4f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7497d50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CocoDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        model_path = \"D:/LTX/code_comment_inconsistency_detection/graphcodebert\"\n",
    "        self.tokenizer = RobertaTokenizer.from_pretrained(model_path, do_lower_case=False)\n",
    "        self.data = self.load_data(self.df)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "    def load_data(self, df):\n",
    "        token_ids = []\n",
    "        mask_ids = []\n",
    "        seg_ids = []\n",
    "        labels = []\n",
    "        \n",
    "        code_list = df['new_code_raw'].to_list() \n",
    "        comment_list = df['old_comment_raw'].to_list()\n",
    "        label_list = df['label'].to_list()\n",
    "\n",
    "        for (code, comment, label) in zip(code_list, comment_list, label_list):\n",
    "            code_id = self.tokenizer(code, add_special_tokens=False, truncation=True, max_length=MAX_LEN)\n",
    "            comment_id = self.tokenizer(comment, add_special_tokens=False, truncation=True, max_length=MAX_LEN)\n",
    "            code_id = code_id[\"input_ids\"]\n",
    "            comment_id = comment_id[\"input_ids\"]\n",
    "            \n",
    "            # want [CLS] comment tokens [SEP] code tokens [SEP]\n",
    "            pair_token_ids = [self.tokenizer.cls_token_id] + comment_id + [self.tokenizer.sep_token_id] + code_id + [self.tokenizer.sep_token_id]\n",
    "            pair_token_ids = self.truncate(pair_token_ids)\n",
    "            code_len = len(code_id)\n",
    "            comment_len = len(comment_id)\n",
    "            \n",
    "            attention_mask_ids = torch.tensor([1] * (code_len + comment_len + 3)) # mask padded values\n",
    "            attention_mask_ids = self.truncate(attention_mask_ids)\n",
    "\n",
    "            \n",
    "            token_ids.append(torch.tensor(pair_token_ids))\n",
    "            mask_ids.append(attention_mask_ids)\n",
    "            labels.append(label)\n",
    "            \n",
    "        token_ids = pad_sequence(token_ids, batch_first=True)\n",
    "        mask_ids = pad_sequence(mask_ids, batch_first=True)\n",
    "        labels = torch.tensor(labels)\n",
    "        \n",
    "        dataset = TensorDataset(token_ids, mask_ids, labels)\n",
    "        return dataset\n",
    "\n",
    "    def truncate(self, ids):\n",
    "        return ids[:MAX_LEN] if len(ids) > MAX_LEN else ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e55828f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<__main__.CocoDataset at 0x1851f374af0>,\n",
       " <__main__.CocoDataset at 0x1851f374820>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = CocoDataset(train_df_clean)\n",
    "valid_data = CocoDataset(valid_df_clean)\n",
    "train_data,valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee37d978-4884-4203-88f8-1d723291d988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "454ba4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "def compute_metrics(predicted_labels, gold_labels):\n",
    "    predicted_labels = [label.item() for label in predicted_labels]\n",
    "    gold_labels = [label.item() for label in gold_labels]\n",
    "\n",
    "    assert len(predicted_labels) == len(gold_labels)\n",
    "\n",
    "    precision = precision_score(gold_labels, predicted_labels, zero_division=0)\n",
    "    recall = recall_score(gold_labels, predicted_labels, zero_division=0)\n",
    "    f1 = f1_score(gold_labels, predicted_labels, zero_division=0)\n",
    "    accuracy = accuracy_score(gold_labels, predicted_labels) \n",
    "\n",
    "    return precision, recall, f1, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca9237ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.utils.notebook import format_time\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from tqdm import tqdm\n",
    "def train(model,train_data_t,valid_data_t,patience=10):\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE)\n",
    "    valid_loader = DataLoader(dataset=valid_data, batch_size=BATCH_SIZE)\n",
    "\n",
    "    best_f1 = 0.0\n",
    "    epochs_without_improvement = 0\n",
    "    \n",
    "    total_steps = len(train_loader) * MAX_EPOCHS\n",
    "    print(\"   Train batch size = {}\".format(BATCH_SIZE))\n",
    "    print(\"   Total steps = {}\".format(total_steps))\n",
    "    print(f\"   Training Start!\")\n",
    "\n",
    "    for epoch in range(MAX_EPOCHS):\n",
    "        start = time.time()\n",
    "        model.to(device)\n",
    "        model.train()\n",
    "\n",
    "        train_loss = 0.0\n",
    "        predictions = []\n",
    "        gold_labels = []\n",
    "        times = 0\n",
    "        for batch_idx, (sequence, attention_masks, labels) in enumerate(tqdm(train_loader, desc=\"Training\", leave=True)):\n",
    "            sequence = sequence.to(device)\n",
    "            attention_masks = attention_masks.to(device)\n",
    "            labels = labels.to(device)\n",
    "#             print(batch_idx,sequence,attention_masks,labels)\n",
    "            \n",
    "            outputs = model(sequence, attention_mask=attention_masks, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            prediction = outputs.logits\n",
    "            times = times + 1\n",
    "#             print(times)\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            prediction = torch.argmax(prediction, dim=-1)\n",
    "\n",
    "            loss.backward()\n",
    "            clip_grad_norm_(model.parameters(), 1.0)  # 梯度截断\n",
    "\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            predictions.extend(prediction)\n",
    "            gold_labels.extend(labels)\n",
    "\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        train_precision, train_recall, train_f1, train_acc = compute_metrics(predictions, gold_labels)\n",
    "        train_time = format_time(time.time()-start)\n",
    "\n",
    "        model.eval()\n",
    "        valid_loss = 0.0\n",
    "        predictions = []\n",
    "        gold_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (sequence, attention_masks, labels) in enumerate(valid_loader):\n",
    "                sequence = sequence.to(device)\n",
    "                attention_masks = attention_masks.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(sequence, attention_mask=attention_masks, labels=labels)\n",
    "                loss = outputs.loss\n",
    "                prediction = outputs.logits\n",
    "                \n",
    "                valid_loss += loss.item()\n",
    "                prediction = torch.argmax(prediction, dim=-1)\n",
    "\n",
    "                predictions.extend(prediction)\n",
    "                gold_labels.extend(labels)\n",
    "\n",
    "        valid_time = format_time(time.time() - start)\n",
    "        valid_loss = valid_loss / len(valid_loader)\n",
    "        valid_precision, valid_recall, valid_f1, valid_acc = compute_metrics(predictions, gold_labels)\n",
    "\n",
    "        if valid_f1 != best_f1:\n",
    "            if valid_f1 > best_f1:\n",
    "                best_f1 = valid_f1\n",
    "                print(f\"New best validation f1 of {valid_f1:.3f}. Saving model.\")\n",
    "                torch.save(model, \"save_GCBmodel.pt\")\n",
    "            epochs_without_improvement = 0      \n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            \n",
    "        # 如果验证集上的f1连续patience个epoch没有变化，则停止训练\n",
    "        if epochs_without_improvement == patience:\n",
    "            print('Early stopping at epoch {}...'.format(epoch+1))\n",
    "            break\n",
    "\n",
    "\n",
    "        end = time.time()\n",
    "        hours, rem = divmod(end - start, 3600)\n",
    "        min, sec = divmod(rem, 60)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}: train_loss: {train_loss:.3f} train_precision: {train_precision:.3f} train_recall: {train_recall:.3f} train_f1: {train_f1:.3f} train_acc: {train_acc:.3f}\")\n",
    "        print(f\"\\t valid_loss: {valid_loss:.3f} valid_precision: {valid_precision:.3f} valid_recall: {valid_recall:.3f} valid_f1: {valid_f1:.3f} valid_acc: {valid_acc:.3f}\")\n",
    "        print(\"\\t {:0>2}:{:0>2}:{:05.2f}\".format(int(hours), int(min), sec))\n",
    "\n",
    "    print('   Training Completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2035879",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Train batch size = 8\n",
      "   Total steps = 412400\n",
      "   Training Start!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:30<00:00,  5.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best validation f1 of 0.720. Saving model.\n",
      "Epoch 1: train_loss: 0.479 train_precision: 0.799 train_recall: 0.725 train_f1: 0.760 train_acc: 0.771\n",
      "\t valid_loss: 0.557 valid_precision: 0.814 valid_recall: 0.645 valid_f1: 0.720 valid_acc: 0.749\n",
      "\t 00:14:11.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:31<00:00,  5.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best validation f1 of 0.728. Saving model.\n",
      "Epoch 2: train_loss: 0.363 train_precision: 0.880 train_recall: 0.826 train_f1: 0.852 train_acc: 0.856\n",
      "\t valid_loss: 0.803 valid_precision: 0.856 valid_recall: 0.634 valid_f1: 0.728 valid_acc: 0.764\n",
      "\t 00:14:08.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:30<00:00,  5.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best validation f1 of 0.748. Saving model.\n",
      "Epoch 3: train_loss: 0.294 train_precision: 0.922 train_recall: 0.885 train_f1: 0.903 train_acc: 0.905\n",
      "\t valid_loss: 1.123 valid_precision: 0.807 valid_recall: 0.698 valid_f1: 0.748 valid_acc: 0.765\n",
      "\t 00:14:07.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:31<00:00,  5.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: train_loss: 0.232 train_precision: 0.948 train_recall: 0.926 train_f1: 0.937 train_acc: 0.938\n",
      "\t valid_loss: 1.243 valid_precision: 0.846 valid_recall: 0.660 valid_f1: 0.741 valid_acc: 0.770\n",
      "\t 00:14:03.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:31<00:00,  5.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best validation f1 of 0.748. Saving model.\n",
      "Epoch 5: train_loss: 0.189 train_precision: 0.959 train_recall: 0.950 train_f1: 0.954 train_acc: 0.954\n",
      "\t valid_loss: 1.149 valid_precision: 0.863 valid_recall: 0.661 valid_f1: 0.748 valid_acc: 0.778\n",
      "\t 00:14:09.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:31<00:00,  5.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best validation f1 of 0.764. Saving model.\n",
      "Epoch 6: train_loss: 0.143 train_precision: 0.971 train_recall: 0.962 train_f1: 0.967 train_acc: 0.967\n",
      "\t valid_loss: 1.413 valid_precision: 0.814 valid_recall: 0.720 valid_f1: 0.764 valid_acc: 0.778\n",
      "\t 00:14:09.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:31<00:00,  5.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: train_loss: 0.123 train_precision: 0.975 train_recall: 0.971 train_f1: 0.973 train_acc: 0.973\n",
      "\t valid_loss: 1.528 valid_precision: 0.811 valid_recall: 0.717 valid_f1: 0.761 valid_acc: 0.775\n",
      "\t 00:14:03.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:32<00:00,  5.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: train_loss: 0.099 train_precision: 0.980 train_recall: 0.979 train_f1: 0.980 train_acc: 0.980\n",
      "\t valid_loss: 1.509 valid_precision: 0.826 valid_recall: 0.690 valid_f1: 0.752 valid_acc: 0.772\n",
      "\t 00:14:04.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:32<00:00,  5.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: train_loss: 0.094 train_precision: 0.982 train_recall: 0.980 train_f1: 0.981 train_acc: 0.981\n",
      "\t valid_loss: 1.583 valid_precision: 0.802 valid_recall: 0.698 valid_f1: 0.746 valid_acc: 0.763\n",
      "\t 00:14:04.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:34<00:00,  5.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: train_loss: 0.075 train_precision: 0.985 train_recall: 0.985 train_f1: 0.985 train_acc: 0.985\n",
      "\t valid_loss: 1.701 valid_precision: 0.833 valid_recall: 0.687 valid_f1: 0.753 valid_acc: 0.775\n",
      "\t 00:14:06.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:35<00:00,  5.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: train_loss: 0.071 train_precision: 0.987 train_recall: 0.985 train_f1: 0.986 train_acc: 0.986\n",
      "\t valid_loss: 1.679 valid_precision: 0.758 valid_recall: 0.758 valid_f1: 0.758 valid_acc: 0.758\n",
      "\t 00:14:07.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:36<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: train_loss: 0.063 train_precision: 0.987 train_recall: 0.988 train_f1: 0.988 train_acc: 0.988\n",
      "\t valid_loss: 1.735 valid_precision: 0.759 valid_recall: 0.757 valid_f1: 0.758 valid_acc: 0.758\n",
      "\t 00:14:08.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:36<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: train_loss: 0.055 train_precision: 0.988 train_recall: 0.990 train_f1: 0.989 train_acc: 0.989\n",
      "\t valid_loss: 2.015 valid_precision: 0.806 valid_recall: 0.702 valid_f1: 0.750 valid_acc: 0.766\n",
      "\t 00:14:08.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:36<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: train_loss: 0.050 train_precision: 0.990 train_recall: 0.991 train_f1: 0.991 train_acc: 0.991\n",
      "\t valid_loss: 1.984 valid_precision: 0.779 valid_recall: 0.720 valid_f1: 0.749 valid_acc: 0.758\n",
      "\t 00:14:09.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:36<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: train_loss: 0.047 train_precision: 0.990 train_recall: 0.992 train_f1: 0.991 train_acc: 0.991\n",
      "\t valid_loss: 2.106 valid_precision: 0.810 valid_recall: 0.687 valid_f1: 0.744 valid_acc: 0.763\n",
      "\t 00:14:08.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:36<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: train_loss: 0.043 train_precision: 0.992 train_recall: 0.991 train_f1: 0.992 train_acc: 0.992\n",
      "\t valid_loss: 1.767 valid_precision: 0.801 valid_recall: 0.713 valid_f1: 0.754 valid_acc: 0.768\n",
      "\t 00:14:08.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:37<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: train_loss: 0.041 train_precision: 0.992 train_recall: 0.993 train_f1: 0.992 train_acc: 0.992\n",
      "\t valid_loss: 1.913 valid_precision: 0.794 valid_recall: 0.686 valid_f1: 0.736 valid_acc: 0.754\n",
      "\t 00:14:09.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:38<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: train_loss: 0.033 train_precision: 0.993 train_recall: 0.995 train_f1: 0.994 train_acc: 0.994\n",
      "\t valid_loss: 1.964 valid_precision: 0.801 valid_recall: 0.694 valid_f1: 0.744 valid_acc: 0.761\n",
      "\t 00:14:11.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:38<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: train_loss: 0.039 train_precision: 0.992 train_recall: 0.993 train_f1: 0.993 train_acc: 0.993\n",
      "\t valid_loss: 1.856 valid_precision: 0.780 valid_recall: 0.738 valid_f1: 0.759 valid_acc: 0.765\n",
      "\t 00:14:11.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:37<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: train_loss: 0.035 train_precision: 0.993 train_recall: 0.994 train_f1: 0.994 train_acc: 0.994\n",
      "\t valid_loss: 1.879 valid_precision: 0.830 valid_recall: 0.674 valid_f1: 0.744 valid_acc: 0.768\n",
      "\t 00:14:09.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:38<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: train_loss: 0.031 train_precision: 0.995 train_recall: 0.994 train_f1: 0.995 train_acc: 0.995\n",
      "\t valid_loss: 2.340 valid_precision: 0.818 valid_recall: 0.661 valid_f1: 0.731 valid_acc: 0.757\n",
      "\t 00:14:10.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:38<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: train_loss: 0.032 train_precision: 0.995 train_recall: 0.994 train_f1: 0.995 train_acc: 0.995\n",
      "\t valid_loss: 2.242 valid_precision: 0.880 valid_recall: 0.600 valid_f1: 0.713 valid_acc: 0.759\n",
      "\t 00:14:11.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:38<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: train_loss: 0.030 train_precision: 0.995 train_recall: 0.994 train_f1: 0.995 train_acc: 0.995\n",
      "\t valid_loss: 2.023 valid_precision: 0.816 valid_recall: 0.668 valid_f1: 0.734 valid_acc: 0.759\n",
      "\t 00:14:10.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:37<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: train_loss: 0.027 train_precision: 0.994 train_recall: 0.995 train_f1: 0.995 train_acc: 0.995\n",
      "\t valid_loss: 2.271 valid_precision: 0.824 valid_recall: 0.661 valid_f1: 0.733 valid_acc: 0.760\n",
      "\t 00:14:09.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:39<00:00,  5.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: train_loss: 0.028 train_precision: 0.994 train_recall: 0.996 train_f1: 0.995 train_acc: 0.995\n",
      "\t valid_loss: 1.987 valid_precision: 0.832 valid_recall: 0.657 valid_f1: 0.734 valid_acc: 0.762\n",
      "\t 00:14:11.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:38<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: train_loss: 0.033 train_precision: 0.993 train_recall: 0.996 train_f1: 0.994 train_acc: 0.994\n",
      "\t valid_loss: 2.128 valid_precision: 0.844 valid_recall: 0.647 valid_f1: 0.733 valid_acc: 0.764\n",
      "\t 00:14:10.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:38<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: train_loss: 0.035 train_precision: 0.993 train_recall: 0.994 train_f1: 0.994 train_acc: 0.994\n",
      "\t valid_loss: 1.927 valid_precision: 0.789 valid_recall: 0.727 valid_f1: 0.757 valid_acc: 0.767\n",
      "\t 00:14:10.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:37<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: train_loss: 0.027 train_precision: 0.995 train_recall: 0.996 train_f1: 0.995 train_acc: 0.995\n",
      "\t valid_loss: 2.059 valid_precision: 0.854 valid_recall: 0.665 valid_f1: 0.748 valid_acc: 0.776\n",
      "\t 00:14:10.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:37<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: train_loss: 0.024 train_precision: 0.996 train_recall: 0.997 train_f1: 0.996 train_acc: 0.996\n",
      "\t valid_loss: 1.986 valid_precision: 0.762 valid_recall: 0.724 valid_f1: 0.743 valid_acc: 0.749\n",
      "\t 00:14:10.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:38<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: train_loss: 0.025 train_precision: 0.995 train_recall: 0.996 train_f1: 0.996 train_acc: 0.996\n",
      "\t valid_loss: 1.890 valid_precision: 0.825 valid_recall: 0.654 valid_f1: 0.730 valid_acc: 0.758\n",
      "\t 00:14:11.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:38<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: train_loss: 0.020 train_precision: 0.996 train_recall: 0.997 train_f1: 0.997 train_acc: 0.997\n",
      "\t valid_loss: 2.037 valid_precision: 0.849 valid_recall: 0.657 valid_f1: 0.741 valid_acc: 0.770\n",
      "\t 00:14:11.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:37<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: train_loss: 0.020 train_precision: 0.996 train_recall: 0.997 train_f1: 0.996 train_acc: 0.996\n",
      "\t valid_loss: 1.984 valid_precision: 0.836 valid_recall: 0.678 valid_f1: 0.749 valid_acc: 0.773\n",
      "\t 00:14:10.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:37<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: train_loss: 0.023 train_precision: 0.996 train_recall: 0.996 train_f1: 0.996 train_acc: 0.996\n",
      "\t valid_loss: 2.013 valid_precision: 0.825 valid_recall: 0.683 valid_f1: 0.747 valid_acc: 0.769\n",
      "\t 00:14:09.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:37<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: train_loss: 0.020 train_precision: 0.996 train_recall: 0.997 train_f1: 0.997 train_acc: 0.997\n",
      "\t valid_loss: 2.207 valid_precision: 0.851 valid_recall: 0.646 valid_f1: 0.734 valid_acc: 0.766\n",
      "\t 00:14:09.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:37<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: train_loss: 0.021 train_precision: 0.997 train_recall: 0.996 train_f1: 0.997 train_acc: 0.997\n",
      "\t valid_loss: 1.903 valid_precision: 0.819 valid_recall: 0.691 valid_f1: 0.749 valid_acc: 0.769\n",
      "\t 00:14:09.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:37<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: train_loss: 0.021 train_precision: 0.996 train_recall: 0.996 train_f1: 0.996 train_acc: 0.996\n",
      "\t valid_loss: 2.043 valid_precision: 0.814 valid_recall: 0.687 valid_f1: 0.745 valid_acc: 0.765\n",
      "\t 00:14:08.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:37<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: train_loss: 0.019 train_precision: 0.997 train_recall: 0.997 train_f1: 0.997 train_acc: 0.997\n",
      "\t valid_loss: 2.013 valid_precision: 0.854 valid_recall: 0.650 valid_f1: 0.738 valid_acc: 0.770\n",
      "\t 00:14:09.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:37<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: train_loss: 0.018 train_precision: 0.997 train_recall: 0.997 train_f1: 0.997 train_acc: 0.997\n",
      "\t valid_loss: 2.024 valid_precision: 0.809 valid_recall: 0.704 valid_f1: 0.753 valid_acc: 0.769\n",
      "\t 00:14:09.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:37<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: train_loss: 0.019 train_precision: 0.996 train_recall: 0.997 train_f1: 0.997 train_acc: 0.997\n",
      "\t valid_loss: 2.160 valid_precision: 0.868 valid_recall: 0.629 valid_f1: 0.729 valid_acc: 0.767\n",
      "\t 00:14:10.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:37<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: train_loss: 0.016 train_precision: 0.997 train_recall: 0.998 train_f1: 0.997 train_acc: 0.997\n",
      "\t valid_loss: 2.200 valid_precision: 0.826 valid_recall: 0.673 valid_f1: 0.742 valid_acc: 0.766\n",
      "\t 00:14:09.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:36<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: train_loss: 0.020 train_precision: 0.997 train_recall: 0.996 train_f1: 0.997 train_acc: 0.997\n",
      "\t valid_loss: 2.077 valid_precision: 0.861 valid_recall: 0.645 valid_f1: 0.738 valid_acc: 0.771\n",
      "\t 00:14:09.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:37<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: train_loss: 0.016 train_precision: 0.998 train_recall: 0.997 train_f1: 0.997 train_acc: 0.997\n",
      "\t valid_loss: 1.965 valid_precision: 0.837 valid_recall: 0.688 valid_f1: 0.756 valid_acc: 0.777\n",
      "\t 00:14:10.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:37<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: train_loss: 0.018 train_precision: 0.997 train_recall: 0.997 train_f1: 0.997 train_acc: 0.997\n",
      "\t valid_loss: 2.256 valid_precision: 0.879 valid_recall: 0.615 valid_f1: 0.724 valid_acc: 0.765\n",
      "\t 00:14:10.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:38<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: train_loss: 0.016 train_precision: 0.997 train_recall: 0.997 train_f1: 0.997 train_acc: 0.997\n",
      "\t valid_loss: 2.034 valid_precision: 0.810 valid_recall: 0.696 valid_f1: 0.749 valid_acc: 0.767\n",
      "\t 00:14:10.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:36<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: train_loss: 0.017 train_precision: 0.997 train_recall: 0.997 train_f1: 0.997 train_acc: 0.997\n",
      "\t valid_loss: 1.961 valid_precision: 0.841 valid_recall: 0.684 valid_f1: 0.754 valid_acc: 0.777\n",
      "\t 00:14:08.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:37<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: train_loss: 0.015 train_precision: 0.998 train_recall: 0.997 train_f1: 0.997 train_acc: 0.997\n",
      "\t valid_loss: 2.033 valid_precision: 0.836 valid_recall: 0.684 valid_f1: 0.752 valid_acc: 0.775\n",
      "\t 00:14:09.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:36<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: train_loss: 0.017 train_precision: 0.998 train_recall: 0.997 train_f1: 0.997 train_acc: 0.997\n",
      "\t valid_loss: 2.048 valid_precision: 0.810 valid_recall: 0.702 valid_f1: 0.752 valid_acc: 0.769\n",
      "\t 00:14:09.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:37<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: train_loss: 0.015 train_precision: 0.997 train_recall: 0.997 train_f1: 0.997 train_acc: 0.997\n",
      "\t valid_loss: 2.125 valid_precision: 0.810 valid_recall: 0.670 valid_f1: 0.733 valid_acc: 0.756\n",
      "\t 00:14:09.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:36<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: train_loss: 0.013 train_precision: 0.997 train_recall: 0.998 train_f1: 0.998 train_acc: 0.998\n",
      "\t valid_loss: 2.316 valid_precision: 0.860 valid_recall: 0.642 valid_f1: 0.735 valid_acc: 0.769\n",
      "\t 00:14:08.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:37<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: train_loss: 0.015 train_precision: 0.997 train_recall: 0.998 train_f1: 0.998 train_acc: 0.998\n",
      "\t valid_loss: 1.945 valid_precision: 0.851 valid_recall: 0.682 valid_f1: 0.757 valid_acc: 0.781\n",
      "\t 00:14:09.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:37<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best validation f1 of 0.767. Saving model.\n",
      "Epoch 51: train_loss: 0.013 train_precision: 0.997 train_recall: 0.999 train_f1: 0.998 train_acc: 0.998\n",
      "\t valid_loss: 1.934 valid_precision: 0.777 valid_recall: 0.757 valid_f1: 0.767 valid_acc: 0.770\n",
      "\t 00:14:15.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:37<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: train_loss: 0.014 train_precision: 0.997 train_recall: 0.998 train_f1: 0.998 train_acc: 0.998\n",
      "\t valid_loss: 2.110 valid_precision: 0.794 valid_recall: 0.695 valid_f1: 0.742 valid_acc: 0.758\n",
      "\t 00:14:09.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:36<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53: train_loss: 0.014 train_precision: 0.998 train_recall: 0.998 train_f1: 0.998 train_acc: 0.998\n",
      "\t valid_loss: 2.048 valid_precision: 0.805 valid_recall: 0.708 valid_f1: 0.753 valid_acc: 0.768\n",
      "\t 00:14:08.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:37<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: train_loss: 0.013 train_precision: 0.997 train_recall: 0.998 train_f1: 0.998 train_acc: 0.998\n",
      "\t valid_loss: 2.113 valid_precision: 0.826 valid_recall: 0.661 valid_f1: 0.735 valid_acc: 0.761\n",
      "\t 00:14:09.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:36<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: train_loss: 0.013 train_precision: 0.998 train_recall: 0.998 train_f1: 0.998 train_acc: 0.998\n",
      "\t valid_loss: 1.964 valid_precision: 0.826 valid_recall: 0.698 valid_f1: 0.756 valid_acc: 0.775\n",
      "\t 00:14:09.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:37<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: train_loss: 0.013 train_precision: 0.997 train_recall: 0.998 train_f1: 0.998 train_acc: 0.998\n",
      "\t valid_loss: 2.022 valid_precision: 0.843 valid_recall: 0.674 valid_f1: 0.749 valid_acc: 0.774\n",
      "\t 00:14:09.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:38<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: train_loss: 0.011 train_precision: 0.997 train_recall: 0.998 train_f1: 0.998 train_acc: 0.998\n",
      "\t valid_loss: 1.946 valid_precision: 0.833 valid_recall: 0.683 valid_f1: 0.750 valid_acc: 0.773\n",
      "\t 00:14:10.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:36<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: train_loss: 0.011 train_precision: 0.998 train_recall: 0.998 train_f1: 0.998 train_acc: 0.998\n",
      "\t valid_loss: 2.117 valid_precision: 0.815 valid_recall: 0.679 valid_f1: 0.741 valid_acc: 0.762\n",
      "\t 00:14:09.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:37<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: train_loss: 0.013 train_precision: 0.997 train_recall: 0.998 train_f1: 0.998 train_acc: 0.998\n",
      "\t valid_loss: 2.106 valid_precision: 0.813 valid_recall: 0.709 valid_f1: 0.757 valid_acc: 0.773\n",
      "\t 00:14:09.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:37<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: train_loss: 0.012 train_precision: 0.998 train_recall: 0.998 train_f1: 0.998 train_acc: 0.998\n",
      "\t valid_loss: 2.090 valid_precision: 0.843 valid_recall: 0.684 valid_f1: 0.755 valid_acc: 0.778\n",
      "\t 00:14:09.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:37<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61: train_loss: 0.014 train_precision: 0.998 train_recall: 0.998 train_f1: 0.998 train_acc: 0.998\n",
      "\t valid_loss: 2.179 valid_precision: 0.846 valid_recall: 0.683 valid_f1: 0.756 valid_acc: 0.779\n",
      "\t 00:14:10.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:36<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62: train_loss: 0.009 train_precision: 0.998 train_recall: 0.998 train_f1: 0.998 train_acc: 0.998\n",
      "\t valid_loss: 1.945 valid_precision: 0.827 valid_recall: 0.690 valid_f1: 0.752 valid_acc: 0.773\n",
      "\t 00:14:08.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:37<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63: train_loss: 0.013 train_precision: 0.998 train_recall: 0.998 train_f1: 0.998 train_acc: 0.998\n",
      "\t valid_loss: 2.237 valid_precision: 0.863 valid_recall: 0.640 valid_f1: 0.735 valid_acc: 0.769\n",
      "\t 00:14:09.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:36<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64: train_loss: 0.012 train_precision: 0.998 train_recall: 0.998 train_f1: 0.998 train_acc: 0.998\n",
      "\t valid_loss: 2.220 valid_precision: 0.833 valid_recall: 0.676 valid_f1: 0.747 valid_acc: 0.771\n",
      "\t 00:14:09.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:37<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65: train_loss: 0.011 train_precision: 0.999 train_recall: 0.998 train_f1: 0.998 train_acc: 0.998\n",
      "\t valid_loss: 2.094 valid_precision: 0.822 valid_recall: 0.698 valid_f1: 0.755 valid_acc: 0.773\n",
      "\t 00:14:09.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:36<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66: train_loss: 0.010 train_precision: 0.998 train_recall: 0.998 train_f1: 0.998 train_acc: 0.998\n",
      "\t valid_loss: 2.219 valid_precision: 0.821 valid_recall: 0.694 valid_f1: 0.752 valid_acc: 0.771\n",
      "\t 00:14:09.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:35<00:00,  5.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67: train_loss: 0.010 train_precision: 0.997 train_recall: 0.999 train_f1: 0.998 train_acc: 0.998\n",
      "\t valid_loss: 2.324 valid_precision: 0.816 valid_recall: 0.687 valid_f1: 0.746 valid_acc: 0.766\n",
      "\t 00:14:08.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:37<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68: train_loss: 0.012 train_precision: 0.998 train_recall: 0.998 train_f1: 0.998 train_acc: 0.998\n",
      "\t valid_loss: 2.192 valid_precision: 0.841 valid_recall: 0.671 valid_f1: 0.747 valid_acc: 0.772\n",
      "\t 00:14:09.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:37<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69: train_loss: 0.011 train_precision: 0.998 train_recall: 0.998 train_f1: 0.998 train_acc: 0.998\n",
      "\t valid_loss: 2.034 valid_precision: 0.844 valid_recall: 0.695 valid_f1: 0.762 valid_acc: 0.783\n",
      "\t 00:14:09.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:37<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70: train_loss: 0.010 train_precision: 0.998 train_recall: 0.998 train_f1: 0.998 train_acc: 0.998\n",
      "\t valid_loss: 2.208 valid_precision: 0.821 valid_recall: 0.709 valid_f1: 0.761 valid_acc: 0.777\n",
      "\t 00:14:09.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:36<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71: train_loss: 0.013 train_precision: 0.998 train_recall: 0.998 train_f1: 0.998 train_acc: 0.998\n",
      "\t valid_loss: 2.025 valid_precision: 0.806 valid_recall: 0.727 valid_f1: 0.765 valid_acc: 0.776\n",
      "\t 00:14:09.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:37<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72: train_loss: 0.009 train_precision: 0.999 train_recall: 0.998 train_f1: 0.998 train_acc: 0.998\n",
      "\t valid_loss: 2.320 valid_precision: 0.786 valid_recall: 0.697 valid_f1: 0.739 valid_acc: 0.754\n",
      "\t 00:14:09.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:35<00:00,  5.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73: train_loss: 0.010 train_precision: 0.998 train_recall: 0.998 train_f1: 0.998 train_acc: 0.998\n",
      "\t valid_loss: 2.295 valid_precision: 0.783 valid_recall: 0.712 valid_f1: 0.746 valid_acc: 0.757\n",
      "\t 00:14:07.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:33<00:00,  5.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74: train_loss: 0.009 train_precision: 0.998 train_recall: 0.999 train_f1: 0.999 train_acc: 0.999\n",
      "\t valid_loss: 2.114 valid_precision: 0.835 valid_recall: 0.693 valid_f1: 0.757 valid_acc: 0.778\n",
      "\t 00:14:05.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:32<00:00,  5.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75: train_loss: 0.012 train_precision: 0.998 train_recall: 0.998 train_f1: 0.998 train_acc: 0.998\n",
      "\t valid_loss: 2.155 valid_precision: 0.804 valid_recall: 0.723 valid_f1: 0.761 valid_acc: 0.773\n",
      "\t 00:14:03.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:32<00:00,  5.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76: train_loss: 0.010 train_precision: 0.998 train_recall: 0.998 train_f1: 0.998 train_acc: 0.998\n",
      "\t valid_loss: 2.149 valid_precision: 0.854 valid_recall: 0.665 valid_f1: 0.748 valid_acc: 0.776\n",
      "\t 00:14:04.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:32<00:00,  5.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best validation f1 of 0.776. Saving model.\n",
      "Epoch 77: train_loss: 0.010 train_precision: 0.998 train_recall: 0.998 train_f1: 0.998 train_acc: 0.998\n",
      "\t valid_loss: 2.052 valid_precision: 0.825 valid_recall: 0.733 valid_f1: 0.776 valid_acc: 0.789\n",
      "\t 00:14:10.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:32<00:00,  5.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78: train_loss: 0.010 train_precision: 0.999 train_recall: 0.998 train_f1: 0.999 train_acc: 0.999\n",
      "\t valid_loss: 2.096 valid_precision: 0.864 valid_recall: 0.682 valid_f1: 0.762 valid_acc: 0.787\n",
      "\t 00:14:04.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:32<00:00,  5.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79: train_loss: 0.010 train_precision: 0.998 train_recall: 0.998 train_f1: 0.998 train_acc: 0.998\n",
      "\t valid_loss: 2.033 valid_precision: 0.818 valid_recall: 0.718 valid_f1: 0.765 valid_acc: 0.779\n",
      "\t 00:14:04.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:31<00:00,  5.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80: train_loss: 0.011 train_precision: 0.998 train_recall: 0.998 train_f1: 0.998 train_acc: 0.998\n",
      "\t valid_loss: 2.030 valid_precision: 0.831 valid_recall: 0.679 valid_f1: 0.747 valid_acc: 0.770\n",
      "\t 00:14:03.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:32<00:00,  5.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81: train_loss: 0.007 train_precision: 0.999 train_recall: 0.999 train_f1: 0.999 train_acc: 0.999\n",
      "\t valid_loss: 2.194 valid_precision: 0.836 valid_recall: 0.713 valid_f1: 0.770 valid_acc: 0.787\n",
      "\t 00:14:04.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:32<00:00,  5.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82: train_loss: 0.012 train_precision: 0.999 train_recall: 0.998 train_f1: 0.998 train_acc: 0.998\n",
      "\t valid_loss: 1.940 valid_precision: 0.819 valid_recall: 0.717 valid_f1: 0.765 valid_acc: 0.779\n",
      "\t 00:14:04.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:33<00:00,  5.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83: train_loss: 0.010 train_precision: 0.998 train_recall: 0.998 train_f1: 0.998 train_acc: 0.998\n",
      "\t valid_loss: 2.228 valid_precision: 0.790 valid_recall: 0.714 valid_f1: 0.750 valid_acc: 0.762\n",
      "\t 00:14:04.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:32<00:00,  5.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84: train_loss: 0.009 train_precision: 0.999 train_recall: 0.998 train_f1: 0.999 train_acc: 0.999\n",
      "\t valid_loss: 2.259 valid_precision: 0.861 valid_recall: 0.627 valid_f1: 0.725 valid_acc: 0.763\n",
      "\t 00:14:04.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:33<00:00,  5.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85: train_loss: 0.009 train_precision: 0.999 train_recall: 0.998 train_f1: 0.999 train_acc: 0.999\n",
      "\t valid_loss: 2.155 valid_precision: 0.857 valid_recall: 0.650 valid_f1: 0.739 valid_acc: 0.771\n",
      "\t 00:14:05.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:33<00:00,  5.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86: train_loss: 0.009 train_precision: 0.999 train_recall: 0.998 train_f1: 0.999 train_acc: 0.999\n",
      "\t valid_loss: 1.998 valid_precision: 0.833 valid_recall: 0.706 valid_f1: 0.764 valid_acc: 0.782\n",
      "\t 00:14:05.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:33<00:00,  5.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87: train_loss: 0.007 train_precision: 0.999 train_recall: 0.999 train_f1: 0.999 train_acc: 0.999\n",
      "\t valid_loss: 2.199 valid_precision: 0.844 valid_recall: 0.699 valid_f1: 0.764 valid_acc: 0.785\n",
      "\t 00:14:05.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████| 4124/4124 [13:32<00:00,  5.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88: train_loss: 0.009 train_precision: 0.999 train_recall: 0.998 train_f1: 0.999 train_acc: 0.999\n",
      "\t valid_loss: 2.061 valid_precision: 0.862 valid_recall: 0.667 valid_f1: 0.752 valid_acc: 0.780\n",
      "\t 00:14:04.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  81%|██████████████████████████████████████████████████████▊             | 3324/4124 [10:56<02:37,  5.08it/s]"
     ]
    }
   ],
   "source": [
    "train_losses,valid_losses = train(model,train_data,valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a9a837-335b-4a28-b11c-e59bac99d065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 假设train_losses和val_losses分别存储了训练损失和验证损失\n",
    "epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_losses, 'r-', label='Training Loss')\n",
    "plt.plot(epochs, valid_losses, 'b-', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db51c77-4394-4948-88d4-c7666188f01e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f601144",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a4d6cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8bee04-fcb2-4e4d-8c39-ff19265a1641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load(\"D:/LTX/code_comment_inconsistency_detection/model_save/save_GraphCodebert.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3cfb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_test_data():\n",
    "    test_param = pd.read_json(\"D:/LTX/code_comment_inconsistency_detection/data/param/test.json\")\n",
    "    test_return = pd.read_json(\"D:/LTX/code_comment_inconsistency_detection/data/return/test.json\")\n",
    "    test_summary = pd.read_json(\"D:/LTX/code_comment_inconsistency_detection/data/summary/test.json\")\n",
    "    test_df = pd.concat([test_summary,test_param, test_return], axis=0)\n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4167d636",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, device):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    predictions = []\n",
    "    gold_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (sequence, attention_masks, labels) in enumerate(test_loader):\n",
    "            sequence = sequence.to(device)\n",
    "            attention_masks = attention_masks.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(sequence, attention_mask=attention_masks, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            prediction = outputs.logits\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            prediction = torch.argmax(prediction, dim=-1)\n",
    "\n",
    "            predictions.extend(prediction)\n",
    "            gold_labels.extend(labels)\n",
    "        \n",
    "    test_loss = test_loss / len(test_loader)\n",
    "    test_precision, test_recall, test_f1, test_acc = compute_metrics(predictions, gold_labels)\n",
    "\n",
    "    print(f\"test_loss: {test_loss:.3f} test_precision: {test_precision:.3f} test_recall: {test_recall:.3f} test_f1: {test_f1:.3f} test_acc: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea8d479",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = retrieve_test_data()\n",
    "test_df_clean = format_data(test_df)\n",
    "\n",
    "test_data = CocoDataset(test_df_clean)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547c01b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fb4944",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea085e8-1ca0-4f49-843d-10c15566151c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leitx",
   "language": "python",
   "name": "leitx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
