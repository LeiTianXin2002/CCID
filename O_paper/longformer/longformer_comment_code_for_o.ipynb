{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd4b65eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import time\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import LongformerForSequenceClassification, LongformerTokenizer\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "# 解决服务器挂掉的问题\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33543e4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.39.3\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a20914ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb44ad63",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 1024\n",
    "MAX_EPOCHS = 100\n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 1e-5\n",
    "NUM_CLASSES = 2\n",
    "WEIGTH_DECAY = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27343058",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at D:/LTX/code_comment_inconsistency_detection/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14866.0994\n"
     ]
    }
   ],
   "source": [
    "model_path = \"D:/LTX/code_comment_inconsistency_detection/longformer-base-4096\"\n",
    "# model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=NUM_CLASSES)\n",
    "model = LongformerForSequenceClassification.from_pretrained(model_path, num_labels=NUM_CLASSES)\n",
    "\n",
    "tokenizer = LongformerTokenizer.from_pretrained(model_path, do_lower_case=False)\n",
    "\n",
    "print(sum([i.nelement() for i in model.parameters()]) / 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c78009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647f4bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b19fa11",
   "metadata": {},
   "source": [
    "处理数据  提取出 old_code_raw old_comment_raw label 三列，并且对old_code_raw的值中的\\n去掉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e93688da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全用 和 只用summary比较\n",
    "# 只用summary的效果可以拿来做对比了\n",
    "def retrieve_train_data():\n",
    "    train_param = pd.read_json(\"D:/LTX/code_comment_inconsistency_detection/data/param/train.json\")\n",
    "    train_return = pd.read_json(\"D:/LTX/code_comment_inconsistency_detection/data/return/train.json\")\n",
    "    train_summary = pd.read_json(\"D:/LTX/code_comment_inconsistency_detection/data/summary/train.json\")\n",
    "    train_df = pd.concat([train_summary,train_param, train_return], axis=0)\n",
    "    # train_df = train_df[:8397]\n",
    "    return train_df\n",
    "def retrieve_valid_data():\n",
    "    valid_param = pd.read_json(\"D:/LTX/code_comment_inconsistency_detection/data/param/valid.json\")\n",
    "    valid_return = pd.read_json(\"D:/LTX/code_comment_inconsistency_detection/data/return/valid.json\")\n",
    "    valid_summary = pd.read_json(\"D:/LTX/code_comment_inconsistency_detection/data/summary/valid.json\")\n",
    "    valid_df = pd.concat([valid_summary,valid_param, valid_return ], axis=0)\n",
    "    # valid_df = valid_df[:800]\n",
    "    return valid_df\n",
    "def retrieve_test_data():\n",
    "    test_param = pd.read_json(\"D:/LTX/code_comment_inconsistency_detection/data/param/test.json\")\n",
    "    test_return = pd.read_json(\"D:/LTX/code_comment_inconsistency_detection/data/return/test.json\")\n",
    "    test_summary = pd.read_json(\"D:/LTX/code_comment_inconsistency_detection/data/summary/test.json\")\n",
    "    test_df = pd.concat([test_summary,test_param, test_return], axis=0)\n",
    "    # test_df = test_df[:1000]\n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88eeffc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>comment_type</th>\n",
       "      <th>old_comment_raw</th>\n",
       "      <th>old_comment_subtokens</th>\n",
       "      <th>new_comment_raw</th>\n",
       "      <th>new_comment_subtokens</th>\n",
       "      <th>span_minimal_diff_comment_subtokens</th>\n",
       "      <th>old_code_raw</th>\n",
       "      <th>old_code_subtokens</th>\n",
       "      <th>new_code_raw</th>\n",
       "      <th>new_code_subtokens</th>\n",
       "      <th>span_diff_code_subtokens</th>\n",
       "      <th>token_diff_code_subtokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grails-plugins_grails-plugin-converters-5-Asso...</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Parses the given JSON and returns ether a JSON...</td>\n",
       "      <td>[parses, the, given, json, and, returns, ether...</td>\n",
       "      <td>Parses the given JSON and returns either a JSO...</td>\n",
       "      <td>[parses, the, given, json, and, returns, eithe...</td>\n",
       "      <td>[&lt;REPLACE_OLD&gt;, ether, &lt;REPLACE_NEW&gt;, either, ...</td>\n",
       "      <td>public static JSONElement parse(InputStrea...</td>\n",
       "      <td>[public, static, jsonelement, parse, (, input,...</td>\n",
       "      <td>public static JSONElement parse(InputStrea...</td>\n",
       "      <td>[public, static, jsonelement, parse, (, input,...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, jsonelement, parse, (...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;KEEP&gt;, jsone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jitsi_jitsi-4343-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Loads an image from a given image identifier.</td>\n",
       "      <td>[loads, an, image, from, a, given, image, iden...</td>\n",
       "      <td>Loads an image from a given image identifier.</td>\n",
       "      <td>[loads, an, image, from, a, given, image, iden...</td>\n",
       "      <td>[]</td>\n",
       "      <td>public static byte[] getImageInBytes(Strin...</td>\n",
       "      <td>[public, static, byte, [, ], get, image, in, b...</td>\n",
       "      <td>public static byte[] getImageInBytes(Strin...</td>\n",
       "      <td>[public, static, byte, [, ], get, image, in, b...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, byte, [, ], get, imag...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;KEEP&gt;, byte,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dropwizard_metrics-26-Associations-FirstSentence</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Creates a new  CounterMetric and registers it ...</td>\n",
       "      <td>[creates, a, new, counter, metric, and, regist...</td>\n",
       "      <td>Creates a new  com.yammer.metrics.core.Counter...</td>\n",
       "      <td>[creates, a, new, com, ., yammer, ., metrics, ...</td>\n",
       "      <td>[&lt;INSERT_OLD_KEEP_BEFORE&gt;, new, &lt;INSERT_NEW_KE...</td>\n",
       "      <td>public static CounterMetric newCounter(Cla...</td>\n",
       "      <td>[public, static, counter, metric, new, counter...</td>\n",
       "      <td>public static Counter newCounter(Class&lt;?&gt; ...</td>\n",
       "      <td>[public, static, counter, new, counter, (, cla...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, counter, &lt;KEEP_END&gt;, ...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;KEEP&gt;, count...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>google_ExoPlayer-92-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Derives a sample format corresponding to a giv...</td>\n",
       "      <td>[derives, a, sample, format, corresponding, to...</td>\n",
       "      <td>Derives a sample format corresponding to a giv...</td>\n",
       "      <td>[derives, a, sample, format, corresponding, to...</td>\n",
       "      <td>[]</td>\n",
       "      <td>private static Format getSampleFormat(Format...</td>\n",
       "      <td>[private, static, format, get, sample, format,...</td>\n",
       "      <td>private static Format getSampleFormat(Format...</td>\n",
       "      <td>[private, static, format, get, sample, format,...</td>\n",
       "      <td>[&lt;KEEP&gt;, private, static, format, get, sample,...</td>\n",
       "      <td>[&lt;KEEP&gt;, private, &lt;KEEP&gt;, static, &lt;KEEP&gt;, form...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>slachiewicz_orekit-main-661-Associations-First...</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Revert a rotation/rotation rate pair.</td>\n",
       "      <td>[revert, a, rotation, /, rotation, rate, pair, .]</td>\n",
       "      <td>Revert a rotation/rotation rate/ rotation acce...</td>\n",
       "      <td>[revert, a, rotation, /, rotation, rate, /, ro...</td>\n",
       "      <td>[&lt;REPLACE_OLD&gt;, pair, &lt;REPLACE_NEW&gt;, /, rotati...</td>\n",
       "      <td>public AngularCoordinates revert() {\\n    ...</td>\n",
       "      <td>[public, angular, coordinates, revert, (, ), {...</td>\n",
       "      <td>public AngularCoordinates revert() {\\n    ...</td>\n",
       "      <td>[public, angular, coordinates, revert, (, ), {...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, angular, coordinates, revert,...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, angular, &lt;KEEP&gt;, coor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  label comment_type  \\\n",
       "0  grails-plugins_grails-plugin-converters-5-Asso...      1      Summary   \n",
       "1                   jitsi_jitsi-4343-FirstSentence-0      0      Summary   \n",
       "2   dropwizard_metrics-26-Associations-FirstSentence      1      Summary   \n",
       "3                google_ExoPlayer-92-FirstSentence-0      0      Summary   \n",
       "4  slachiewicz_orekit-main-661-Associations-First...      1      Summary   \n",
       "\n",
       "                                     old_comment_raw  \\\n",
       "0  Parses the given JSON and returns ether a JSON...   \n",
       "1      Loads an image from a given image identifier.   \n",
       "2  Creates a new  CounterMetric and registers it ...   \n",
       "3  Derives a sample format corresponding to a giv...   \n",
       "4              Revert a rotation/rotation rate pair.   \n",
       "\n",
       "                               old_comment_subtokens  \\\n",
       "0  [parses, the, given, json, and, returns, ether...   \n",
       "1  [loads, an, image, from, a, given, image, iden...   \n",
       "2  [creates, a, new, counter, metric, and, regist...   \n",
       "3  [derives, a, sample, format, corresponding, to...   \n",
       "4  [revert, a, rotation, /, rotation, rate, pair, .]   \n",
       "\n",
       "                                     new_comment_raw  \\\n",
       "0  Parses the given JSON and returns either a JSO...   \n",
       "1      Loads an image from a given image identifier.   \n",
       "2  Creates a new  com.yammer.metrics.core.Counter...   \n",
       "3  Derives a sample format corresponding to a giv...   \n",
       "4  Revert a rotation/rotation rate/ rotation acce...   \n",
       "\n",
       "                               new_comment_subtokens  \\\n",
       "0  [parses, the, given, json, and, returns, eithe...   \n",
       "1  [loads, an, image, from, a, given, image, iden...   \n",
       "2  [creates, a, new, com, ., yammer, ., metrics, ...   \n",
       "3  [derives, a, sample, format, corresponding, to...   \n",
       "4  [revert, a, rotation, /, rotation, rate, /, ro...   \n",
       "\n",
       "                 span_minimal_diff_comment_subtokens  \\\n",
       "0  [<REPLACE_OLD>, ether, <REPLACE_NEW>, either, ...   \n",
       "1                                                 []   \n",
       "2  [<INSERT_OLD_KEEP_BEFORE>, new, <INSERT_NEW_KE...   \n",
       "3                                                 []   \n",
       "4  [<REPLACE_OLD>, pair, <REPLACE_NEW>, /, rotati...   \n",
       "\n",
       "                                        old_code_raw  \\\n",
       "0      public static JSONElement parse(InputStrea...   \n",
       "1      public static byte[] getImageInBytes(Strin...   \n",
       "2      public static CounterMetric newCounter(Cla...   \n",
       "3    private static Format getSampleFormat(Format...   \n",
       "4      public AngularCoordinates revert() {\\n    ...   \n",
       "\n",
       "                                  old_code_subtokens  \\\n",
       "0  [public, static, jsonelement, parse, (, input,...   \n",
       "1  [public, static, byte, [, ], get, image, in, b...   \n",
       "2  [public, static, counter, metric, new, counter...   \n",
       "3  [private, static, format, get, sample, format,...   \n",
       "4  [public, angular, coordinates, revert, (, ), {...   \n",
       "\n",
       "                                        new_code_raw  \\\n",
       "0      public static JSONElement parse(InputStrea...   \n",
       "1      public static byte[] getImageInBytes(Strin...   \n",
       "2      public static Counter newCounter(Class<?> ...   \n",
       "3    private static Format getSampleFormat(Format...   \n",
       "4      public AngularCoordinates revert() {\\n    ...   \n",
       "\n",
       "                                  new_code_subtokens  \\\n",
       "0  [public, static, jsonelement, parse, (, input,...   \n",
       "1  [public, static, byte, [, ], get, image, in, b...   \n",
       "2  [public, static, counter, new, counter, (, cla...   \n",
       "3  [private, static, format, get, sample, format,...   \n",
       "4  [public, angular, coordinates, revert, (, ), {...   \n",
       "\n",
       "                            span_diff_code_subtokens  \\\n",
       "0  [<KEEP>, public, static, jsonelement, parse, (...   \n",
       "1  [<KEEP>, public, static, byte, [, ], get, imag...   \n",
       "2  [<KEEP>, public, static, counter, <KEEP_END>, ...   \n",
       "3  [<KEEP>, private, static, format, get, sample,...   \n",
       "4  [<KEEP>, public, angular, coordinates, revert,...   \n",
       "\n",
       "                           token_diff_code_subtokens  \n",
       "0  [<KEEP>, public, <KEEP>, static, <KEEP>, jsone...  \n",
       "1  [<KEEP>, public, <KEEP>, static, <KEEP>, byte,...  \n",
       "2  [<KEEP>, public, <KEEP>, static, <KEEP>, count...  \n",
       "3  [<KEEP>, private, <KEEP>, static, <KEEP>, form...  \n",
       "4  [<KEEP>, public, <KEEP>, angular, <KEEP>, coor...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = retrieve_train_data()\n",
    "valid_df = retrieve_valid_data()\n",
    "test_df = retrieve_test_data()\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72db5ace",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>comment_type</th>\n",
       "      <th>old_comment_raw</th>\n",
       "      <th>old_comment_subtokens</th>\n",
       "      <th>new_comment_raw</th>\n",
       "      <th>new_comment_subtokens</th>\n",
       "      <th>span_minimal_diff_comment_subtokens</th>\n",
       "      <th>old_code_raw</th>\n",
       "      <th>old_code_subtokens</th>\n",
       "      <th>new_code_raw</th>\n",
       "      <th>new_code_subtokens</th>\n",
       "      <th>span_diff_code_subtokens</th>\n",
       "      <th>token_diff_code_subtokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>todoroo_astrid-987-FirstSentence-0</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Return SQL selector query for getting tasks wi...</td>\n",
       "      <td>[return, sql, selector, query, for, getting, t...</td>\n",
       "      <td>Return SQL selector query for getting tasks wi...</td>\n",
       "      <td>[return, sql, selector, query, for, getting, t...</td>\n",
       "      <td>[&lt;INSERT_OLD_KEEP_BEFORE&gt;, tag, &lt;INSERT_NEW_KE...</td>\n",
       "      <td>public QueryTemplate queryTemplate(Cri...</td>\n",
       "      <td>[public, query, template, query, template, (, ...</td>\n",
       "      <td>public static QueryTemplate queryTempl...</td>\n",
       "      <td>[public, static, query, template, query, templ...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP_END&gt;, &lt;INSERT&gt;, static,...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;INSERT&gt;, static, &lt;KEEP&gt;, que...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Red5_red5_server-43-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Return period of ghost connections cleanup tas...</td>\n",
       "      <td>[return, period, of, ghost, connections, clean...</td>\n",
       "      <td>Return period of ghost connections cleanup tas...</td>\n",
       "      <td>[return, period, of, ghost, connections, clean...</td>\n",
       "      <td>[]</td>\n",
       "      <td>public int getGhostConnsCleanupPeriod() {\\...</td>\n",
       "      <td>[public, int, get, ghost, conns, cleanup, peri...</td>\n",
       "      <td>public int getGhostConnsCleanupPeriod() {\\...</td>\n",
       "      <td>[public, int, get, ghost, conns, cleanup, peri...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, int, get, ghost, conns, clean...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, int, &lt;KEEP&gt;, get, &lt;KE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nickman_Rindle-11-Associations-FirstSentence</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Allocates an initialized and initially unlocke...</td>\n",
       "      <td>[allocates, an, initialized, and, initially, u...</td>\n",
       "      <td>Allocates an initialized and initially unlocke...</td>\n",
       "      <td>[allocates, an, initialized, and, initially, u...</td>\n",
       "      <td>[&lt;INSERT_OLD_KEEP_BEFORE&gt;, unlocked, &lt;INSERT_N...</td>\n",
       "      <td>\\tpublic static long allocateSpinLock() {\\r\\n\\...</td>\n",
       "      <td>[public, static, long, allocate, spin, lock, (...</td>\n",
       "      <td>\\tpublic static SpinLock allocateSpinLock() {\\...</td>\n",
       "      <td>[public, static, spin, lock, allocate, spin, l...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, &lt;KEEP_END&gt;, &lt;REPLACE_...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;REPLACE_OLD&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>h2oai_h2o_2-427-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Rebalance a frame for load balancing</td>\n",
       "      <td>[rebalance, a, frame, for, load, balancing]</td>\n",
       "      <td>Rebalance a frame for load balancing</td>\n",
       "      <td>[rebalance, a, frame, for, load, balancing]</td>\n",
       "      <td>[]</td>\n",
       "      <td>private Frame reBalance(final Frame fr, bool...</td>\n",
       "      <td>[private, frame, re, balance, (, final, frame,...</td>\n",
       "      <td>private static Frame reBalance(final Frame f...</td>\n",
       "      <td>[private, static, frame, re, balance, (, final...</td>\n",
       "      <td>[&lt;KEEP&gt;, private, &lt;KEEP_END&gt;, &lt;INSERT&gt;, static...</td>\n",
       "      <td>[&lt;KEEP&gt;, private, &lt;INSERT&gt;, static, &lt;KEEP&gt;, fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sonatype_sonatype-aether-11-Associations-First...</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Sets the host of this proxy.</td>\n",
       "      <td>[sets, the, host, of, this, proxy, .]</td>\n",
       "      <td>Sets the host of the proxy.</td>\n",
       "      <td>[sets, the, host, of, the, proxy, .]</td>\n",
       "      <td>[&lt;REPLACE_OLD&gt;, this, &lt;REPLACE_NEW&gt;, the, &lt;REP...</td>\n",
       "      <td>public Proxy setHost( String host )\\n    {...</td>\n",
       "      <td>[public, proxy, set, host, (, string, host, ),...</td>\n",
       "      <td>public Proxy setHost( String host )\\n    {...</td>\n",
       "      <td>[public, proxy, set, host, (, string, host, ),...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, proxy, set, host, (, string, ...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, proxy, &lt;KEEP&gt;, set, &lt;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  label comment_type  \\\n",
       "0                 todoroo_astrid-987-FirstSentence-0      1      Summary   \n",
       "1                Red5_red5_server-43-FirstSentence-0      0      Summary   \n",
       "2       nickman_Rindle-11-Associations-FirstSentence      1      Summary   \n",
       "3                    h2oai_h2o_2-427-FirstSentence-0      0      Summary   \n",
       "4  sonatype_sonatype-aether-11-Associations-First...      1      Summary   \n",
       "\n",
       "                                     old_comment_raw  \\\n",
       "0  Return SQL selector query for getting tasks wi...   \n",
       "1  Return period of ghost connections cleanup tas...   \n",
       "2  Allocates an initialized and initially unlocke...   \n",
       "3               Rebalance a frame for load balancing   \n",
       "4                       Sets the host of this proxy.   \n",
       "\n",
       "                               old_comment_subtokens  \\\n",
       "0  [return, sql, selector, query, for, getting, t...   \n",
       "1  [return, period, of, ghost, connections, clean...   \n",
       "2  [allocates, an, initialized, and, initially, u...   \n",
       "3        [rebalance, a, frame, for, load, balancing]   \n",
       "4              [sets, the, host, of, this, proxy, .]   \n",
       "\n",
       "                                     new_comment_raw  \\\n",
       "0  Return SQL selector query for getting tasks wi...   \n",
       "1  Return period of ghost connections cleanup tas...   \n",
       "2  Allocates an initialized and initially unlocke...   \n",
       "3               Rebalance a frame for load balancing   \n",
       "4                        Sets the host of the proxy.   \n",
       "\n",
       "                               new_comment_subtokens  \\\n",
       "0  [return, sql, selector, query, for, getting, t...   \n",
       "1  [return, period, of, ghost, connections, clean...   \n",
       "2  [allocates, an, initialized, and, initially, u...   \n",
       "3        [rebalance, a, frame, for, load, balancing]   \n",
       "4               [sets, the, host, of, the, proxy, .]   \n",
       "\n",
       "                 span_minimal_diff_comment_subtokens  \\\n",
       "0  [<INSERT_OLD_KEEP_BEFORE>, tag, <INSERT_NEW_KE...   \n",
       "1                                                 []   \n",
       "2  [<INSERT_OLD_KEEP_BEFORE>, unlocked, <INSERT_N...   \n",
       "3                                                 []   \n",
       "4  [<REPLACE_OLD>, this, <REPLACE_NEW>, the, <REP...   \n",
       "\n",
       "                                        old_code_raw  \\\n",
       "0          public QueryTemplate queryTemplate(Cri...   \n",
       "1      public int getGhostConnsCleanupPeriod() {\\...   \n",
       "2  \\tpublic static long allocateSpinLock() {\\r\\n\\...   \n",
       "3    private Frame reBalance(final Frame fr, bool...   \n",
       "4      public Proxy setHost( String host )\\n    {...   \n",
       "\n",
       "                                  old_code_subtokens  \\\n",
       "0  [public, query, template, query, template, (, ...   \n",
       "1  [public, int, get, ghost, conns, cleanup, peri...   \n",
       "2  [public, static, long, allocate, spin, lock, (...   \n",
       "3  [private, frame, re, balance, (, final, frame,...   \n",
       "4  [public, proxy, set, host, (, string, host, ),...   \n",
       "\n",
       "                                        new_code_raw  \\\n",
       "0          public static QueryTemplate queryTempl...   \n",
       "1      public int getGhostConnsCleanupPeriod() {\\...   \n",
       "2  \\tpublic static SpinLock allocateSpinLock() {\\...   \n",
       "3    private static Frame reBalance(final Frame f...   \n",
       "4      public Proxy setHost( String host )\\n    {...   \n",
       "\n",
       "                                  new_code_subtokens  \\\n",
       "0  [public, static, query, template, query, templ...   \n",
       "1  [public, int, get, ghost, conns, cleanup, peri...   \n",
       "2  [public, static, spin, lock, allocate, spin, l...   \n",
       "3  [private, static, frame, re, balance, (, final...   \n",
       "4  [public, proxy, set, host, (, string, host, ),...   \n",
       "\n",
       "                            span_diff_code_subtokens  \\\n",
       "0  [<KEEP>, public, <KEEP_END>, <INSERT>, static,...   \n",
       "1  [<KEEP>, public, int, get, ghost, conns, clean...   \n",
       "2  [<KEEP>, public, static, <KEEP_END>, <REPLACE_...   \n",
       "3  [<KEEP>, private, <KEEP_END>, <INSERT>, static...   \n",
       "4  [<KEEP>, public, proxy, set, host, (, string, ...   \n",
       "\n",
       "                           token_diff_code_subtokens  \n",
       "0  [<KEEP>, public, <INSERT>, static, <KEEP>, que...  \n",
       "1  [<KEEP>, public, <KEEP>, int, <KEEP>, get, <KE...  \n",
       "2  [<KEEP>, public, <KEEP>, static, <REPLACE_OLD>...  \n",
       "3  [<KEEP>, private, <INSERT>, static, <KEEP>, fr...  \n",
       "4  [<KEEP>, public, <KEEP>, proxy, <KEEP>, set, <...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57a62873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(df):\n",
    "    old_code_raw = df['new_code_raw']\n",
    "    old_code_raw = old_code_raw.values\n",
    "    old_code_raw = [str(ele) for ele in old_code_raw]\n",
    "       \n",
    "    multi_line_old_code = []\n",
    "    for i in range(len(old_code_raw)):\n",
    "        multi_line_test = old_code_raw[i].replace('\\n', ' ')   # 去掉\\n\n",
    "        multi_line_test = ' '.join(multi_line_test.split())    # 把多余空格变成一个空格\n",
    "        multi_line_old_code.append(multi_line_test) \n",
    "     \n",
    "    old_comment_raw = df['old_comment_raw']\n",
    "    old_comment_raw = old_comment_raw.values\n",
    "    old_comment_raw = [str(ele) for ele in old_comment_raw]\n",
    "    multi_line_old_comment = []\n",
    "    for i in range(len(old_comment_raw)):\n",
    "        multi_line_test = ' '.join(old_comment_raw[i].split())    # 把多余空格变成一个空格\n",
    "        multi_line_old_comment.append(multi_line_test)  \n",
    "    \n",
    "    df['new_code_raw'] = multi_line_old_code\n",
    "    df['old_comment_raw'] = multi_line_old_comment\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e53063b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>comment_type</th>\n",
       "      <th>old_comment_raw</th>\n",
       "      <th>old_comment_subtokens</th>\n",
       "      <th>new_comment_raw</th>\n",
       "      <th>new_comment_subtokens</th>\n",
       "      <th>span_minimal_diff_comment_subtokens</th>\n",
       "      <th>old_code_raw</th>\n",
       "      <th>old_code_subtokens</th>\n",
       "      <th>new_code_raw</th>\n",
       "      <th>new_code_subtokens</th>\n",
       "      <th>span_diff_code_subtokens</th>\n",
       "      <th>token_diff_code_subtokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grails-plugins_grails-plugin-converters-5-Asso...</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Parses the given JSON and returns ether a JSON...</td>\n",
       "      <td>[parses, the, given, json, and, returns, ether...</td>\n",
       "      <td>Parses the given JSON and returns either a JSO...</td>\n",
       "      <td>[parses, the, given, json, and, returns, eithe...</td>\n",
       "      <td>[&lt;REPLACE_OLD&gt;, ether, &lt;REPLACE_NEW&gt;, either, ...</td>\n",
       "      <td>public static JSONElement parse(InputStrea...</td>\n",
       "      <td>[public, static, jsonelement, parse, (, input,...</td>\n",
       "      <td>public static JSONElement parse(InputStream is...</td>\n",
       "      <td>[public, static, jsonelement, parse, (, input,...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, jsonelement, parse, (...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;KEEP&gt;, jsone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jitsi_jitsi-4343-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Loads an image from a given image identifier.</td>\n",
       "      <td>[loads, an, image, from, a, given, image, iden...</td>\n",
       "      <td>Loads an image from a given image identifier.</td>\n",
       "      <td>[loads, an, image, from, a, given, image, iden...</td>\n",
       "      <td>[]</td>\n",
       "      <td>public static byte[] getImageInBytes(Strin...</td>\n",
       "      <td>[public, static, byte, [, ], get, image, in, b...</td>\n",
       "      <td>public static byte[] getImageInBytes(String im...</td>\n",
       "      <td>[public, static, byte, [, ], get, image, in, b...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, byte, [, ], get, imag...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;KEEP&gt;, byte,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dropwizard_metrics-26-Associations-FirstSentence</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Creates a new CounterMetric and registers it u...</td>\n",
       "      <td>[creates, a, new, counter, metric, and, regist...</td>\n",
       "      <td>Creates a new  com.yammer.metrics.core.Counter...</td>\n",
       "      <td>[creates, a, new, com, ., yammer, ., metrics, ...</td>\n",
       "      <td>[&lt;INSERT_OLD_KEEP_BEFORE&gt;, new, &lt;INSERT_NEW_KE...</td>\n",
       "      <td>public static CounterMetric newCounter(Cla...</td>\n",
       "      <td>[public, static, counter, metric, new, counter...</td>\n",
       "      <td>public static Counter newCounter(Class&lt;?&gt; klas...</td>\n",
       "      <td>[public, static, counter, new, counter, (, cla...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, counter, &lt;KEEP_END&gt;, ...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;KEEP&gt;, count...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>google_ExoPlayer-92-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Derives a sample format corresponding to a giv...</td>\n",
       "      <td>[derives, a, sample, format, corresponding, to...</td>\n",
       "      <td>Derives a sample format corresponding to a giv...</td>\n",
       "      <td>[derives, a, sample, format, corresponding, to...</td>\n",
       "      <td>[]</td>\n",
       "      <td>private static Format getSampleFormat(Format...</td>\n",
       "      <td>[private, static, format, get, sample, format,...</td>\n",
       "      <td>private static Format getSampleFormat(Format c...</td>\n",
       "      <td>[private, static, format, get, sample, format,...</td>\n",
       "      <td>[&lt;KEEP&gt;, private, static, format, get, sample,...</td>\n",
       "      <td>[&lt;KEEP&gt;, private, &lt;KEEP&gt;, static, &lt;KEEP&gt;, form...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>slachiewicz_orekit-main-661-Associations-First...</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Revert a rotation/rotation rate pair.</td>\n",
       "      <td>[revert, a, rotation, /, rotation, rate, pair, .]</td>\n",
       "      <td>Revert a rotation/rotation rate/ rotation acce...</td>\n",
       "      <td>[revert, a, rotation, /, rotation, rate, /, ro...</td>\n",
       "      <td>[&lt;REPLACE_OLD&gt;, pair, &lt;REPLACE_NEW&gt;, /, rotati...</td>\n",
       "      <td>public AngularCoordinates revert() {\\n    ...</td>\n",
       "      <td>[public, angular, coordinates, revert, (, ), {...</td>\n",
       "      <td>public AngularCoordinates revert() { return ne...</td>\n",
       "      <td>[public, angular, coordinates, revert, (, ), {...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, angular, coordinates, revert,...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, angular, &lt;KEEP&gt;, coor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  label comment_type  \\\n",
       "0  grails-plugins_grails-plugin-converters-5-Asso...      1      Summary   \n",
       "1                   jitsi_jitsi-4343-FirstSentence-0      0      Summary   \n",
       "2   dropwizard_metrics-26-Associations-FirstSentence      1      Summary   \n",
       "3                google_ExoPlayer-92-FirstSentence-0      0      Summary   \n",
       "4  slachiewicz_orekit-main-661-Associations-First...      1      Summary   \n",
       "\n",
       "                                     old_comment_raw  \\\n",
       "0  Parses the given JSON and returns ether a JSON...   \n",
       "1      Loads an image from a given image identifier.   \n",
       "2  Creates a new CounterMetric and registers it u...   \n",
       "3  Derives a sample format corresponding to a giv...   \n",
       "4              Revert a rotation/rotation rate pair.   \n",
       "\n",
       "                               old_comment_subtokens  \\\n",
       "0  [parses, the, given, json, and, returns, ether...   \n",
       "1  [loads, an, image, from, a, given, image, iden...   \n",
       "2  [creates, a, new, counter, metric, and, regist...   \n",
       "3  [derives, a, sample, format, corresponding, to...   \n",
       "4  [revert, a, rotation, /, rotation, rate, pair, .]   \n",
       "\n",
       "                                     new_comment_raw  \\\n",
       "0  Parses the given JSON and returns either a JSO...   \n",
       "1      Loads an image from a given image identifier.   \n",
       "2  Creates a new  com.yammer.metrics.core.Counter...   \n",
       "3  Derives a sample format corresponding to a giv...   \n",
       "4  Revert a rotation/rotation rate/ rotation acce...   \n",
       "\n",
       "                               new_comment_subtokens  \\\n",
       "0  [parses, the, given, json, and, returns, eithe...   \n",
       "1  [loads, an, image, from, a, given, image, iden...   \n",
       "2  [creates, a, new, com, ., yammer, ., metrics, ...   \n",
       "3  [derives, a, sample, format, corresponding, to...   \n",
       "4  [revert, a, rotation, /, rotation, rate, /, ro...   \n",
       "\n",
       "                 span_minimal_diff_comment_subtokens  \\\n",
       "0  [<REPLACE_OLD>, ether, <REPLACE_NEW>, either, ...   \n",
       "1                                                 []   \n",
       "2  [<INSERT_OLD_KEEP_BEFORE>, new, <INSERT_NEW_KE...   \n",
       "3                                                 []   \n",
       "4  [<REPLACE_OLD>, pair, <REPLACE_NEW>, /, rotati...   \n",
       "\n",
       "                                        old_code_raw  \\\n",
       "0      public static JSONElement parse(InputStrea...   \n",
       "1      public static byte[] getImageInBytes(Strin...   \n",
       "2      public static CounterMetric newCounter(Cla...   \n",
       "3    private static Format getSampleFormat(Format...   \n",
       "4      public AngularCoordinates revert() {\\n    ...   \n",
       "\n",
       "                                  old_code_subtokens  \\\n",
       "0  [public, static, jsonelement, parse, (, input,...   \n",
       "1  [public, static, byte, [, ], get, image, in, b...   \n",
       "2  [public, static, counter, metric, new, counter...   \n",
       "3  [private, static, format, get, sample, format,...   \n",
       "4  [public, angular, coordinates, revert, (, ), {...   \n",
       "\n",
       "                                        new_code_raw  \\\n",
       "0  public static JSONElement parse(InputStream is...   \n",
       "1  public static byte[] getImageInBytes(String im...   \n",
       "2  public static Counter newCounter(Class<?> klas...   \n",
       "3  private static Format getSampleFormat(Format c...   \n",
       "4  public AngularCoordinates revert() { return ne...   \n",
       "\n",
       "                                  new_code_subtokens  \\\n",
       "0  [public, static, jsonelement, parse, (, input,...   \n",
       "1  [public, static, byte, [, ], get, image, in, b...   \n",
       "2  [public, static, counter, new, counter, (, cla...   \n",
       "3  [private, static, format, get, sample, format,...   \n",
       "4  [public, angular, coordinates, revert, (, ), {...   \n",
       "\n",
       "                            span_diff_code_subtokens  \\\n",
       "0  [<KEEP>, public, static, jsonelement, parse, (...   \n",
       "1  [<KEEP>, public, static, byte, [, ], get, imag...   \n",
       "2  [<KEEP>, public, static, counter, <KEEP_END>, ...   \n",
       "3  [<KEEP>, private, static, format, get, sample,...   \n",
       "4  [<KEEP>, public, angular, coordinates, revert,...   \n",
       "\n",
       "                           token_diff_code_subtokens  \n",
       "0  [<KEEP>, public, <KEEP>, static, <KEEP>, jsone...  \n",
       "1  [<KEEP>, public, <KEEP>, static, <KEEP>, byte,...  \n",
       "2  [<KEEP>, public, <KEEP>, static, <KEEP>, count...  \n",
       "3  [<KEEP>, private, <KEEP>, static, <KEEP>, form...  \n",
       "4  [<KEEP>, public, <KEEP>, angular, <KEEP>, coor...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_clean = format_data(train_df)\n",
    "train_df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3742e39e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>comment_type</th>\n",
       "      <th>old_comment_raw</th>\n",
       "      <th>old_comment_subtokens</th>\n",
       "      <th>new_comment_raw</th>\n",
       "      <th>new_comment_subtokens</th>\n",
       "      <th>span_minimal_diff_comment_subtokens</th>\n",
       "      <th>old_code_raw</th>\n",
       "      <th>old_code_subtokens</th>\n",
       "      <th>new_code_raw</th>\n",
       "      <th>new_code_subtokens</th>\n",
       "      <th>span_diff_code_subtokens</th>\n",
       "      <th>token_diff_code_subtokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>todoroo_astrid-987-FirstSentence-0</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Return SQL selector query for getting tasks wi...</td>\n",
       "      <td>[return, sql, selector, query, for, getting, t...</td>\n",
       "      <td>Return SQL selector query for getting tasks wi...</td>\n",
       "      <td>[return, sql, selector, query, for, getting, t...</td>\n",
       "      <td>[&lt;INSERT_OLD_KEEP_BEFORE&gt;, tag, &lt;INSERT_NEW_KE...</td>\n",
       "      <td>public QueryTemplate queryTemplate(Cri...</td>\n",
       "      <td>[public, query, template, query, template, (, ...</td>\n",
       "      <td>public static QueryTemplate queryTemplate(Crit...</td>\n",
       "      <td>[public, static, query, template, query, templ...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP_END&gt;, &lt;INSERT&gt;, static,...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;INSERT&gt;, static, &lt;KEEP&gt;, que...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Red5_red5_server-43-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Return period of ghost connections cleanup tas...</td>\n",
       "      <td>[return, period, of, ghost, connections, clean...</td>\n",
       "      <td>Return period of ghost connections cleanup tas...</td>\n",
       "      <td>[return, period, of, ghost, connections, clean...</td>\n",
       "      <td>[]</td>\n",
       "      <td>public int getGhostConnsCleanupPeriod() {\\...</td>\n",
       "      <td>[public, int, get, ghost, conns, cleanup, peri...</td>\n",
       "      <td>public int getGhostConnsCleanupPeriod() { retu...</td>\n",
       "      <td>[public, int, get, ghost, conns, cleanup, peri...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, int, get, ghost, conns, clean...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, int, &lt;KEEP&gt;, get, &lt;KE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nickman_Rindle-11-Associations-FirstSentence</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Allocates an initialized and initially unlocke...</td>\n",
       "      <td>[allocates, an, initialized, and, initially, u...</td>\n",
       "      <td>Allocates an initialized and initially unlocke...</td>\n",
       "      <td>[allocates, an, initialized, and, initially, u...</td>\n",
       "      <td>[&lt;INSERT_OLD_KEEP_BEFORE&gt;, unlocked, &lt;INSERT_N...</td>\n",
       "      <td>\\tpublic static long allocateSpinLock() {\\r\\n\\...</td>\n",
       "      <td>[public, static, long, allocate, spin, lock, (...</td>\n",
       "      <td>public static SpinLock allocateSpinLock() { lo...</td>\n",
       "      <td>[public, static, spin, lock, allocate, spin, l...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, &lt;KEEP_END&gt;, &lt;REPLACE_...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;REPLACE_OLD&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>h2oai_h2o_2-427-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Rebalance a frame for load balancing</td>\n",
       "      <td>[rebalance, a, frame, for, load, balancing]</td>\n",
       "      <td>Rebalance a frame for load balancing</td>\n",
       "      <td>[rebalance, a, frame, for, load, balancing]</td>\n",
       "      <td>[]</td>\n",
       "      <td>private Frame reBalance(final Frame fr, bool...</td>\n",
       "      <td>[private, frame, re, balance, (, final, frame,...</td>\n",
       "      <td>private static Frame reBalance(final Frame fr,...</td>\n",
       "      <td>[private, static, frame, re, balance, (, final...</td>\n",
       "      <td>[&lt;KEEP&gt;, private, &lt;KEEP_END&gt;, &lt;INSERT&gt;, static...</td>\n",
       "      <td>[&lt;KEEP&gt;, private, &lt;INSERT&gt;, static, &lt;KEEP&gt;, fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sonatype_sonatype-aether-11-Associations-First...</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Sets the host of this proxy.</td>\n",
       "      <td>[sets, the, host, of, this, proxy, .]</td>\n",
       "      <td>Sets the host of the proxy.</td>\n",
       "      <td>[sets, the, host, of, the, proxy, .]</td>\n",
       "      <td>[&lt;REPLACE_OLD&gt;, this, &lt;REPLACE_NEW&gt;, the, &lt;REP...</td>\n",
       "      <td>public Proxy setHost( String host )\\n    {...</td>\n",
       "      <td>[public, proxy, set, host, (, string, host, ),...</td>\n",
       "      <td>public Proxy setHost( String host ) { return n...</td>\n",
       "      <td>[public, proxy, set, host, (, string, host, ),...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, proxy, set, host, (, string, ...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, proxy, &lt;KEEP&gt;, set, &lt;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  label comment_type  \\\n",
       "0                 todoroo_astrid-987-FirstSentence-0      1      Summary   \n",
       "1                Red5_red5_server-43-FirstSentence-0      0      Summary   \n",
       "2       nickman_Rindle-11-Associations-FirstSentence      1      Summary   \n",
       "3                    h2oai_h2o_2-427-FirstSentence-0      0      Summary   \n",
       "4  sonatype_sonatype-aether-11-Associations-First...      1      Summary   \n",
       "\n",
       "                                     old_comment_raw  \\\n",
       "0  Return SQL selector query for getting tasks wi...   \n",
       "1  Return period of ghost connections cleanup tas...   \n",
       "2  Allocates an initialized and initially unlocke...   \n",
       "3               Rebalance a frame for load balancing   \n",
       "4                       Sets the host of this proxy.   \n",
       "\n",
       "                               old_comment_subtokens  \\\n",
       "0  [return, sql, selector, query, for, getting, t...   \n",
       "1  [return, period, of, ghost, connections, clean...   \n",
       "2  [allocates, an, initialized, and, initially, u...   \n",
       "3        [rebalance, a, frame, for, load, balancing]   \n",
       "4              [sets, the, host, of, this, proxy, .]   \n",
       "\n",
       "                                     new_comment_raw  \\\n",
       "0  Return SQL selector query for getting tasks wi...   \n",
       "1  Return period of ghost connections cleanup tas...   \n",
       "2  Allocates an initialized and initially unlocke...   \n",
       "3               Rebalance a frame for load balancing   \n",
       "4                        Sets the host of the proxy.   \n",
       "\n",
       "                               new_comment_subtokens  \\\n",
       "0  [return, sql, selector, query, for, getting, t...   \n",
       "1  [return, period, of, ghost, connections, clean...   \n",
       "2  [allocates, an, initialized, and, initially, u...   \n",
       "3        [rebalance, a, frame, for, load, balancing]   \n",
       "4               [sets, the, host, of, the, proxy, .]   \n",
       "\n",
       "                 span_minimal_diff_comment_subtokens  \\\n",
       "0  [<INSERT_OLD_KEEP_BEFORE>, tag, <INSERT_NEW_KE...   \n",
       "1                                                 []   \n",
       "2  [<INSERT_OLD_KEEP_BEFORE>, unlocked, <INSERT_N...   \n",
       "3                                                 []   \n",
       "4  [<REPLACE_OLD>, this, <REPLACE_NEW>, the, <REP...   \n",
       "\n",
       "                                        old_code_raw  \\\n",
       "0          public QueryTemplate queryTemplate(Cri...   \n",
       "1      public int getGhostConnsCleanupPeriod() {\\...   \n",
       "2  \\tpublic static long allocateSpinLock() {\\r\\n\\...   \n",
       "3    private Frame reBalance(final Frame fr, bool...   \n",
       "4      public Proxy setHost( String host )\\n    {...   \n",
       "\n",
       "                                  old_code_subtokens  \\\n",
       "0  [public, query, template, query, template, (, ...   \n",
       "1  [public, int, get, ghost, conns, cleanup, peri...   \n",
       "2  [public, static, long, allocate, spin, lock, (...   \n",
       "3  [private, frame, re, balance, (, final, frame,...   \n",
       "4  [public, proxy, set, host, (, string, host, ),...   \n",
       "\n",
       "                                        new_code_raw  \\\n",
       "0  public static QueryTemplate queryTemplate(Crit...   \n",
       "1  public int getGhostConnsCleanupPeriod() { retu...   \n",
       "2  public static SpinLock allocateSpinLock() { lo...   \n",
       "3  private static Frame reBalance(final Frame fr,...   \n",
       "4  public Proxy setHost( String host ) { return n...   \n",
       "\n",
       "                                  new_code_subtokens  \\\n",
       "0  [public, static, query, template, query, templ...   \n",
       "1  [public, int, get, ghost, conns, cleanup, peri...   \n",
       "2  [public, static, spin, lock, allocate, spin, l...   \n",
       "3  [private, static, frame, re, balance, (, final...   \n",
       "4  [public, proxy, set, host, (, string, host, ),...   \n",
       "\n",
       "                            span_diff_code_subtokens  \\\n",
       "0  [<KEEP>, public, <KEEP_END>, <INSERT>, static,...   \n",
       "1  [<KEEP>, public, int, get, ghost, conns, clean...   \n",
       "2  [<KEEP>, public, static, <KEEP_END>, <REPLACE_...   \n",
       "3  [<KEEP>, private, <KEEP_END>, <INSERT>, static...   \n",
       "4  [<KEEP>, public, proxy, set, host, (, string, ...   \n",
       "\n",
       "                           token_diff_code_subtokens  \n",
       "0  [<KEEP>, public, <INSERT>, static, <KEEP>, que...  \n",
       "1  [<KEEP>, public, <KEEP>, int, <KEEP>, get, <KE...  \n",
       "2  [<KEEP>, public, <KEEP>, static, <REPLACE_OLD>...  \n",
       "3  [<KEEP>, private, <INSERT>, static, <KEEP>, fr...  \n",
       "4  [<KEEP>, public, <KEEP>, proxy, <KEEP>, set, <...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df_clean = format_data(valid_df)\n",
    "valid_df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccbbab85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>comment_type</th>\n",
       "      <th>old_comment_raw</th>\n",
       "      <th>old_comment_subtokens</th>\n",
       "      <th>new_comment_raw</th>\n",
       "      <th>new_comment_subtokens</th>\n",
       "      <th>span_minimal_diff_comment_subtokens</th>\n",
       "      <th>old_code_raw</th>\n",
       "      <th>old_code_subtokens</th>\n",
       "      <th>new_code_raw</th>\n",
       "      <th>new_code_subtokens</th>\n",
       "      <th>span_diff_code_subtokens</th>\n",
       "      <th>token_diff_code_subtokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apache_calcite-896-FirstSentence-0</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Creates elastic node as single member of a clu...</td>\n",
       "      <td>[creates, elastic, node, as, single, member, o...</td>\n",
       "      <td>Creates an instance with existing settings</td>\n",
       "      <td>[creates, an, instance, with, existing, settings]</td>\n",
       "      <td>[&lt;REPLACE_OLD&gt;, elastic, node, as, single, mem...</td>\n",
       "      <td>public static EmbeddedElasticsearchNode crea...</td>\n",
       "      <td>[public, static, embedded, elasticsearch, node...</td>\n",
       "      <td>private static EmbeddedElasticsearchNode creat...</td>\n",
       "      <td>[private, static, embedded, elasticsearch, nod...</td>\n",
       "      <td>[&lt;REPLACE_OLD&gt;, public, &lt;REPLACE_NEW&gt;, private...</td>\n",
       "      <td>[&lt;REPLACE_OLD&gt;, public, &lt;REPLACE_NEW&gt;, private...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hibernate_hibernate_orm-1601-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Check whether any insertion or deletion action...</td>\n",
       "      <td>[check, whether, any, insertion, or, deletion,...</td>\n",
       "      <td>Check whether any insertion or deletion action...</td>\n",
       "      <td>[check, whether, any, insertion, or, deletion,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>\\tpublic boolean areInsertionsOrDeletionsQueue...</td>\n",
       "      <td>[public, boolean, are, insertions, or, deletio...</td>\n",
       "      <td>public boolean areInsertionsOrDeletionsQueued(...</td>\n",
       "      <td>[public, boolean, are, insertions, or, deletio...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, boolean, are, insertions, or,...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, boolean, &lt;KEEP&gt;, are,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apache_giraph-33-Associations-FirstSentence</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Marshal the aggregator values of to a JSONArra...</td>\n",
       "      <td>[marshal, the, aggregator, values, of, to, a, ...</td>\n",
       "      <td>Marshal the aggregator values of the worker to...</td>\n",
       "      <td>[marshal, the, aggregator, values, of, the, wo...</td>\n",
       "      <td>[&lt;INSERT_OLD_KEEP_BEFORE&gt;, of, &lt;INSERT_NEW_KEE...</td>\n",
       "      <td>private JSONArray marshalAggregatorValues(lo...</td>\n",
       "      <td>[private, jsonarray, marshal, aggregator, valu...</td>\n",
       "      <td>private byte[] marshalAggregatorValues(long su...</td>\n",
       "      <td>[private, byte, [, ], marshal, aggregator, val...</td>\n",
       "      <td>[&lt;KEEP&gt;, private, &lt;KEEP_END&gt;, &lt;REPLACE_OLD&gt;, j...</td>\n",
       "      <td>[&lt;KEEP&gt;, private, &lt;REPLACE_OLD&gt;, jsonarray, &lt;R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apache_calcite-677-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Returns a list of the types of the fields in a...</td>\n",
       "      <td>[returns, a, list, of, the, types, of, the, fi...</td>\n",
       "      <td>Returns a list of the types of the fields in a...</td>\n",
       "      <td>[returns, a, list, of, the, types, of, the, fi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>public static List&lt;RelDataType&gt; getFieldType...</td>\n",
       "      <td>[public, static, list, &lt;, rel, data, type, &gt;, ...</td>\n",
       "      <td>public static List&lt;RelDataType&gt; getFieldTypeLi...</td>\n",
       "      <td>[public, static, list, &lt;, rel, data, type, &gt;, ...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, list, &lt;, rel, data, t...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;KEEP&gt;, list,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apache_calcite-315-Associations-FirstSentence</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Create an instance based on current maven prof...</td>\n",
       "      <td>[create, an, instance, based, on, current, mav...</td>\n",
       "      <td>Creates an instance based on current maven pro...</td>\n",
       "      <td>[creates, an, instance, based, on, current, ma...</td>\n",
       "      <td>[&lt;REPLACE_OLD&gt;, create, &lt;REPLACE_NEW&gt;, creates...</td>\n",
       "      <td>static MongoDatabaseRule create() {\\n    fin...</td>\n",
       "      <td>[static, mongo, database, rule, create, (, ), ...</td>\n",
       "      <td>static MongoDatabasePolicy create() { final Mo...</td>\n",
       "      <td>[static, mongo, database, policy, create, (, )...</td>\n",
       "      <td>[&lt;KEEP&gt;, static, mongo, database, &lt;KEEP_END&gt;, ...</td>\n",
       "      <td>[&lt;KEEP&gt;, static, &lt;KEEP&gt;, mongo, &lt;KEEP&gt;, databa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              id  label comment_type  \\\n",
       "0             apache_calcite-896-FirstSentence-0      1      Summary   \n",
       "1   hibernate_hibernate_orm-1601-FirstSentence-0      0      Summary   \n",
       "2    apache_giraph-33-Associations-FirstSentence      1      Summary   \n",
       "3             apache_calcite-677-FirstSentence-0      0      Summary   \n",
       "4  apache_calcite-315-Associations-FirstSentence      1      Summary   \n",
       "\n",
       "                                     old_comment_raw  \\\n",
       "0  Creates elastic node as single member of a clu...   \n",
       "1  Check whether any insertion or deletion action...   \n",
       "2  Marshal the aggregator values of to a JSONArra...   \n",
       "3  Returns a list of the types of the fields in a...   \n",
       "4  Create an instance based on current maven prof...   \n",
       "\n",
       "                               old_comment_subtokens  \\\n",
       "0  [creates, elastic, node, as, single, member, o...   \n",
       "1  [check, whether, any, insertion, or, deletion,...   \n",
       "2  [marshal, the, aggregator, values, of, to, a, ...   \n",
       "3  [returns, a, list, of, the, types, of, the, fi...   \n",
       "4  [create, an, instance, based, on, current, mav...   \n",
       "\n",
       "                                     new_comment_raw  \\\n",
       "0         Creates an instance with existing settings   \n",
       "1  Check whether any insertion or deletion action...   \n",
       "2  Marshal the aggregator values of the worker to...   \n",
       "3  Returns a list of the types of the fields in a...   \n",
       "4  Creates an instance based on current maven pro...   \n",
       "\n",
       "                               new_comment_subtokens  \\\n",
       "0  [creates, an, instance, with, existing, settings]   \n",
       "1  [check, whether, any, insertion, or, deletion,...   \n",
       "2  [marshal, the, aggregator, values, of, the, wo...   \n",
       "3  [returns, a, list, of, the, types, of, the, fi...   \n",
       "4  [creates, an, instance, based, on, current, ma...   \n",
       "\n",
       "                 span_minimal_diff_comment_subtokens  \\\n",
       "0  [<REPLACE_OLD>, elastic, node, as, single, mem...   \n",
       "1                                                 []   \n",
       "2  [<INSERT_OLD_KEEP_BEFORE>, of, <INSERT_NEW_KEE...   \n",
       "3                                                 []   \n",
       "4  [<REPLACE_OLD>, create, <REPLACE_NEW>, creates...   \n",
       "\n",
       "                                        old_code_raw  \\\n",
       "0    public static EmbeddedElasticsearchNode crea...   \n",
       "1  \\tpublic boolean areInsertionsOrDeletionsQueue...   \n",
       "2    private JSONArray marshalAggregatorValues(lo...   \n",
       "3    public static List<RelDataType> getFieldType...   \n",
       "4    static MongoDatabaseRule create() {\\n    fin...   \n",
       "\n",
       "                                  old_code_subtokens  \\\n",
       "0  [public, static, embedded, elasticsearch, node...   \n",
       "1  [public, boolean, are, insertions, or, deletio...   \n",
       "2  [private, jsonarray, marshal, aggregator, valu...   \n",
       "3  [public, static, list, <, rel, data, type, >, ...   \n",
       "4  [static, mongo, database, rule, create, (, ), ...   \n",
       "\n",
       "                                        new_code_raw  \\\n",
       "0  private static EmbeddedElasticsearchNode creat...   \n",
       "1  public boolean areInsertionsOrDeletionsQueued(...   \n",
       "2  private byte[] marshalAggregatorValues(long su...   \n",
       "3  public static List<RelDataType> getFieldTypeLi...   \n",
       "4  static MongoDatabasePolicy create() { final Mo...   \n",
       "\n",
       "                                  new_code_subtokens  \\\n",
       "0  [private, static, embedded, elasticsearch, nod...   \n",
       "1  [public, boolean, are, insertions, or, deletio...   \n",
       "2  [private, byte, [, ], marshal, aggregator, val...   \n",
       "3  [public, static, list, <, rel, data, type, >, ...   \n",
       "4  [static, mongo, database, policy, create, (, )...   \n",
       "\n",
       "                            span_diff_code_subtokens  \\\n",
       "0  [<REPLACE_OLD>, public, <REPLACE_NEW>, private...   \n",
       "1  [<KEEP>, public, boolean, are, insertions, or,...   \n",
       "2  [<KEEP>, private, <KEEP_END>, <REPLACE_OLD>, j...   \n",
       "3  [<KEEP>, public, static, list, <, rel, data, t...   \n",
       "4  [<KEEP>, static, mongo, database, <KEEP_END>, ...   \n",
       "\n",
       "                           token_diff_code_subtokens  \n",
       "0  [<REPLACE_OLD>, public, <REPLACE_NEW>, private...  \n",
       "1  [<KEEP>, public, <KEEP>, boolean, <KEEP>, are,...  \n",
       "2  [<KEEP>, private, <REPLACE_OLD>, jsonarray, <R...  \n",
       "3  [<KEEP>, public, <KEEP>, static, <KEEP>, list,...  \n",
       "4  [<KEEP>, static, <KEEP>, mongo, <KEEP>, databa...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_clean = format_data(test_df)\n",
    "test_df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487b7a39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18f7f7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CocoDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        model_path = \"D:/LTX/code_comment_inconsistency_detection/longformer-base-4096\"\n",
    "        self.tokenizer = LongformerTokenizer.from_pretrained(model_path, do_lower_case=False)        \n",
    "        self.data = self.load_data(self.df)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "    def load_data(self, df):\n",
    "        token_ids = []\n",
    "        mask_ids = []\n",
    "        seg_ids = []\n",
    "        labels = []\n",
    "        \n",
    "        code_list = df['new_code_raw'].to_list() \n",
    "        comment_list = df['old_comment_raw'].to_list()\n",
    "        label_list = df['label'].to_list()\n",
    "\n",
    "        for (code, comment, label) in zip(code_list, comment_list, label_list):\n",
    "            code_id = self.tokenizer.encode(code, add_special_tokens=False, truncation=True, max_length=256)\n",
    "            comment_id = self.tokenizer.encode(comment, add_special_tokens=False, truncation=True, max_length=256)\n",
    "\n",
    "            # want [CLS] comment tokens [SEP] code tokens [SEP]\n",
    "            pair_token_ids = [self.tokenizer.cls_token_id] + comment_id + [self.tokenizer.sep_token_id] + code_id + [self.tokenizer.sep_token_id]\n",
    "            pair_token_ids = self.truncate(pair_token_ids)\n",
    "            code_len = len(code_id)\n",
    "            comment_len = len(comment_id)\n",
    "            \n",
    "            attention_mask_ids = torch.tensor([1] * (code_len + comment_len + 3)) # mask padded values\n",
    "            segment_ids = torch.tensor([0] * (comment_len + 2) + [1] * (code_len + 1)) # sentence 0 (comment) and sentence 1 (code)\n",
    "            \n",
    "            attention_mask_ids = self.truncate(attention_mask_ids)\n",
    "            segment_ids = self.truncate(segment_ids)\n",
    "            \n",
    "            token_ids.append(torch.tensor(pair_token_ids))\n",
    "            mask_ids.append(attention_mask_ids)\n",
    "            seg_ids.append(segment_ids)\n",
    "            labels.append(label)\n",
    "            \n",
    "        token_ids = pad_sequence(token_ids, batch_first=True)\n",
    "        mask_ids = pad_sequence(mask_ids, batch_first=True)\n",
    "        seg_ids = pad_sequence(seg_ids, batch_first=True)\n",
    "        labels = torch.tensor(labels)\n",
    "        \n",
    "        dataset = TensorDataset(token_ids, mask_ids, seg_ids, labels)\n",
    "        return dataset\n",
    "\n",
    "    def truncate(self, ids):\n",
    "        return ids[:MAX_LEN] if len(ids) > 512 else ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ad75ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<__main__.CocoDataset at 0x268fe54a830>,\n",
       " <__main__.CocoDataset at 0x268c48518d0>,\n",
       " <__main__.CocoDataset at 0x268c48501f0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = CocoDataset(train_df_clean)\n",
    "valid_data = CocoDataset(valid_df_clean)\n",
    "test_data = CocoDataset(test_df_clean)\n",
    "\n",
    "train_data,valid_data,test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5715642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb02e093",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c751555f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "def compute_metrics(predicted_labels, gold_labels):\n",
    "    predicted_labels = [label.item() for label in predicted_labels]\n",
    "    gold_labels = [label.item() for label in gold_labels]\n",
    "\n",
    "    assert len(predicted_labels) == len(gold_labels)\n",
    "\n",
    "    precision = precision_score(gold_labels, predicted_labels, zero_division=0)\n",
    "    recall = recall_score(gold_labels, predicted_labels, zero_division=0)\n",
    "    f1 = f1_score(gold_labels, predicted_labels, zero_division=0)\n",
    "    accuracy = accuracy_score(gold_labels, predicted_labels) \n",
    "\n",
    "    return precision, recall, f1, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3dc2a01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_data_t):\n",
    "    \n",
    "    test_data = CocoDataset(test_data_t)\n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE)\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    predictions = []\n",
    "    gold_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (sequence, attention_masks, token_type_ids, labels) in enumerate(test_loader):\n",
    "            sequence = sequence.to(device)\n",
    "            attention_masks = attention_masks.to(device)\n",
    "            token_type_ids = token_type_ids.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(sequence, attention_mask=attention_masks, token_type_ids=token_type_ids, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            prediction = outputs.logits\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            prediction = torch.argmax(prediction, dim=-1)\n",
    "\n",
    "            predictions.extend(prediction)\n",
    "            gold_labels.extend(labels)\n",
    "        \n",
    "    test_loss = test_loss / len(test_loader)\n",
    "    test_precision, test_recall, test_f1, test_acc = compute_metrics(predictions, gold_labels)\n",
    "\n",
    "    print(f\"test_loss: {test_loss:.3f} test_precision: {test_precision:.3f} test_recall: {test_recall:.3f} test_f1: {test_f1:.3f} test_acc: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c4eb878",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.utils.notebook import format_time\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from tqdm import tqdm\n",
    "def train(model,train_data_,valid_data_,patience=10):\n",
    "\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_data_, batch_size=BATCH_SIZE)\n",
    "    valid_loader = DataLoader(dataset=valid_data_, batch_size=BATCH_SIZE)\n",
    "\n",
    "    best_f1 = 0.0\n",
    "    epochs_without_improvement = 0\n",
    "    \n",
    "    total_steps = len(train_loader) * MAX_EPOCHS\n",
    "    print(\"   Train batch size = {}\".format(BATCH_SIZE))\n",
    "    print(\"   Total steps = {}\".format(total_steps))\n",
    "    print(f\"   Training Start!\")\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    times = 0\n",
    "    for epoch in range(MAX_EPOCHS):\n",
    "        # 每个周期输出一个txt，检查valid的预测数据\n",
    "        times = times+1\n",
    "        start = time.time()\n",
    "        model.to(device)\n",
    "        model.train()\n",
    "    \n",
    "        # string_colmn_name = \"input_data    label    prediction_label\"\n",
    "        # file_name = 'check_newdata_bert_valid_dataset_epoch_{}'\n",
    "        # with open(file_name.format(times)+'.txt', 'w') as f:\n",
    "        #     f.write(string_colmn_name)\n",
    "            \n",
    "        train_loss = 0.0\n",
    "        predictions = []\n",
    "        gold_labels = []\n",
    "        for batch_idx, (sequence, attention_masks, token_type_ids, labels) in enumerate(tqdm(train_loader, desc=\"Training\", leave=True)):\n",
    "            sequence = sequence.to(device)\n",
    "            attention_masks = attention_masks.to(device)\n",
    "            token_type_ids = token_type_ids.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(sequence, attention_mask=attention_masks,labels=labels)\n",
    "            loss = outputs.loss\n",
    "            prediction = outputs.logits\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            prediction = torch.argmax(prediction, dim=-1)\n",
    "\n",
    "            loss.backward()\n",
    "            clip_grad_norm_(model.parameters(), 1.0)  # 梯度截断\n",
    "\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "#             scheduler.step()\n",
    "\n",
    "            predictions.extend(prediction)\n",
    "            gold_labels.extend(labels)\n",
    "\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        train_precision, train_recall, train_f1, train_acc = compute_metrics(predictions, gold_labels)\n",
    "        train_time = format_time(time.time()-start)\n",
    "\n",
    "        model.eval()\n",
    "        valid_loss = 0.0\n",
    "        predictions = []\n",
    "        gold_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (sequence, attention_masks, token_type_ids, labels) in enumerate(valid_loader):\n",
    "                sequence = sequence.to(device)\n",
    "                attention_masks = attention_masks.to(device)\n",
    "                token_type_ids = token_type_ids.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                outputs = model(sequence, attention_mask=attention_masks,  labels=labels)\n",
    "                loss = outputs.loss\n",
    "                prediction = outputs.logits\n",
    "                \n",
    "                valid_loss += loss.item()\n",
    "                prediction = torch.argmax(prediction, dim=1)\n",
    "\n",
    "                predictions.extend(prediction)\n",
    "                gold_labels.extend(labels)\n",
    "\n",
    "                labels_cpu = labels.cpu()\n",
    "                prediction_cpu = prediction.cpu()\n",
    "                input_data = str([tokenizer.decode(ids,skip_special_tokens=True) for ids in sequence])\n",
    "                # with open(file_name.format(times) +'.txt', 'a') as f:\n",
    "                #     f.write(input_data)\n",
    "                #     f.write('%s\\n' % labels_cpu.numpy().tolist())\n",
    "                #     f.write('%s\\n' % prediction_cpu.numpy().tolist())\n",
    "     \n",
    "        valid_time = format_time(time.time() - start)\n",
    "        valid_loss = valid_loss / len(valid_loader)\n",
    "        valid_precision, valid_recall, valid_f1, valid_acc = compute_metrics(predictions, gold_labels)\n",
    "        \n",
    "        if valid_f1 != best_f1:\n",
    "            if valid_f1 > best_f1:\n",
    "                best_f1 = valid_f1\n",
    "                print(f\"New best validation f1 of {valid_f1:.3f}. Saving model.\")\n",
    "                torch.save(model, \"save_longformerModel.pt\")\n",
    "            epochs_without_improvement = 0      \n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            \n",
    "        # 如果验证集上的f1连续patience个epoch没有变化，则停止训练\n",
    "        if epochs_without_improvement == patience:\n",
    "            print('Early stopping at epoch {}...'.format(epoch+1))\n",
    "            break\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "\n",
    "        end = time.time()\n",
    "        hours, rem = divmod(end - start, 3600)\n",
    "        min, sec = divmod(rem, 60)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}: train_loss: {train_loss:.3f} train_precision: {train_precision:.3f} train_recall: {train_recall:.3f} train_f1: {train_f1:.3f} train_acc: {train_acc:.3f}\")\n",
    "        print(f\"\\t valid_loss: {valid_loss:.3f} valid_precision: {valid_precision:.3f} valid_recall: {valid_recall:.3f} valid_f1: {valid_f1:.3f} valid_acc: {valid_acc:.3f}\")\n",
    "        print(\"\\t {:0>2}:{:0>2}:{:05.2f}\".format(int(hours), int(min), sec))\n",
    "\n",
    "    print('   Training Completed!')\n",
    "    return train_losses,valid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db417b89-0b63-4f44-a83b-a5f66f49618a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Train batch size = 8\n",
      "   Total steps = 412400\n",
      "   Training Start!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                               | 0/4124 [00:00<?, ?it/s]Initializing global attention on CLS token...\n",
      "Input ids are automatically padded from 515 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████| 4124/4124 [1:17:38<00:00,  1.13s/it]\n",
      "Input ids are automatically padded from 398 to 512 to be a multiple of `config.attention_window`: 512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best validation f1 of 0.522. Saving model.\n",
      "Epoch 1: train_loss: 0.569 train_precision: 0.731 train_recall: 0.640 train_f1: 0.683 train_acc: 0.702\n",
      "\t valid_loss: 0.703 valid_precision: 0.758 valid_recall: 0.398 valid_f1: 0.522 valid_acc: 0.636\n",
      "\t 01:19:50.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████| 4124/4124 [1:17:56<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best validation f1 of 0.666. Saving model.\n",
      "Epoch 2: train_loss: 0.506 train_precision: 0.797 train_recall: 0.719 train_f1: 0.756 train_acc: 0.768\n",
      "\t valid_loss: 0.644 valid_precision: 0.728 valid_recall: 0.613 valid_f1: 0.666 valid_acc: 0.692\n",
      "\t 01:20:06.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████| 4124/4124 [1:21:10<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best validation f1 of 0.685. Saving model.\n",
      "Epoch 3: train_loss: 0.483 train_precision: 0.805 train_recall: 0.746 train_f1: 0.774 train_acc: 0.783\n",
      "\t valid_loss: 0.701 valid_precision: 0.718 valid_recall: 0.654 valid_f1: 0.685 valid_acc: 0.699\n",
      "\t 01:23:20.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████| 4124/4124 [1:21:22<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: train_loss: 0.428 train_precision: 0.844 train_recall: 0.815 train_f1: 0.829 train_acc: 0.832\n",
      "\t valid_loss: 1.073 valid_precision: 0.777 valid_recall: 0.583 valid_f1: 0.666 valid_acc: 0.708\n",
      "\t 01:23:25.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████| 4124/4124 [1:20:59<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: train_loss: 0.402 train_precision: 0.875 train_recall: 0.836 train_f1: 0.855 train_acc: 0.858\n",
      "\t valid_loss: 1.094 valid_precision: 0.769 valid_recall: 0.616 valid_f1: 0.684 valid_acc: 0.715\n",
      "\t 01:23:06.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████| 4124/4124 [1:20:44<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: train_loss: 0.381 train_precision: 0.893 train_recall: 0.857 train_f1: 0.875 train_acc: 0.877\n",
      "\t valid_loss: 1.199 valid_precision: 0.825 valid_recall: 0.527 valid_f1: 0.643 valid_acc: 0.708\n",
      "\t 01:22:50.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████| 4124/4124 [1:20:45<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: train_loss: 0.355 train_precision: 0.909 train_recall: 0.886 train_f1: 0.898 train_acc: 0.899\n",
      "\t valid_loss: 1.255 valid_precision: 0.775 valid_recall: 0.613 valid_f1: 0.684 valid_acc: 0.717\n",
      "\t 01:22:51.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████| 4124/4124 [1:20:41<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: train_loss: 0.322 train_precision: 0.926 train_recall: 0.901 train_f1: 0.914 train_acc: 0.915\n",
      "\t valid_loss: 1.322 valid_precision: 0.771 valid_recall: 0.613 valid_f1: 0.683 valid_acc: 0.715\n",
      "\t 01:22:44.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████| 4124/4124 [1:20:30<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best validation f1 of 0.690. Saving model.\n",
      "Epoch 9: train_loss: 0.291 train_precision: 0.937 train_recall: 0.918 train_f1: 0.927 train_acc: 0.928\n",
      "\t valid_loss: 1.439 valid_precision: 0.739 valid_recall: 0.647 valid_f1: 0.690 valid_acc: 0.709\n",
      "\t 01:22:41.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████| 4124/4124 [1:19:58<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: train_loss: 0.257 train_precision: 0.946 train_recall: 0.930 train_f1: 0.938 train_acc: 0.939\n",
      "\t valid_loss: 1.358 valid_precision: 0.794 valid_recall: 0.574 valid_f1: 0.666 valid_acc: 0.713\n",
      "\t 01:22:02.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████| 4124/4124 [1:19:48<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best validation f1 of 0.714. Saving model.\n",
      "Epoch 11: train_loss: 0.232 train_precision: 0.953 train_recall: 0.937 train_f1: 0.945 train_acc: 0.945\n",
      "\t valid_loss: 1.402 valid_precision: 0.759 valid_recall: 0.675 valid_f1: 0.714 valid_acc: 0.730\n",
      "\t 01:21:58.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████| 4124/4124 [1:19:56<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: train_loss: 0.206 train_precision: 0.962 train_recall: 0.948 train_f1: 0.955 train_acc: 0.955\n",
      "\t valid_loss: 1.419 valid_precision: 0.825 valid_recall: 0.578 valid_f1: 0.680 valid_acc: 0.728\n",
      "\t 01:21:59.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████| 4124/4124 [1:20:02<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: train_loss: 0.186 train_precision: 0.966 train_recall: 0.954 train_f1: 0.960 train_acc: 0.960\n",
      "\t valid_loss: 1.576 valid_precision: 0.772 valid_recall: 0.625 valid_f1: 0.691 valid_acc: 0.720\n",
      "\t 01:22:07.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████| 4124/4124 [1:19:59<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: train_loss: 0.166 train_precision: 0.967 train_recall: 0.962 train_f1: 0.965 train_acc: 0.965\n",
      "\t valid_loss: 1.660 valid_precision: 0.755 valid_recall: 0.663 valid_f1: 0.706 valid_acc: 0.724\n",
      "\t 01:22:07.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████| 4124/4124 [1:19:54<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: train_loss: 0.155 train_precision: 0.973 train_recall: 0.964 train_f1: 0.969 train_acc: 0.969\n",
      "\t valid_loss: 1.626 valid_precision: 0.740 valid_recall: 0.676 valid_f1: 0.707 valid_acc: 0.719\n",
      "\t 01:21:58.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████| 4124/4124 [1:20:02<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: train_loss: 0.154 train_precision: 0.970 train_recall: 0.967 train_f1: 0.968 train_acc: 0.969\n",
      "\t valid_loss: 1.763 valid_precision: 0.740 valid_recall: 0.679 valid_f1: 0.708 valid_acc: 0.720\n",
      "\t 01:22:05.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████| 4124/4124 [1:20:42<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: train_loss: 0.141 train_precision: 0.969 train_recall: 0.974 train_f1: 0.972 train_acc: 0.971\n",
      "\t valid_loss: 1.941 valid_precision: 0.756 valid_recall: 0.593 valid_f1: 0.664 valid_acc: 0.700\n",
      "\t 01:22:45.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████| 4124/4124 [1:19:35<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: train_loss: 0.122 train_precision: 0.977 train_recall: 0.974 train_f1: 0.975 train_acc: 0.975\n",
      "\t valid_loss: 1.868 valid_precision: 0.719 valid_recall: 0.675 valid_f1: 0.696 valid_acc: 0.706\n",
      "\t 01:21:34.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████| 4124/4124 [1:18:20<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: train_loss: 0.116 train_precision: 0.975 train_recall: 0.978 train_f1: 0.977 train_acc: 0.977\n",
      "\t valid_loss: 1.774 valid_precision: 0.803 valid_recall: 0.558 valid_f1: 0.658 valid_acc: 0.710\n",
      "\t 01:20:18.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████| 4124/4124 [1:18:19<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: train_loss: 0.125 train_precision: 0.977 train_recall: 0.974 train_f1: 0.976 train_acc: 0.976\n",
      "\t valid_loss: 1.723 valid_precision: 0.744 valid_recall: 0.674 valid_f1: 0.707 valid_acc: 0.721\n",
      "\t 01:20:17.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████| 4124/4124 [1:18:45<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: train_loss: 0.112 train_precision: 0.980 train_recall: 0.977 train_f1: 0.978 train_acc: 0.978\n",
      "\t valid_loss: 1.826 valid_precision: 0.771 valid_recall: 0.627 valid_f1: 0.692 valid_acc: 0.720\n",
      "\t 01:20:50.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████| 4124/4124 [1:22:52<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: train_loss: 0.109 train_precision: 0.981 train_recall: 0.977 train_f1: 0.979 train_acc: 0.979\n",
      "\t valid_loss: 1.978 valid_precision: 0.789 valid_recall: 0.602 valid_f1: 0.683 valid_acc: 0.720\n",
      "\t 01:24:56.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████| 4124/4124 [1:23:09<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: train_loss: 0.105 train_precision: 0.980 train_recall: 0.980 train_f1: 0.980 train_acc: 0.980\n",
      "\t valid_loss: 2.032 valid_precision: 0.735 valid_recall: 0.672 valid_f1: 0.702 valid_acc: 0.715\n",
      "\t 01:25:16.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████| 4124/4124 [1:23:01<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: train_loss: 0.102 train_precision: 0.979 train_recall: 0.983 train_f1: 0.981 train_acc: 0.981\n",
      "\t valid_loss: 2.047 valid_precision: 0.752 valid_recall: 0.626 valid_f1: 0.683 valid_acc: 0.710\n",
      "\t 01:25:05.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████| 4124/4124 [1:22:33<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: train_loss: 0.088 train_precision: 0.979 train_recall: 0.986 train_f1: 0.983 train_acc: 0.983\n",
      "\t valid_loss: 2.002 valid_precision: 0.792 valid_recall: 0.617 valid_f1: 0.694 valid_acc: 0.727\n",
      "\t 01:24:38.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████| 4124/4124 [1:22:07<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: train_loss: 0.083 train_precision: 0.984 train_recall: 0.985 train_f1: 0.984 train_acc: 0.984\n",
      "\t valid_loss: 2.141 valid_precision: 0.721 valid_recall: 0.674 valid_f1: 0.697 valid_acc: 0.706\n",
      "\t 01:24:10.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████| 4124/4124 [1:21:55<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: train_loss: 0.089 train_precision: 0.982 train_recall: 0.986 train_f1: 0.984 train_acc: 0.984\n",
      "\t valid_loss: 1.973 valid_precision: 0.777 valid_recall: 0.632 valid_f1: 0.697 valid_acc: 0.725\n",
      "\t 01:24:01.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████| 4124/4124 [1:21:41<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: train_loss: 0.086 train_precision: 0.982 train_recall: 0.986 train_f1: 0.984 train_acc: 0.984\n",
      "\t valid_loss: 1.928 valid_precision: 0.788 valid_recall: 0.638 valid_f1: 0.705 valid_acc: 0.733\n",
      "\t 01:23:47.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████| 4124/4124 [1:21:34<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: train_loss: 0.077 train_precision: 0.985 train_recall: 0.986 train_f1: 0.986 train_acc: 0.986\n",
      "\t valid_loss: 2.008 valid_precision: 0.779 valid_recall: 0.617 valid_f1: 0.688 valid_acc: 0.721\n",
      "\t 01:23:37.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████| 4124/4124 [1:21:20<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: train_loss: 0.082 train_precision: 0.985 train_recall: 0.984 train_f1: 0.984 train_acc: 0.984\n",
      "\t valid_loss: 2.064 valid_precision: 0.753 valid_recall: 0.632 valid_f1: 0.687 valid_acc: 0.712\n",
      "\t 01:23:28.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████| 4124/4124 [1:21:16<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: train_loss: 0.081 train_precision: 0.982 train_recall: 0.986 train_f1: 0.984 train_acc: 0.984\n",
      "\t valid_loss: 2.078 valid_precision: 0.783 valid_recall: 0.622 valid_f1: 0.693 valid_acc: 0.725\n",
      "\t 01:23:19.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████| 4124/4124 [1:19:30<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: train_loss: 0.085 train_precision: 0.983 train_recall: 0.987 train_f1: 0.985 train_acc: 0.985\n",
      "\t valid_loss: 1.807 valid_precision: 0.755 valid_recall: 0.655 valid_f1: 0.701 valid_acc: 0.721\n",
      "\t 01:21:28.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████| 4124/4124 [1:17:50<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: train_loss: 0.083 train_precision: 0.982 train_recall: 0.987 train_f1: 0.984 train_acc: 0.984\n",
      "\t valid_loss: 2.058 valid_precision: 0.794 valid_recall: 0.607 valid_f1: 0.688 valid_acc: 0.725\n",
      "\t 01:19:48.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████| 4124/4124 [1:17:57<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: train_loss: 0.083 train_precision: 0.979 train_recall: 0.989 train_f1: 0.984 train_acc: 0.984\n",
      "\t valid_loss: 1.942 valid_precision: 0.777 valid_recall: 0.641 valid_f1: 0.703 valid_acc: 0.729\n",
      "\t 01:19:55.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████| 4124/4124 [1:18:09<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: train_loss: 0.074 train_precision: 0.985 train_recall: 0.987 train_f1: 0.986 train_acc: 0.986\n",
      "\t valid_loss: 2.054 valid_precision: 0.768 valid_recall: 0.651 valid_f1: 0.705 valid_acc: 0.727\n",
      "\t 01:20:07.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████| 4124/4124 [1:18:20<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: train_loss: 0.061 train_precision: 0.988 train_recall: 0.990 train_f1: 0.989 train_acc: 0.989\n",
      "\t valid_loss: 2.195 valid_precision: 0.804 valid_recall: 0.578 valid_f1: 0.673 valid_acc: 0.719\n",
      "\t 01:20:18.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|███▉                                                               | 241/4124 [04:29<1:12:00,  1.11s/it]"
     ]
    }
   ],
   "source": [
    "train_losses,valid_losses = train(model,train_data,valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e35695-c24b-4aa8-a396-8483e00f234a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 假设train_losses和val_losses分别存储了训练损失和验证损失\n",
    "epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_losses, 'r-', label='Training Loss')\n",
    "plt.plot(epochs, valid_losses, 'b-', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532abfd0-b8d7-41e9-80e2-879fdb9a351d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee580c6a-81d2-4f2d-a002-778bc12d51c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d072f1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_test_data():\n",
    "    test_param = pd.read_json(\"D:/LTX/code_comment_inconsistency_detection/data/param/test.json\")\n",
    "    test_return = pd.read_json(\"D:/LTX/code_comment_inconsistency_detection/data/return/test.json\")\n",
    "    test_summary = pd.read_json(\"D:/LTX/code_comment_inconsistency_detection/data/summary/test.json\")\n",
    "    test_df = pd.concat([test_summary,test_param, test_return], axis=0)\n",
    "    test_df = test_df[:1000]\n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc77854-bf34-465f-8c19-bc3d9d4c956f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, device):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    predictions = []\n",
    "    gold_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (sequence, attention_masks, token_type_ids, labels) in enumerate(test_loader):\n",
    "            sequence = sequence.to(device)\n",
    "            attention_masks = attention_masks.to(device)\n",
    "            token_type_ids = token_type_ids.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(sequence, attention_mask=attention_masks, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            prediction = outputs.logits\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            prediction = torch.argmax(prediction, dim=-1)\n",
    "\n",
    "            predictions.extend(prediction)\n",
    "            gold_labels.extend(labels)\n",
    "        \n",
    "    test_loss = test_loss / len(test_loader)\n",
    "    test_precision, test_recall, test_f1, test_acc = compute_metrics(predictions, gold_labels)\n",
    "\n",
    "    print(f\"test_loss: {test_loss:.3f} test_precision: {test_precision:.3f} test_recall: {test_recall:.3f} test_f1: {test_f1:.3f} test_acc: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d8bb2a-ec3e-4f94-9d4e-9a14705e4551",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = retrieve_test_data()\n",
    "train_df_clean = format_data(train_df)\n",
    "test_data = CocoDataset(train_df_clean)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9092a7d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leitx",
   "language": "python",
   "name": "leitx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
