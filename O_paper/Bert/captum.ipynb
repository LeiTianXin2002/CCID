{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e84e3fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer,BertModel\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "\n",
    "\n",
    "from captum.attr import visualization as viz\n",
    "from captum.attr import LayerConductance, LayerIntegratedGradients\n",
    "from captum.attr import configure_interpretable_embedding_layer, remove_interpretable_embedding_layer\n",
    "\n",
    "# 解决服务器挂掉的问题\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff062613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device( \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf31e07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 1024\n",
    "MAX_EPOCHS = 10\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 1e-5\n",
    "NUM_CLASSES = 2\n",
    "WEIGTH_DECAY = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9449ad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_train_data():\n",
    "    train_param = pd.read_json(\"D:/BERT_learing/code_comment_inconsistency_detection/data/param/train.json\")\n",
    "    train_return = pd.read_json(\"D:/BERT_learing/code_comment_inconsistency_detection/data/return/train.json\")\n",
    "    train_summary = pd.read_json(\"D:/BERT_learing/code_comment_inconsistency_detection/data/summary/train.json\")\n",
    "    train_df = pd.concat([train_summary,train_param, train_return], axis=0)\n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "    return train_df\n",
    "def retrieve_valid_data():\n",
    "    valid_param = pd.read_json(\"D:/BERT_learing/code_comment_inconsistency_detection/data/param/valid.json\")\n",
    "    valid_return = pd.read_json(\"D:/BERT_learing/code_comment_inconsistency_detection/data/return/valid.json\")\n",
    "    valid_summary = pd.read_json(\"D:/BERT_learing/code_comment_inconsistency_detection/data/summary/valid.json\")\n",
    "    valid_df = pd.concat([valid_summary,valid_param, valid_return ], axis=0)\n",
    "    valid_df = valid_df.reset_index(drop=True)\n",
    "    return valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e9b5366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>comment_type</th>\n",
       "      <th>old_comment_raw</th>\n",
       "      <th>old_comment_subtokens</th>\n",
       "      <th>new_comment_raw</th>\n",
       "      <th>new_comment_subtokens</th>\n",
       "      <th>span_minimal_diff_comment_subtokens</th>\n",
       "      <th>old_code_raw</th>\n",
       "      <th>old_code_subtokens</th>\n",
       "      <th>new_code_raw</th>\n",
       "      <th>new_code_subtokens</th>\n",
       "      <th>span_diff_code_subtokens</th>\n",
       "      <th>token_diff_code_subtokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grails-plugins_grails-plugin-converters-5-Asso...</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Parses the given JSON and returns ether a JSON...</td>\n",
       "      <td>[parses, the, given, json, and, returns, ether...</td>\n",
       "      <td>Parses the given JSON and returns either a JSO...</td>\n",
       "      <td>[parses, the, given, json, and, returns, eithe...</td>\n",
       "      <td>[&lt;REPLACE_OLD&gt;, ether, &lt;REPLACE_NEW&gt;, either, ...</td>\n",
       "      <td>public static JSONElement parse(InputStrea...</td>\n",
       "      <td>[public, static, jsonelement, parse, (, input,...</td>\n",
       "      <td>public static JSONElement parse(InputStrea...</td>\n",
       "      <td>[public, static, jsonelement, parse, (, input,...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, jsonelement, parse, (...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;KEEP&gt;, jsone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jitsi_jitsi-4343-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Loads an image from a given image identifier.</td>\n",
       "      <td>[loads, an, image, from, a, given, image, iden...</td>\n",
       "      <td>Loads an image from a given image identifier.</td>\n",
       "      <td>[loads, an, image, from, a, given, image, iden...</td>\n",
       "      <td>[]</td>\n",
       "      <td>public static byte[] getImageInBytes(Strin...</td>\n",
       "      <td>[public, static, byte, [, ], get, image, in, b...</td>\n",
       "      <td>public static byte[] getImageInBytes(Strin...</td>\n",
       "      <td>[public, static, byte, [, ], get, image, in, b...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, byte, [, ], get, imag...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;KEEP&gt;, byte,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dropwizard_metrics-26-Associations-FirstSentence</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Creates a new  CounterMetric and registers it ...</td>\n",
       "      <td>[creates, a, new, counter, metric, and, regist...</td>\n",
       "      <td>Creates a new  com.yammer.metrics.core.Counter...</td>\n",
       "      <td>[creates, a, new, com, ., yammer, ., metrics, ...</td>\n",
       "      <td>[&lt;INSERT_OLD_KEEP_BEFORE&gt;, new, &lt;INSERT_NEW_KE...</td>\n",
       "      <td>public static CounterMetric newCounter(Cla...</td>\n",
       "      <td>[public, static, counter, metric, new, counter...</td>\n",
       "      <td>public static Counter newCounter(Class&lt;?&gt; ...</td>\n",
       "      <td>[public, static, counter, new, counter, (, cla...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, counter, &lt;KEEP_END&gt;, ...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;KEEP&gt;, count...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>google_ExoPlayer-92-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Derives a sample format corresponding to a giv...</td>\n",
       "      <td>[derives, a, sample, format, corresponding, to...</td>\n",
       "      <td>Derives a sample format corresponding to a giv...</td>\n",
       "      <td>[derives, a, sample, format, corresponding, to...</td>\n",
       "      <td>[]</td>\n",
       "      <td>private static Format getSampleFormat(Format...</td>\n",
       "      <td>[private, static, format, get, sample, format,...</td>\n",
       "      <td>private static Format getSampleFormat(Format...</td>\n",
       "      <td>[private, static, format, get, sample, format,...</td>\n",
       "      <td>[&lt;KEEP&gt;, private, static, format, get, sample,...</td>\n",
       "      <td>[&lt;KEEP&gt;, private, &lt;KEEP&gt;, static, &lt;KEEP&gt;, form...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>slachiewicz_orekit-main-661-Associations-First...</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Revert a rotation/rotation rate pair.</td>\n",
       "      <td>[revert, a, rotation, /, rotation, rate, pair, .]</td>\n",
       "      <td>Revert a rotation/rotation rate/ rotation acce...</td>\n",
       "      <td>[revert, a, rotation, /, rotation, rate, /, ro...</td>\n",
       "      <td>[&lt;REPLACE_OLD&gt;, pair, &lt;REPLACE_NEW&gt;, /, rotati...</td>\n",
       "      <td>public AngularCoordinates revert() {\\n    ...</td>\n",
       "      <td>[public, angular, coordinates, revert, (, ), {...</td>\n",
       "      <td>public AngularCoordinates revert() {\\n    ...</td>\n",
       "      <td>[public, angular, coordinates, revert, (, ), {...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, angular, coordinates, revert,...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, angular, &lt;KEEP&gt;, coor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  label comment_type  \\\n",
       "0  grails-plugins_grails-plugin-converters-5-Asso...      1      Summary   \n",
       "1                   jitsi_jitsi-4343-FirstSentence-0      0      Summary   \n",
       "2   dropwizard_metrics-26-Associations-FirstSentence      1      Summary   \n",
       "3                google_ExoPlayer-92-FirstSentence-0      0      Summary   \n",
       "4  slachiewicz_orekit-main-661-Associations-First...      1      Summary   \n",
       "\n",
       "                                     old_comment_raw  \\\n",
       "0  Parses the given JSON and returns ether a JSON...   \n",
       "1      Loads an image from a given image identifier.   \n",
       "2  Creates a new  CounterMetric and registers it ...   \n",
       "3  Derives a sample format corresponding to a giv...   \n",
       "4              Revert a rotation/rotation rate pair.   \n",
       "\n",
       "                               old_comment_subtokens  \\\n",
       "0  [parses, the, given, json, and, returns, ether...   \n",
       "1  [loads, an, image, from, a, given, image, iden...   \n",
       "2  [creates, a, new, counter, metric, and, regist...   \n",
       "3  [derives, a, sample, format, corresponding, to...   \n",
       "4  [revert, a, rotation, /, rotation, rate, pair, .]   \n",
       "\n",
       "                                     new_comment_raw  \\\n",
       "0  Parses the given JSON and returns either a JSO...   \n",
       "1      Loads an image from a given image identifier.   \n",
       "2  Creates a new  com.yammer.metrics.core.Counter...   \n",
       "3  Derives a sample format corresponding to a giv...   \n",
       "4  Revert a rotation/rotation rate/ rotation acce...   \n",
       "\n",
       "                               new_comment_subtokens  \\\n",
       "0  [parses, the, given, json, and, returns, eithe...   \n",
       "1  [loads, an, image, from, a, given, image, iden...   \n",
       "2  [creates, a, new, com, ., yammer, ., metrics, ...   \n",
       "3  [derives, a, sample, format, corresponding, to...   \n",
       "4  [revert, a, rotation, /, rotation, rate, /, ro...   \n",
       "\n",
       "                 span_minimal_diff_comment_subtokens  \\\n",
       "0  [<REPLACE_OLD>, ether, <REPLACE_NEW>, either, ...   \n",
       "1                                                 []   \n",
       "2  [<INSERT_OLD_KEEP_BEFORE>, new, <INSERT_NEW_KE...   \n",
       "3                                                 []   \n",
       "4  [<REPLACE_OLD>, pair, <REPLACE_NEW>, /, rotati...   \n",
       "\n",
       "                                        old_code_raw  \\\n",
       "0      public static JSONElement parse(InputStrea...   \n",
       "1      public static byte[] getImageInBytes(Strin...   \n",
       "2      public static CounterMetric newCounter(Cla...   \n",
       "3    private static Format getSampleFormat(Format...   \n",
       "4      public AngularCoordinates revert() {\\n    ...   \n",
       "\n",
       "                                  old_code_subtokens  \\\n",
       "0  [public, static, jsonelement, parse, (, input,...   \n",
       "1  [public, static, byte, [, ], get, image, in, b...   \n",
       "2  [public, static, counter, metric, new, counter...   \n",
       "3  [private, static, format, get, sample, format,...   \n",
       "4  [public, angular, coordinates, revert, (, ), {...   \n",
       "\n",
       "                                        new_code_raw  \\\n",
       "0      public static JSONElement parse(InputStrea...   \n",
       "1      public static byte[] getImageInBytes(Strin...   \n",
       "2      public static Counter newCounter(Class<?> ...   \n",
       "3    private static Format getSampleFormat(Format...   \n",
       "4      public AngularCoordinates revert() {\\n    ...   \n",
       "\n",
       "                                  new_code_subtokens  \\\n",
       "0  [public, static, jsonelement, parse, (, input,...   \n",
       "1  [public, static, byte, [, ], get, image, in, b...   \n",
       "2  [public, static, counter, new, counter, (, cla...   \n",
       "3  [private, static, format, get, sample, format,...   \n",
       "4  [public, angular, coordinates, revert, (, ), {...   \n",
       "\n",
       "                            span_diff_code_subtokens  \\\n",
       "0  [<KEEP>, public, static, jsonelement, parse, (...   \n",
       "1  [<KEEP>, public, static, byte, [, ], get, imag...   \n",
       "2  [<KEEP>, public, static, counter, <KEEP_END>, ...   \n",
       "3  [<KEEP>, private, static, format, get, sample,...   \n",
       "4  [<KEEP>, public, angular, coordinates, revert,...   \n",
       "\n",
       "                           token_diff_code_subtokens  \n",
       "0  [<KEEP>, public, <KEEP>, static, <KEEP>, jsone...  \n",
       "1  [<KEEP>, public, <KEEP>, static, <KEEP>, byte,...  \n",
       "2  [<KEEP>, public, <KEEP>, static, <KEEP>, count...  \n",
       "3  [<KEEP>, private, <KEEP>, static, <KEEP>, form...  \n",
       "4  [<KEEP>, public, <KEEP>, angular, <KEEP>, coor...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = retrieve_train_data()\n",
    "valid_df = retrieve_valid_data()\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a71bbe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>comment_type</th>\n",
       "      <th>old_comment_raw</th>\n",
       "      <th>old_comment_subtokens</th>\n",
       "      <th>new_comment_raw</th>\n",
       "      <th>new_comment_subtokens</th>\n",
       "      <th>span_minimal_diff_comment_subtokens</th>\n",
       "      <th>old_code_raw</th>\n",
       "      <th>old_code_subtokens</th>\n",
       "      <th>new_code_raw</th>\n",
       "      <th>new_code_subtokens</th>\n",
       "      <th>span_diff_code_subtokens</th>\n",
       "      <th>token_diff_code_subtokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>todoroo_astrid-987-FirstSentence-0</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Return SQL selector query for getting tasks wi...</td>\n",
       "      <td>[return, sql, selector, query, for, getting, t...</td>\n",
       "      <td>Return SQL selector query for getting tasks wi...</td>\n",
       "      <td>[return, sql, selector, query, for, getting, t...</td>\n",
       "      <td>[&lt;INSERT_OLD_KEEP_BEFORE&gt;, tag, &lt;INSERT_NEW_KE...</td>\n",
       "      <td>public QueryTemplate queryTemplate(Cri...</td>\n",
       "      <td>[public, query, template, query, template, (, ...</td>\n",
       "      <td>public static QueryTemplate queryTempl...</td>\n",
       "      <td>[public, static, query, template, query, templ...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP_END&gt;, &lt;INSERT&gt;, static,...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;INSERT&gt;, static, &lt;KEEP&gt;, que...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Red5_red5_server-43-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Return period of ghost connections cleanup tas...</td>\n",
       "      <td>[return, period, of, ghost, connections, clean...</td>\n",
       "      <td>Return period of ghost connections cleanup tas...</td>\n",
       "      <td>[return, period, of, ghost, connections, clean...</td>\n",
       "      <td>[]</td>\n",
       "      <td>public int getGhostConnsCleanupPeriod() {\\...</td>\n",
       "      <td>[public, int, get, ghost, conns, cleanup, peri...</td>\n",
       "      <td>public int getGhostConnsCleanupPeriod() {\\...</td>\n",
       "      <td>[public, int, get, ghost, conns, cleanup, peri...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, int, get, ghost, conns, clean...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, int, &lt;KEEP&gt;, get, &lt;KE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nickman_Rindle-11-Associations-FirstSentence</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Allocates an initialized and initially unlocke...</td>\n",
       "      <td>[allocates, an, initialized, and, initially, u...</td>\n",
       "      <td>Allocates an initialized and initially unlocke...</td>\n",
       "      <td>[allocates, an, initialized, and, initially, u...</td>\n",
       "      <td>[&lt;INSERT_OLD_KEEP_BEFORE&gt;, unlocked, &lt;INSERT_N...</td>\n",
       "      <td>\\tpublic static long allocateSpinLock() {\\r\\n\\...</td>\n",
       "      <td>[public, static, long, allocate, spin, lock, (...</td>\n",
       "      <td>\\tpublic static SpinLock allocateSpinLock() {\\...</td>\n",
       "      <td>[public, static, spin, lock, allocate, spin, l...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, &lt;KEEP_END&gt;, &lt;REPLACE_...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;REPLACE_OLD&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>h2oai_h2o_2-427-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Rebalance a frame for load balancing</td>\n",
       "      <td>[rebalance, a, frame, for, load, balancing]</td>\n",
       "      <td>Rebalance a frame for load balancing</td>\n",
       "      <td>[rebalance, a, frame, for, load, balancing]</td>\n",
       "      <td>[]</td>\n",
       "      <td>private Frame reBalance(final Frame fr, bool...</td>\n",
       "      <td>[private, frame, re, balance, (, final, frame,...</td>\n",
       "      <td>private static Frame reBalance(final Frame f...</td>\n",
       "      <td>[private, static, frame, re, balance, (, final...</td>\n",
       "      <td>[&lt;KEEP&gt;, private, &lt;KEEP_END&gt;, &lt;INSERT&gt;, static...</td>\n",
       "      <td>[&lt;KEEP&gt;, private, &lt;INSERT&gt;, static, &lt;KEEP&gt;, fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sonatype_sonatype-aether-11-Associations-First...</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Sets the host of this proxy.</td>\n",
       "      <td>[sets, the, host, of, this, proxy, .]</td>\n",
       "      <td>Sets the host of the proxy.</td>\n",
       "      <td>[sets, the, host, of, the, proxy, .]</td>\n",
       "      <td>[&lt;REPLACE_OLD&gt;, this, &lt;REPLACE_NEW&gt;, the, &lt;REP...</td>\n",
       "      <td>public Proxy setHost( String host )\\n    {...</td>\n",
       "      <td>[public, proxy, set, host, (, string, host, ),...</td>\n",
       "      <td>public Proxy setHost( String host )\\n    {...</td>\n",
       "      <td>[public, proxy, set, host, (, string, host, ),...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, proxy, set, host, (, string, ...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, proxy, &lt;KEEP&gt;, set, &lt;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  label comment_type  \\\n",
       "0                 todoroo_astrid-987-FirstSentence-0      1      Summary   \n",
       "1                Red5_red5_server-43-FirstSentence-0      0      Summary   \n",
       "2       nickman_Rindle-11-Associations-FirstSentence      1      Summary   \n",
       "3                    h2oai_h2o_2-427-FirstSentence-0      0      Summary   \n",
       "4  sonatype_sonatype-aether-11-Associations-First...      1      Summary   \n",
       "\n",
       "                                     old_comment_raw  \\\n",
       "0  Return SQL selector query for getting tasks wi...   \n",
       "1  Return period of ghost connections cleanup tas...   \n",
       "2  Allocates an initialized and initially unlocke...   \n",
       "3               Rebalance a frame for load balancing   \n",
       "4                       Sets the host of this proxy.   \n",
       "\n",
       "                               old_comment_subtokens  \\\n",
       "0  [return, sql, selector, query, for, getting, t...   \n",
       "1  [return, period, of, ghost, connections, clean...   \n",
       "2  [allocates, an, initialized, and, initially, u...   \n",
       "3        [rebalance, a, frame, for, load, balancing]   \n",
       "4              [sets, the, host, of, this, proxy, .]   \n",
       "\n",
       "                                     new_comment_raw  \\\n",
       "0  Return SQL selector query for getting tasks wi...   \n",
       "1  Return period of ghost connections cleanup tas...   \n",
       "2  Allocates an initialized and initially unlocke...   \n",
       "3               Rebalance a frame for load balancing   \n",
       "4                        Sets the host of the proxy.   \n",
       "\n",
       "                               new_comment_subtokens  \\\n",
       "0  [return, sql, selector, query, for, getting, t...   \n",
       "1  [return, period, of, ghost, connections, clean...   \n",
       "2  [allocates, an, initialized, and, initially, u...   \n",
       "3        [rebalance, a, frame, for, load, balancing]   \n",
       "4               [sets, the, host, of, the, proxy, .]   \n",
       "\n",
       "                 span_minimal_diff_comment_subtokens  \\\n",
       "0  [<INSERT_OLD_KEEP_BEFORE>, tag, <INSERT_NEW_KE...   \n",
       "1                                                 []   \n",
       "2  [<INSERT_OLD_KEEP_BEFORE>, unlocked, <INSERT_N...   \n",
       "3                                                 []   \n",
       "4  [<REPLACE_OLD>, this, <REPLACE_NEW>, the, <REP...   \n",
       "\n",
       "                                        old_code_raw  \\\n",
       "0          public QueryTemplate queryTemplate(Cri...   \n",
       "1      public int getGhostConnsCleanupPeriod() {\\...   \n",
       "2  \\tpublic static long allocateSpinLock() {\\r\\n\\...   \n",
       "3    private Frame reBalance(final Frame fr, bool...   \n",
       "4      public Proxy setHost( String host )\\n    {...   \n",
       "\n",
       "                                  old_code_subtokens  \\\n",
       "0  [public, query, template, query, template, (, ...   \n",
       "1  [public, int, get, ghost, conns, cleanup, peri...   \n",
       "2  [public, static, long, allocate, spin, lock, (...   \n",
       "3  [private, frame, re, balance, (, final, frame,...   \n",
       "4  [public, proxy, set, host, (, string, host, ),...   \n",
       "\n",
       "                                        new_code_raw  \\\n",
       "0          public static QueryTemplate queryTempl...   \n",
       "1      public int getGhostConnsCleanupPeriod() {\\...   \n",
       "2  \\tpublic static SpinLock allocateSpinLock() {\\...   \n",
       "3    private static Frame reBalance(final Frame f...   \n",
       "4      public Proxy setHost( String host )\\n    {...   \n",
       "\n",
       "                                  new_code_subtokens  \\\n",
       "0  [public, static, query, template, query, templ...   \n",
       "1  [public, int, get, ghost, conns, cleanup, peri...   \n",
       "2  [public, static, spin, lock, allocate, spin, l...   \n",
       "3  [private, static, frame, re, balance, (, final...   \n",
       "4  [public, proxy, set, host, (, string, host, ),...   \n",
       "\n",
       "                            span_diff_code_subtokens  \\\n",
       "0  [<KEEP>, public, <KEEP_END>, <INSERT>, static,...   \n",
       "1  [<KEEP>, public, int, get, ghost, conns, clean...   \n",
       "2  [<KEEP>, public, static, <KEEP_END>, <REPLACE_...   \n",
       "3  [<KEEP>, private, <KEEP_END>, <INSERT>, static...   \n",
       "4  [<KEEP>, public, proxy, set, host, (, string, ...   \n",
       "\n",
       "                           token_diff_code_subtokens  \n",
       "0  [<KEEP>, public, <INSERT>, static, <KEEP>, que...  \n",
       "1  [<KEEP>, public, <KEEP>, int, <KEEP>, get, <KE...  \n",
       "2  [<KEEP>, public, <KEEP>, static, <REPLACE_OLD>...  \n",
       "3  [<KEEP>, private, <INSERT>, static, <KEEP>, fr...  \n",
       "4  [<KEEP>, public, <KEEP>, proxy, <KEEP>, set, <...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aeb436d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(df):\n",
    "    old_code_raw = df['new_code_raw']\n",
    "    old_code_raw = old_code_raw.values\n",
    "    old_code_raw = [str(ele) for ele in old_code_raw]\n",
    "       \n",
    "    multi_line_old_code = []\n",
    "    for i in range(len(old_code_raw)):\n",
    "        multi_line_test = old_code_raw[i].replace('\\n', ' ')   # 去掉\\n\n",
    "        multi_line_test = ' '.join(multi_line_test.split())    # 把多余空格变成一个空格\n",
    "        multi_line_old_code.append(multi_line_test) \n",
    "     \n",
    "    old_comment_raw = df['old_comment_raw']\n",
    "    old_comment_raw = old_comment_raw.values\n",
    "    old_comment_raw = [str(ele) for ele in old_comment_raw]\n",
    "    multi_line_old_comment = []\n",
    "    for i in range(len(old_comment_raw)):\n",
    "        multi_line_test = ' '.join(old_comment_raw[i].split())    # 把多余空格变成一个空格\n",
    "        multi_line_old_comment.append(multi_line_test)  \n",
    "    \n",
    "    df['new_code_raw'] = multi_line_old_code\n",
    "    df['old_comment_raw'] = multi_line_old_comment\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e42afc18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>comment_type</th>\n",
       "      <th>old_comment_raw</th>\n",
       "      <th>old_comment_subtokens</th>\n",
       "      <th>new_comment_raw</th>\n",
       "      <th>new_comment_subtokens</th>\n",
       "      <th>span_minimal_diff_comment_subtokens</th>\n",
       "      <th>old_code_raw</th>\n",
       "      <th>old_code_subtokens</th>\n",
       "      <th>new_code_raw</th>\n",
       "      <th>new_code_subtokens</th>\n",
       "      <th>span_diff_code_subtokens</th>\n",
       "      <th>token_diff_code_subtokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grails-plugins_grails-plugin-converters-5-Asso...</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Parses the given JSON and returns ether a JSON...</td>\n",
       "      <td>[parses, the, given, json, and, returns, ether...</td>\n",
       "      <td>Parses the given JSON and returns either a JSO...</td>\n",
       "      <td>[parses, the, given, json, and, returns, eithe...</td>\n",
       "      <td>[&lt;REPLACE_OLD&gt;, ether, &lt;REPLACE_NEW&gt;, either, ...</td>\n",
       "      <td>public static JSONElement parse(InputStrea...</td>\n",
       "      <td>[public, static, jsonelement, parse, (, input,...</td>\n",
       "      <td>public static JSONElement parse(InputStream is...</td>\n",
       "      <td>[public, static, jsonelement, parse, (, input,...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, jsonelement, parse, (...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;KEEP&gt;, jsone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jitsi_jitsi-4343-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Loads an image from a given image identifier.</td>\n",
       "      <td>[loads, an, image, from, a, given, image, iden...</td>\n",
       "      <td>Loads an image from a given image identifier.</td>\n",
       "      <td>[loads, an, image, from, a, given, image, iden...</td>\n",
       "      <td>[]</td>\n",
       "      <td>public static byte[] getImageInBytes(Strin...</td>\n",
       "      <td>[public, static, byte, [, ], get, image, in, b...</td>\n",
       "      <td>public static byte[] getImageInBytes(String im...</td>\n",
       "      <td>[public, static, byte, [, ], get, image, in, b...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, byte, [, ], get, imag...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;KEEP&gt;, byte,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dropwizard_metrics-26-Associations-FirstSentence</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Creates a new CounterMetric and registers it u...</td>\n",
       "      <td>[creates, a, new, counter, metric, and, regist...</td>\n",
       "      <td>Creates a new  com.yammer.metrics.core.Counter...</td>\n",
       "      <td>[creates, a, new, com, ., yammer, ., metrics, ...</td>\n",
       "      <td>[&lt;INSERT_OLD_KEEP_BEFORE&gt;, new, &lt;INSERT_NEW_KE...</td>\n",
       "      <td>public static CounterMetric newCounter(Cla...</td>\n",
       "      <td>[public, static, counter, metric, new, counter...</td>\n",
       "      <td>public static Counter newCounter(Class&lt;?&gt; klas...</td>\n",
       "      <td>[public, static, counter, new, counter, (, cla...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, counter, &lt;KEEP_END&gt;, ...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;KEEP&gt;, count...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>google_ExoPlayer-92-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Derives a sample format corresponding to a giv...</td>\n",
       "      <td>[derives, a, sample, format, corresponding, to...</td>\n",
       "      <td>Derives a sample format corresponding to a giv...</td>\n",
       "      <td>[derives, a, sample, format, corresponding, to...</td>\n",
       "      <td>[]</td>\n",
       "      <td>private static Format getSampleFormat(Format...</td>\n",
       "      <td>[private, static, format, get, sample, format,...</td>\n",
       "      <td>private static Format getSampleFormat(Format c...</td>\n",
       "      <td>[private, static, format, get, sample, format,...</td>\n",
       "      <td>[&lt;KEEP&gt;, private, static, format, get, sample,...</td>\n",
       "      <td>[&lt;KEEP&gt;, private, &lt;KEEP&gt;, static, &lt;KEEP&gt;, form...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>slachiewicz_orekit-main-661-Associations-First...</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Revert a rotation/rotation rate pair.</td>\n",
       "      <td>[revert, a, rotation, /, rotation, rate, pair, .]</td>\n",
       "      <td>Revert a rotation/rotation rate/ rotation acce...</td>\n",
       "      <td>[revert, a, rotation, /, rotation, rate, /, ro...</td>\n",
       "      <td>[&lt;REPLACE_OLD&gt;, pair, &lt;REPLACE_NEW&gt;, /, rotati...</td>\n",
       "      <td>public AngularCoordinates revert() {\\n    ...</td>\n",
       "      <td>[public, angular, coordinates, revert, (, ), {...</td>\n",
       "      <td>public AngularCoordinates revert() { return ne...</td>\n",
       "      <td>[public, angular, coordinates, revert, (, ), {...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, angular, coordinates, revert,...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, angular, &lt;KEEP&gt;, coor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  label comment_type  \\\n",
       "0  grails-plugins_grails-plugin-converters-5-Asso...      1      Summary   \n",
       "1                   jitsi_jitsi-4343-FirstSentence-0      0      Summary   \n",
       "2   dropwizard_metrics-26-Associations-FirstSentence      1      Summary   \n",
       "3                google_ExoPlayer-92-FirstSentence-0      0      Summary   \n",
       "4  slachiewicz_orekit-main-661-Associations-First...      1      Summary   \n",
       "\n",
       "                                     old_comment_raw  \\\n",
       "0  Parses the given JSON and returns ether a JSON...   \n",
       "1      Loads an image from a given image identifier.   \n",
       "2  Creates a new CounterMetric and registers it u...   \n",
       "3  Derives a sample format corresponding to a giv...   \n",
       "4              Revert a rotation/rotation rate pair.   \n",
       "\n",
       "                               old_comment_subtokens  \\\n",
       "0  [parses, the, given, json, and, returns, ether...   \n",
       "1  [loads, an, image, from, a, given, image, iden...   \n",
       "2  [creates, a, new, counter, metric, and, regist...   \n",
       "3  [derives, a, sample, format, corresponding, to...   \n",
       "4  [revert, a, rotation, /, rotation, rate, pair, .]   \n",
       "\n",
       "                                     new_comment_raw  \\\n",
       "0  Parses the given JSON and returns either a JSO...   \n",
       "1      Loads an image from a given image identifier.   \n",
       "2  Creates a new  com.yammer.metrics.core.Counter...   \n",
       "3  Derives a sample format corresponding to a giv...   \n",
       "4  Revert a rotation/rotation rate/ rotation acce...   \n",
       "\n",
       "                               new_comment_subtokens  \\\n",
       "0  [parses, the, given, json, and, returns, eithe...   \n",
       "1  [loads, an, image, from, a, given, image, iden...   \n",
       "2  [creates, a, new, com, ., yammer, ., metrics, ...   \n",
       "3  [derives, a, sample, format, corresponding, to...   \n",
       "4  [revert, a, rotation, /, rotation, rate, /, ro...   \n",
       "\n",
       "                 span_minimal_diff_comment_subtokens  \\\n",
       "0  [<REPLACE_OLD>, ether, <REPLACE_NEW>, either, ...   \n",
       "1                                                 []   \n",
       "2  [<INSERT_OLD_KEEP_BEFORE>, new, <INSERT_NEW_KE...   \n",
       "3                                                 []   \n",
       "4  [<REPLACE_OLD>, pair, <REPLACE_NEW>, /, rotati...   \n",
       "\n",
       "                                        old_code_raw  \\\n",
       "0      public static JSONElement parse(InputStrea...   \n",
       "1      public static byte[] getImageInBytes(Strin...   \n",
       "2      public static CounterMetric newCounter(Cla...   \n",
       "3    private static Format getSampleFormat(Format...   \n",
       "4      public AngularCoordinates revert() {\\n    ...   \n",
       "\n",
       "                                  old_code_subtokens  \\\n",
       "0  [public, static, jsonelement, parse, (, input,...   \n",
       "1  [public, static, byte, [, ], get, image, in, b...   \n",
       "2  [public, static, counter, metric, new, counter...   \n",
       "3  [private, static, format, get, sample, format,...   \n",
       "4  [public, angular, coordinates, revert, (, ), {...   \n",
       "\n",
       "                                        new_code_raw  \\\n",
       "0  public static JSONElement parse(InputStream is...   \n",
       "1  public static byte[] getImageInBytes(String im...   \n",
       "2  public static Counter newCounter(Class<?> klas...   \n",
       "3  private static Format getSampleFormat(Format c...   \n",
       "4  public AngularCoordinates revert() { return ne...   \n",
       "\n",
       "                                  new_code_subtokens  \\\n",
       "0  [public, static, jsonelement, parse, (, input,...   \n",
       "1  [public, static, byte, [, ], get, image, in, b...   \n",
       "2  [public, static, counter, new, counter, (, cla...   \n",
       "3  [private, static, format, get, sample, format,...   \n",
       "4  [public, angular, coordinates, revert, (, ), {...   \n",
       "\n",
       "                            span_diff_code_subtokens  \\\n",
       "0  [<KEEP>, public, static, jsonelement, parse, (...   \n",
       "1  [<KEEP>, public, static, byte, [, ], get, imag...   \n",
       "2  [<KEEP>, public, static, counter, <KEEP_END>, ...   \n",
       "3  [<KEEP>, private, static, format, get, sample,...   \n",
       "4  [<KEEP>, public, angular, coordinates, revert,...   \n",
       "\n",
       "                           token_diff_code_subtokens  \n",
       "0  [<KEEP>, public, <KEEP>, static, <KEEP>, jsone...  \n",
       "1  [<KEEP>, public, <KEEP>, static, <KEEP>, byte,...  \n",
       "2  [<KEEP>, public, <KEEP>, static, <KEEP>, count...  \n",
       "3  [<KEEP>, private, <KEEP>, static, <KEEP>, form...  \n",
       "4  [<KEEP>, public, <KEEP>, angular, <KEEP>, coor...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_clean = format_data(train_df)\n",
    "train_df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbb175a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>comment_type</th>\n",
       "      <th>old_comment_raw</th>\n",
       "      <th>old_comment_subtokens</th>\n",
       "      <th>new_comment_raw</th>\n",
       "      <th>new_comment_subtokens</th>\n",
       "      <th>span_minimal_diff_comment_subtokens</th>\n",
       "      <th>old_code_raw</th>\n",
       "      <th>old_code_subtokens</th>\n",
       "      <th>new_code_raw</th>\n",
       "      <th>new_code_subtokens</th>\n",
       "      <th>span_diff_code_subtokens</th>\n",
       "      <th>token_diff_code_subtokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>todoroo_astrid-987-FirstSentence-0</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Return SQL selector query for getting tasks wi...</td>\n",
       "      <td>[return, sql, selector, query, for, getting, t...</td>\n",
       "      <td>Return SQL selector query for getting tasks wi...</td>\n",
       "      <td>[return, sql, selector, query, for, getting, t...</td>\n",
       "      <td>[&lt;INSERT_OLD_KEEP_BEFORE&gt;, tag, &lt;INSERT_NEW_KE...</td>\n",
       "      <td>public QueryTemplate queryTemplate(Cri...</td>\n",
       "      <td>[public, query, template, query, template, (, ...</td>\n",
       "      <td>public static QueryTemplate queryTemplate(Crit...</td>\n",
       "      <td>[public, static, query, template, query, templ...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP_END&gt;, &lt;INSERT&gt;, static,...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;INSERT&gt;, static, &lt;KEEP&gt;, que...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Red5_red5_server-43-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Return period of ghost connections cleanup tas...</td>\n",
       "      <td>[return, period, of, ghost, connections, clean...</td>\n",
       "      <td>Return period of ghost connections cleanup tas...</td>\n",
       "      <td>[return, period, of, ghost, connections, clean...</td>\n",
       "      <td>[]</td>\n",
       "      <td>public int getGhostConnsCleanupPeriod() {\\...</td>\n",
       "      <td>[public, int, get, ghost, conns, cleanup, peri...</td>\n",
       "      <td>public int getGhostConnsCleanupPeriod() { retu...</td>\n",
       "      <td>[public, int, get, ghost, conns, cleanup, peri...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, int, get, ghost, conns, clean...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, int, &lt;KEEP&gt;, get, &lt;KE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nickman_Rindle-11-Associations-FirstSentence</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Allocates an initialized and initially unlocke...</td>\n",
       "      <td>[allocates, an, initialized, and, initially, u...</td>\n",
       "      <td>Allocates an initialized and initially unlocke...</td>\n",
       "      <td>[allocates, an, initialized, and, initially, u...</td>\n",
       "      <td>[&lt;INSERT_OLD_KEEP_BEFORE&gt;, unlocked, &lt;INSERT_N...</td>\n",
       "      <td>\\tpublic static long allocateSpinLock() {\\r\\n\\...</td>\n",
       "      <td>[public, static, long, allocate, spin, lock, (...</td>\n",
       "      <td>public static SpinLock allocateSpinLock() { lo...</td>\n",
       "      <td>[public, static, spin, lock, allocate, spin, l...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, static, &lt;KEEP_END&gt;, &lt;REPLACE_...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, static, &lt;REPLACE_OLD&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>h2oai_h2o_2-427-FirstSentence-0</td>\n",
       "      <td>0</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Rebalance a frame for load balancing</td>\n",
       "      <td>[rebalance, a, frame, for, load, balancing]</td>\n",
       "      <td>Rebalance a frame for load balancing</td>\n",
       "      <td>[rebalance, a, frame, for, load, balancing]</td>\n",
       "      <td>[]</td>\n",
       "      <td>private Frame reBalance(final Frame fr, bool...</td>\n",
       "      <td>[private, frame, re, balance, (, final, frame,...</td>\n",
       "      <td>private static Frame reBalance(final Frame fr,...</td>\n",
       "      <td>[private, static, frame, re, balance, (, final...</td>\n",
       "      <td>[&lt;KEEP&gt;, private, &lt;KEEP_END&gt;, &lt;INSERT&gt;, static...</td>\n",
       "      <td>[&lt;KEEP&gt;, private, &lt;INSERT&gt;, static, &lt;KEEP&gt;, fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sonatype_sonatype-aether-11-Associations-First...</td>\n",
       "      <td>1</td>\n",
       "      <td>Summary</td>\n",
       "      <td>Sets the host of this proxy.</td>\n",
       "      <td>[sets, the, host, of, this, proxy, .]</td>\n",
       "      <td>Sets the host of the proxy.</td>\n",
       "      <td>[sets, the, host, of, the, proxy, .]</td>\n",
       "      <td>[&lt;REPLACE_OLD&gt;, this, &lt;REPLACE_NEW&gt;, the, &lt;REP...</td>\n",
       "      <td>public Proxy setHost( String host )\\n    {...</td>\n",
       "      <td>[public, proxy, set, host, (, string, host, ),...</td>\n",
       "      <td>public Proxy setHost( String host ) { return n...</td>\n",
       "      <td>[public, proxy, set, host, (, string, host, ),...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, proxy, set, host, (, string, ...</td>\n",
       "      <td>[&lt;KEEP&gt;, public, &lt;KEEP&gt;, proxy, &lt;KEEP&gt;, set, &lt;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  label comment_type  \\\n",
       "0                 todoroo_astrid-987-FirstSentence-0      1      Summary   \n",
       "1                Red5_red5_server-43-FirstSentence-0      0      Summary   \n",
       "2       nickman_Rindle-11-Associations-FirstSentence      1      Summary   \n",
       "3                    h2oai_h2o_2-427-FirstSentence-0      0      Summary   \n",
       "4  sonatype_sonatype-aether-11-Associations-First...      1      Summary   \n",
       "\n",
       "                                     old_comment_raw  \\\n",
       "0  Return SQL selector query for getting tasks wi...   \n",
       "1  Return period of ghost connections cleanup tas...   \n",
       "2  Allocates an initialized and initially unlocke...   \n",
       "3               Rebalance a frame for load balancing   \n",
       "4                       Sets the host of this proxy.   \n",
       "\n",
       "                               old_comment_subtokens  \\\n",
       "0  [return, sql, selector, query, for, getting, t...   \n",
       "1  [return, period, of, ghost, connections, clean...   \n",
       "2  [allocates, an, initialized, and, initially, u...   \n",
       "3        [rebalance, a, frame, for, load, balancing]   \n",
       "4              [sets, the, host, of, this, proxy, .]   \n",
       "\n",
       "                                     new_comment_raw  \\\n",
       "0  Return SQL selector query for getting tasks wi...   \n",
       "1  Return period of ghost connections cleanup tas...   \n",
       "2  Allocates an initialized and initially unlocke...   \n",
       "3               Rebalance a frame for load balancing   \n",
       "4                        Sets the host of the proxy.   \n",
       "\n",
       "                               new_comment_subtokens  \\\n",
       "0  [return, sql, selector, query, for, getting, t...   \n",
       "1  [return, period, of, ghost, connections, clean...   \n",
       "2  [allocates, an, initialized, and, initially, u...   \n",
       "3        [rebalance, a, frame, for, load, balancing]   \n",
       "4               [sets, the, host, of, the, proxy, .]   \n",
       "\n",
       "                 span_minimal_diff_comment_subtokens  \\\n",
       "0  [<INSERT_OLD_KEEP_BEFORE>, tag, <INSERT_NEW_KE...   \n",
       "1                                                 []   \n",
       "2  [<INSERT_OLD_KEEP_BEFORE>, unlocked, <INSERT_N...   \n",
       "3                                                 []   \n",
       "4  [<REPLACE_OLD>, this, <REPLACE_NEW>, the, <REP...   \n",
       "\n",
       "                                        old_code_raw  \\\n",
       "0          public QueryTemplate queryTemplate(Cri...   \n",
       "1      public int getGhostConnsCleanupPeriod() {\\...   \n",
       "2  \\tpublic static long allocateSpinLock() {\\r\\n\\...   \n",
       "3    private Frame reBalance(final Frame fr, bool...   \n",
       "4      public Proxy setHost( String host )\\n    {...   \n",
       "\n",
       "                                  old_code_subtokens  \\\n",
       "0  [public, query, template, query, template, (, ...   \n",
       "1  [public, int, get, ghost, conns, cleanup, peri...   \n",
       "2  [public, static, long, allocate, spin, lock, (...   \n",
       "3  [private, frame, re, balance, (, final, frame,...   \n",
       "4  [public, proxy, set, host, (, string, host, ),...   \n",
       "\n",
       "                                        new_code_raw  \\\n",
       "0  public static QueryTemplate queryTemplate(Crit...   \n",
       "1  public int getGhostConnsCleanupPeriod() { retu...   \n",
       "2  public static SpinLock allocateSpinLock() { lo...   \n",
       "3  private static Frame reBalance(final Frame fr,...   \n",
       "4  public Proxy setHost( String host ) { return n...   \n",
       "\n",
       "                                  new_code_subtokens  \\\n",
       "0  [public, static, query, template, query, templ...   \n",
       "1  [public, int, get, ghost, conns, cleanup, peri...   \n",
       "2  [public, static, spin, lock, allocate, spin, l...   \n",
       "3  [private, static, frame, re, balance, (, final...   \n",
       "4  [public, proxy, set, host, (, string, host, ),...   \n",
       "\n",
       "                            span_diff_code_subtokens  \\\n",
       "0  [<KEEP>, public, <KEEP_END>, <INSERT>, static,...   \n",
       "1  [<KEEP>, public, int, get, ghost, conns, clean...   \n",
       "2  [<KEEP>, public, static, <KEEP_END>, <REPLACE_...   \n",
       "3  [<KEEP>, private, <KEEP_END>, <INSERT>, static...   \n",
       "4  [<KEEP>, public, proxy, set, host, (, string, ...   \n",
       "\n",
       "                           token_diff_code_subtokens  \n",
       "0  [<KEEP>, public, <INSERT>, static, <KEEP>, que...  \n",
       "1  [<KEEP>, public, <KEEP>, int, <KEEP>, get, <KE...  \n",
       "2  [<KEEP>, public, <KEEP>, static, <REPLACE_OLD>...  \n",
       "3  [<KEEP>, private, <INSERT>, static, <KEEP>, fr...  \n",
       "4  [<KEEP>, public, <KEEP>, proxy, <KEEP>, set, <...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df_clean = format_data(valid_df)\n",
    "valid_df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf598e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = torch.load('save_GCBmodel.pt',map_location=torch.device('cuda:0'))\n",
    "model = torch.load('D:/BERT_learing/CCDP/for_captum/save_model/save_bertmodel.pt',map_location=torch.device('cpu'))\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d76cca9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1+cpu\n",
      "None\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())  #输出为True，则安装无误\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db0b8ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c959164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aba07f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\leitx\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea322f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertEmbeddings(\n",
       "  (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "  (position_embeddings): Embedding(512, 768)\n",
       "  (token_type_embeddings): Embedding(2, 768)\n",
       "  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bert.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db6de6fe",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertLayer(\n",
       "  (attention): BertAttention(\n",
       "    (self): BertSelfAttention(\n",
       "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (output): BertSelfOutput(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (intermediate): BertIntermediate(\n",
       "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    (intermediate_act_fn): GELUActivation()\n",
       "  )\n",
       "  (output): BertOutput(\n",
       "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bert.encoder.layer[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f954904a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79e32eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_embeddings = model.get_input_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c241dc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict和squad_pos_forward_func可以合成一个\n",
    "def predict(inputs, position_ids=None, attention_mask=None):\n",
    "    output = model(inputs,\n",
    "                   position_ids=position_ids,\n",
    "                  attention_mask=attention_mask )\n",
    "    \n",
    "    prediction = output.logits\n",
    "    prediction_1 = nn.functional.softmax(prediction, dim=1)\n",
    "    prediction = prediction_1.max(1).values\n",
    "    out = torch.argmax(prediction_1, dim=-1)\n",
    "    # prediction：每个输入样本的最大预测概率。\n",
    "    # out：预测的类别标签。\n",
    "    # prediction_1：所有类别的预测概率。    \n",
    "    return prediction,out,prediction_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4de032c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squad_pos_forward_func(inputs,position_ids=None, attention_mask=None, position=0):\n",
    "    pred ,_,_= predict(inputs,\n",
    "                     position_ids=position_ids,\n",
    "                   attention_mask=attention_mask)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1bd6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_token_id = tokenizer.pad_token_id # 0\n",
    "sep_token_id = tokenizer.sep_token_id # 101\n",
    "cls_token_id = tokenizer.cls_token_id # 102\n",
    "ref_token_id,sep_token_id,cls_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8206c991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这是单个数据的处理方式，应该要想数据集应该怎么处理\n",
    "def construct_input_ref_pair(comment,AST_type,  ref_token_id, sep_token_id, cls_token_id):\n",
    "    comment = tokenizer.encode(comment, add_special_tokens=False,truncation=True,max_length=512)\n",
    "    AST_type = tokenizer.encode(AST_type, add_special_tokens=False,truncation=True,max_length=512)\n",
    "    # construct input token ids\n",
    "    input_ids = [cls_token_id] + comment + [sep_token_id] + AST_type + [sep_token_id]\n",
    "\n",
    "    # construct reference token ids \n",
    "    ref_input_ids = [cls_token_id] + [ref_token_id] * len(comment) + [sep_token_id] + \\\n",
    "        [ref_token_id] * len(AST_type) + [sep_token_id]\n",
    "\n",
    "    return torch.tensor([input_ids], device=device), torch.tensor([ref_input_ids], device=device), len(comment)\n",
    "\n",
    "def construct_input_ref_token_type_pair(input_ids, sep_ind=0):\n",
    "    seq_len = input_ids.size(1)\n",
    "    token_type_ids = torch.tensor([[0 if i <= sep_ind else 1 for i in range(seq_len)]], device=device)\n",
    "    ref_token_type_ids = torch.zeros_like(token_type_ids, device=device)# * -1\n",
    "    return token_type_ids, ref_token_type_ids\n",
    "\n",
    "def construct_input_ref_pos_id_pair(input_ids):\n",
    "    seq_length = input_ids.size(1)\n",
    "    position_ids = torch.arange(seq_length, dtype=torch.long, device=device)\n",
    "    # we could potentially also use random permutation with `torch.randperm(seq_length, device=device)`\n",
    "    ref_position_ids = torch.zeros(seq_length, dtype=torch.long, device=device)\n",
    "\n",
    "    position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "    ref_position_ids = ref_position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "    return position_ids, ref_position_ids\n",
    "\n",
    "def construct_attention_mask(input_ids):\n",
    "    return torch.ones_like(input_ids)\n",
    "\n",
    "def construct_whole_bert_embeddings(input_ids, ref_input_ids, \\\n",
    "                                    token_type_ids=None, ref_token_type_ids=None, \\\n",
    "                                    position_ids=None, ref_position_ids=None):\n",
    "    input_embeddings = model.embeddings(input_ids, token_type_ids=token_type_ids, position_ids=position_ids)\n",
    "    ref_input_embeddings = model.embeddings(ref_input_ids, token_type_ids=ref_token_type_ids, position_ids=ref_position_ids)\n",
    "    \n",
    "    return input_embeddings, ref_input_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2657c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_list = train_df_clean.loc[2,'new_code_raw'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bc6667",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_list = train_df_clean.loc[2,'new_code_raw'] \n",
    "comment_list = train_df_clean.loc[2,'old_comment_raw']\n",
    "ground_lable = train_df_clean.loc[2,'label']\n",
    "print(code_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77439e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(comment_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec362b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ground_lable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef90c595",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_t, ref_input_ids_t, comment_len_t = construct_input_ref_pair(comment_list,code_list, ref_token_id, sep_token_id, cls_token_id)\n",
    "token_type_ids_t, ref_token_type_ids_t = construct_input_ref_token_type_pair(input_ids_t, comment_len_t)\n",
    "position_ids_t, ref_position_ids_t = construct_input_ref_pos_id_pair(input_ids_t)\n",
    "attention_mask_t = construct_attention_mask(input_ids_t)\n",
    "\n",
    "indices_t = input_ids_t[0].detach().tolist()\n",
    "all_tokens_t = tokenizer.convert_ids_to_tokens(indices_t) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fc9d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_t,ref_input_ids_t,all_tokens_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8b4bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(input_ids_t,position_ids=position_ids_t,attention_mask=attention_mask_t)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a26112",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred ,sen_type,pred_tensor= predict(input_ids_t,position_ids=position_ids_t,attention_mask=attention_mask_t)\n",
    "pred ,sen_type,pred_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb22814b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = squad_pos_forward_func(input_ids_t,position_ids=position_ids_t,attention_mask=attention_mask_t)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49521f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre ,out,_ = predict(input_ids_t,position_ids=position_ids_t,attention_mask=attention_mask_t)\n",
    "if out == 1:\n",
    "    sen_type = 'pos'\n",
    "else:\n",
    "    sen_type = 'nag'\n",
    "pre = pre.item()\n",
    "pre = \"{:.3f}\".format(pre)\n",
    "pre = float(pre) \n",
    "pre ,sen_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0e4a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "AST_list = []\n",
    "for i in range(10): \n",
    "    AST_list.append(train_df_clean.loc[i,'new_code_raw'])\n",
    "\n",
    "comment_list = []\n",
    "for i in range(10): \n",
    "    comment_list.append(train_df_clean.loc[i,'old_comment_raw'])\n",
    "\n",
    "ground_lable = []\n",
    "for i in range(10): \n",
    "    ground_lable.append(train_df_clean.loc[i,'label'])\n",
    "\n",
    "print(AST_list[2])\n",
    "print(comment_list[2])\n",
    "print(ground_lable[2])\n",
    "\n",
    "def input_data_list(AST_list,comment_list):\n",
    "    input_ids_all = []\n",
    "    ref_input_ids_all = []\n",
    "    position_ids_all = []\n",
    "    attention_mask_all = []\n",
    "    token_type_ids_all = []\n",
    "    all_tokens_all = []\n",
    "    for i in range(len(AST_list)):\n",
    "        input_ids, ref_input_ids, comment_len = construct_input_ref_pair(comment_list[i],AST_list[i], ref_token_id, sep_token_id, cls_token_id)\n",
    "        token_type_ids, ref_token_type_ids = construct_input_ref_token_type_pair(input_ids, comment_len)\n",
    "        position_ids, ref_position_ids = construct_input_ref_pos_id_pair(input_ids)\n",
    "        attention_mask = construct_attention_mask(input_ids)\n",
    "        \n",
    "        indices = input_ids[0].detach().tolist()\n",
    "        all_tokens = tokenizer.convert_ids_to_tokens(indices)\n",
    "        \n",
    "        input_ids_all.append(input_ids)\n",
    "        ref_input_ids_all.append(ref_input_ids)\n",
    "        position_ids_all.append(position_ids)\n",
    "        attention_mask_all.append(attention_mask)\n",
    "        token_type_ids_all.append(token_type_ids)\n",
    "        all_tokens_all.append(all_tokens)\n",
    "\n",
    "    return input_ids_all,ref_input_ids_all,position_ids_all,attention_mask_all,token_type_ids_all,all_tokens_all \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b6ac2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_all,ref_input_ids_all,position_ids_all,attention_mask_all,token_type_ids_all,all_tokens_all= input_data_list(AST_list,comment_list)\n",
    "# print(input_ids_all[1])\n",
    "# print(ref_input_ids_all[1])\n",
    "# print(input_ids_all[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1094ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前k个贡献最高的word 和 token_type 和 position\n",
    "# return value为归因贡献值  indices为词对应的索引  top_tokens为 词或位置或token_type\n",
    "def get_topk_attributed_tokens(attrs,all_token_t, k=5):\n",
    "    values_max, indices_max = torch.topk(attrs, k)\n",
    "    top_tokens_max = [all_token_t[idx] for idx in indices_max]\n",
    "    values_min, indices_min = torch.topk(attrs, k, largest=False)\n",
    "    top_tokens_min = [all_token_t[idx] for idx in indices_min] \n",
    "    \n",
    "    return top_tokens_max, values_max, indices_max,top_tokens_min,values_min,indices_min\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d196c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import LayerIntegratedGradients\n",
    "from captum.attr import visualization as viz\n",
    "\n",
    "lig = LayerIntegratedGradients(squad_pos_forward_func,input_embeddings)\n",
    "\n",
    "vis_data_records_ig = []\n",
    "\n",
    "def interpret_sentence(input_ids,ref_input_ids, token_type_ids, position_ids, attention_mask, all_tokens, ground_lable):\n",
    "    pre ,out,_ = predict(input_ids, \\\n",
    "                position_ids=position_ids,\n",
    "                attention_mask=attention_mask)\n",
    "    if out == 1:\n",
    "        sen_type = 'pos'\n",
    "    else:\n",
    "        sen_type = 'nag'\n",
    "    pre = pre.item()\n",
    "    pre = \"{:.3f}\".format(pre)\n",
    "    pre = float(pre) \n",
    "    pre ,sen_type\n",
    "    \n",
    "    attributions_ig, delta_ig = lig.attribute(input_ids, baselines=ref_input_ids,\\\n",
    "                           additional_forward_args=(position_ids,attention_mask,0),return_convergence_delta=True,internal_batch_size=8)\n",
    "    \n",
    "    attributions = attributions_ig.sum(dim=2).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "    \n",
    "    add_attributions_to_visualizer(attributions, all_tokens, pre, ground_lable, sen_type, delta_ig, vis_data_records_ig)\n",
    "    \n",
    "    top_tokens_max, values_max, indices_max,top_tokens_min,values_min,indices_min = get_topk_attributed_tokens(attributions,all_tokens)\n",
    "    \n",
    "    return top_tokens_max, values_max, indices_max,top_tokens_min,values_min,indices_min\n",
    "\n",
    "\n",
    "def add_attributions_to_visualizer(attributions, all_tokens, pre, ground_lable, sen_type, delta, vis_data_records):\n",
    "\n",
    "    # storing couple samples in an array for visualization purposes\n",
    "    vis_data_records.append(viz.VisualizationDataRecord(\n",
    "                            attributions,\n",
    "                            pre,\n",
    "                            pre,\n",
    "                            ground_lable,\n",
    "                            sen_type,\n",
    "                            attributions.sum(),\n",
    "                            all_tokens,\n",
    "                            delta))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65b6821",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(AST_list)):    \n",
    "    top_tokens_max, values_max, indices_max,top_tokens_min,values_min,indices_min = interpret_sentence(input_ids_all[i],ref_input_ids_all[i], token_type_ids_all[i], position_ids_all[i], attention_mask_all[i], all_tokens_all[i], ground_lable[i])\n",
    "    print(f'第{i}个top：分别为贡献最大，贡献最大值，token值，贡献最小，贡献最小值\\n{top_tokens_max}\\n, {values_max}\\n, {indices_max}\\n,{top_tokens_min}\\n,{values_min}\\n,{indices_min}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7d4398",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Visualize attributions based on Integrated Gradients')\n",
    "_ = viz.visualize_text(vis_data_records_ig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aacfe1",
   "metadata": {},
   "source": [
    "#### Interpreting Bert Layers\n",
    "每个token在所有层的归因分数分布。\n",
    "此处使用了LayerConductance进行分析，更改了前向传播函数；只更改了模型的输入参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8e2b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 与predict函数差不多\n",
    "def squad_pos_forward_func2(input_emb, attention_mask=None, position=0):\n",
    "    pred = model(inputs_embeds=input_emb, attention_mask=attention_mask, )\n",
    "    \n",
    "    prediction = pred.logits\n",
    "    prediction_1 = nn.functional.softmax(prediction, dim=1)\n",
    "    prediction = prediction_1.max(1).values\n",
    "\n",
    "    return prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8acf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_attributions(attributions):\n",
    "    attributions = attributions.sum(dim=-1).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "    return attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c230087b",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_ids_t,ref_position_ids_t = construct_input_ref_pos_id_pair(input_ids_t)\n",
    "position_ids_t,ref_position_ids_t "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee1a087",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layer_attrs = []\n",
    "\n",
    "# The token that we would like to examine separately. 下一步实验为对所有token进行计算。\n",
    "token_to_explain = 2   # 想要查看的token在所有层归因  示例中23为kinds\n",
    "layer_attrs_dist = []\n",
    "\n",
    "# input_embeddings, ref_input_embeddings = construct_whole_bert_embeddings(input_ids_t, ref_input_ids_t, \\\n",
    "#                                          token_type_ids=token_type_ids_t, ref_token_type_ids=ref_token_type_ids_t, \\\n",
    "#                                          position_ids=position_ids_t, ref_position_ids=ref_position_ids_t)\n",
    "input_embeddings, ref_input_embeddings = construct_whole_bert_embeddings(input_ids_t, ref_input_ids_t, \\\n",
    "                                         position_ids=position_ids_t, ref_position_ids=ref_position_ids_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dd3196",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2111795e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在bert.config.num_hidden_layers上对token=23的词进行分析\n",
    "for i in range(model.config.num_hidden_layers):\n",
    "    lc = LayerConductance(squad_pos_forward_func2, model.encoder.layer[i])\n",
    "    layer_attributions = lc.attribute(inputs=input_embeddings, baselines=ref_input_embeddings, additional_forward_args=(attention_mask_t, 0),internal_batch_size=1)\n",
    "    layer_attrs.append(summarize_attributions(layer_attributions).cpu().detach().tolist())\n",
    "    \n",
    "    # storing attributions of the token id that we would like to examine in more detail in token_to_explain\n",
    "    layer_attrs_dist.append(layer_attributions[0,token_to_explain,:].cpu().detach().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4b586c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 画图\n",
    "fig, ax = plt.subplots(figsize=(25,10))\n",
    "xticklabels=all_tokens_t\n",
    "yticklabels=list(range(1,13))\n",
    "ax = sns.heatmap(np.array(layer_attrs), xticklabels=xticklabels, yticklabels=yticklabels, linewidth=0.2)\n",
    "plt.xlabel('Tokens')\n",
    "plt.ylabel('Layers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8c67e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "ax = sns.boxplot(data=layer_attrs_dist)\n",
    "plt.xlabel('Layers')\n",
    "plt.ylabel('Attribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e918528",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(layer_attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e76f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52b2822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer_attributions[0,token_to_explain,:]\n",
    "# 在第一个维度选择第一个元素，第二个维度选择 token_to_explain 这个元素三个维度选择全部元素\n",
    "layer_attributions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13382486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e2e97e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee19767a",
   "metadata": {},
   "source": [
    "Visualizing Attention Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1025bf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 只有设置了 output_attentions=True 时 output.attentions 才会有值\n",
    "output = model(input_ids_t, output_attentions=True)\n",
    "print(output.attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e292233e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b69e2e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(inputs, token_type_ids=None, position_ids=None, attention_mask=None):\n",
    "    output = model(inputs, token_type_ids=token_type_ids,\n",
    "                 position_ids=position_ids, attention_mask=attention_mask, output_attentions=True )\n",
    "    return output.logits, output.attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "750abafd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_ids_t' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m output_logits,output_attentions\u001b[38;5;241m=\u001b[39m predict(input_ids_t,attention_mask\u001b[38;5;241m=\u001b[39mattention_mask_t)\n\u001b[0;32m      2\u001b[0m output_logits,output_attentions\n",
      "\u001b[1;31mNameError\u001b[0m: name 'input_ids_t' is not defined"
     ]
    }
   ],
   "source": [
    "output_logits,output_attentions= predict(input_ids_t,attention_mask=attention_mask_t)\n",
    "output_logits,output_attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809e69a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape -> layer x batch x head x seq_len x seq_len\n",
    "output_attentions_all = torch.stack(output_attentions)\n",
    "output_attentions_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249831d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_attentions_all[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599207de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_token2token_scores(scores_mat,all_tokens, x_label_name='Head'):\n",
    "    fig = plt.figure(figsize=(50, 50))\n",
    "\n",
    "    for idx, scores in enumerate(scores_mat):\n",
    "        scores_np = np.array(scores)\n",
    "        ax = fig.add_subplot(4, 3, idx+1)\n",
    "        # append the attention weights\n",
    "        im = ax.imshow(scores, cmap='viridis')\n",
    "\n",
    "        fontdict = {'fontsize': 15}\n",
    "\n",
    "        ax.set_xticks(range(len(all_tokens)))\n",
    "        ax.set_yticks(range(len(all_tokens)))\n",
    "\n",
    "        ax.set_xticklabels(all_tokens, fontdict=fontdict, rotation=90)\n",
    "        ax.set_yticklabels(all_tokens, fontdict=fontdict)\n",
    "        ax.set_xlabel('{} {}'.format(x_label_name, idx+1))\n",
    "\n",
    "        fig.colorbar(im, fraction=0.046, pad=0.04)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d17dd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_token2head_scores(scores_mat,all_tokens):\n",
    "    fig = plt.figure(figsize=(50, 50))\n",
    "\n",
    "    for idx, scores in enumerate(scores_mat):\n",
    "        scores_np = np.array(scores)\n",
    "        ax = fig.add_subplot(6, 2, idx+1)\n",
    "        # append the attention weights\n",
    "        im = ax.matshow(scores_np, cmap='viridis')\n",
    "\n",
    "        fontdict = {'fontsize': 15}\n",
    "\n",
    "        ax.set_xticks(range(len(all_tokens)))\n",
    "        ax.set_yticks(range(len(scores)))\n",
    "\n",
    "        ax.set_xticklabels(all_tokens, fontdict=fontdict, rotation=90)\n",
    "        ax.set_yticklabels(range(len(scores[0])), fontdict=fontdict)\n",
    "        ax.set_xlabel('Layer {}'.format(idx+1))\n",
    "\n",
    "        fig.colorbar(im, fraction=0.046, pad=0.04)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53b2387",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a40c1b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualize_token2token_scores(output_attentions_all[layer].squeeze().detach().cpu().numpy(),all_tokens_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323083cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0beda8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.__version__ >= '1.7.0':\n",
    "    norm_fn = torch.linalg.norm\n",
    "else:\n",
    "    norm_fn = torch.norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2a0f48",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualize_token2token_scores(norm_fn(output_attentions_all, dim=2).squeeze().detach().cpu().numpy(),all_tokens_t,x_label_name='Layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60016da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ae00022",
   "metadata": {},
   "source": [
    "Interpreting Outputs and Self-Attention Matrices in each Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db75a642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_whole_bert_embeddings(input_ids, ref_input_ids, \\\n",
    "                                    token_type_ids=None, ref_token_type_ids=None, \\\n",
    "                                    position_ids=None, ref_position_ids=None):\n",
    "    input_embeddings = interpretable_embedding.indices_to_embeddings(input_ids)\n",
    "    ref_input_embeddings = interpretable_embedding.indices_to_embeddings(ref_input_ids)\n",
    "    \n",
    "    return input_embeddings, ref_input_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1726a025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054368fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squad_pos_forward_func(inputs, attention_mask=None, position=0):\n",
    "    pred = model(inputs_embeds=inputs,  attention_mask=attention_mask, )\n",
    "    pred = pred[position]\n",
    "    return pred.max(1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6928f94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpretable_embedding = configure_interpretable_embedding_layer(model, 'roberta.embeddings.word_embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995ac9d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layer_attrs = []\n",
    "layer_attn_mat = []\n",
    "\n",
    "input_embeddings, ref_input_embeddings = construct_whole_bert_embeddings(input_ids_t, ref_input_ids_t, \\\n",
    "                                         ref_position_ids=ref_position_ids_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a57b2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f031f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(inputs_embeds=input_embeddings, attention_mask=attention_mask_t, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30b57a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fade306",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(model.config.num_hidden_layers):\n",
    "    lc = LayerConductance(squad_pos_forward_func, model.roberta.encoder.layer[i])    \n",
    "    layer_attributions = lc.attribute(inputs=input_embeddings, baselines=ref_input_embeddings, additional_forward_args=(attention_mask_t, 0),internal_batch_size=1)\n",
    "    print(layer_attributions.shape)\n",
    "    layer_attrs.append(summarize_attributions(layer_attributions[0]))\n",
    "\n",
    "    layer_attn_mat.append(layer_attributions[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6af11dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d86f755c",
   "metadata": {},
   "source": [
    "Interpreting Attribution Scores for Attention Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c5a0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_token2token_scores(layer_attn_mat[layer].squeeze().cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd93dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_token2token_scores(norm_fn(layer_attn_mat, dim=2).squeeze().detach().cpu().numpy(),\n",
    "                             x_label_name='Layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31016ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Interpreting Attribution Scores for Attention Matrices\n",
    "\n",
    "visualize_token2token_scores(layer_attn_mat[layer].squeeze().cpu().detach().numpy())\n",
    "\n",
    "visualize_token2token_scores(norm_fn(layer_attn_mat, dim=2).squeeze().detach().cpu().numpy(),\n",
    "                             x_label_name='Layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ba21c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c929cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leitx",
   "language": "python",
   "name": "leitx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
